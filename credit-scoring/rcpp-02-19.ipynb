{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load_ext autoreload\n",
    "# %autoreload 2\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Experimental setup arguments\n",
    "\n",
    "class args:\n",
    "\n",
    "    alpha = 0.2\n",
    "\n",
    "    delta = 0.1\n",
    "\n",
    "    epsilon = 0.01\n",
    "\n",
    "    tau = 0.1\n",
    "\n",
    "    lambda_max = 1.0\n",
    "\n",
    "    L = 5.0\n",
    "\n",
    "    T = 5  # number of iterations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n= 18357\n",
      "d= 10\n"
     ]
    }
   ],
   "source": [
    "from data_prep import load_data\n",
    "\n",
    "path_to_csv_file = './data/cs-training.csv'\n",
    "X_all, Y_all, data = load_data(path_to_csv_file)\n",
    "\n",
    "n = X_all.shape[0]\n",
    "d = X_all.shape[1] - 1\n",
    "\n",
    "print('n=',n)\n",
    "print('d=',d)\n",
    "\n",
    "size = n // 3\n",
    "X_train, X_cv, Y_train, Y_cv = train_test_split(X_all, Y_all, train_size=size, random_state=42)\n",
    "del X_all, Y_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Strategic Features: \n",
      "\n",
      "0 RevolvingUtilizationOfUnsecuredLines\n",
      "1 NumberOfOpenCreditLinesAndLoans\n",
      "2 NumberRealEstateLoansOrLines\n"
     ]
    }
   ],
   "source": [
    "# strategic feature indices\n",
    "strat_features = np.array([1, 6, 8]) - 1 # for later\n",
    "\n",
    "print('Strategic Features: \\n')\n",
    "for i, feature in enumerate(strat_features):\n",
    "    print(i, data.columns[feature + 1])\n",
    "\n",
    "# # zero out non-strategic features\n",
    "# assert model.coef_.shape == (1, d+1) \n",
    "# strat_coef = np.zeros((1, d+1))\n",
    "# strat_coef[0, strat_features] = model.coef_[0, strat_features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_logistic_regression(X, Y, **kwargs):\n",
    "    # fit_intercept=False since X already has bias term\n",
    "    model = LogisticRegression(fit_intercept=False, **kwargs)  # intercept pre-built in X\n",
    "    model.fit(X, Y)\n",
    "    assert model.classes_[0] == 0 and model.classes_[1] == 1\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.01162508 -0.42431799  2.07627747  0.00436746 -0.27894954  0.08004076\n",
      "   2.55829725  0.04811393  1.45300537  0.09495302 -0.41032303]]\n"
     ]
    }
   ],
   "source": [
    "model = train_logistic_regression(X_train, Y_train)\n",
    "# example_thresh = 0.5\n",
    "# Y_proba = model.predict_proba(X_train)[:,1]\n",
    "# Y_pred = Y_proba > example_thresh\n",
    "print(model.coef_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set up\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Union\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "\n",
    "\n",
    "def type_II_error(Y, Y_proba, threshold):\n",
    "    \"\"\"Y=actual, Y_proba=predicted probability, threshold=threshold\"\"\"\n",
    "    return np.mean((Y == 1) * (Y_proba < 1 - threshold))\n",
    "\n",
    "\n",
    "def piecewise_fn(Y_proba, thresh):\n",
    "    # clipping assumes loss btwn 0 and 1\n",
    "\n",
    "    # lower_bound = (1 - thresh) - 1 / args.L\n",
    "    # upper_bound = 1 - thresh\n",
    "    # y = np.where(Y_proba < lower_bound, 1, \n",
    "    #              np.where(Y_proba > upper_bound, 0, \n",
    "    #                       1 - args.L * (Y_proba - (1 - thresh) + 1 / args.L)))\n",
    "\n",
    "    # Optimization 1: use np.clip\n",
    "    # y = np.clip(1 - args.L * (Y_proba - (1 - thresh) + 1 / args.L), 0, 1)\n",
    "\n",
    "    # Optimization 2: compute less\n",
    "    return np.clip(args.L * (1 - thresh - Y_proba), 0, 1).reshape(-1, 1)\n",
    "\n",
    "\n",
    "def piecewise_loss(Y, Y_proba, thresh):\n",
    "    return (Y == 1) * piecewise_fn(Y_proba, thresh)\n",
    "\n",
    "\n",
    "def surrogate_loss(Y, Y_proba, thresh):\n",
    "    \"\"\"l_{\\tilde}\"\"\"\n",
    "    return piecewise_loss(Y, Y_proba, thresh) + args.tau * (args.lambda_max - thresh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_next_thresh(Y, Y_proba, init_range=None, tol=1e-5, max_iter=30):\n",
    "    def f(thresh):\n",
    "        return surrogate_loss(Y, Y_proba, thresh).mean() - args.alpha\n",
    "\n",
    "    # Choose two initial guesses.\n",
    "    if init_range is None:\n",
    "        t0, t1 = 0.0, 1.0\n",
    "    else:\n",
    "        t0 = max(0.0, init_range[0])\n",
    "        t1 = min(1.0, init_range[1])\n",
    "    \n",
    "    f0, f1 = f(t0), f(t1)\n",
    "    \n",
    "    # If either guess is already close enough, return it.\n",
    "    if abs(f0) < tol:\n",
    "        return t0\n",
    "    if abs(f1) < tol:\n",
    "        return t1\n",
    "\n",
    "    for _ in range(max_iter):\n",
    "        # Prevent division by zero if f1 == f0.\n",
    "        if f1 - f0 == 0:\n",
    "            break\n",
    "        \n",
    "        # Secant update.\n",
    "        t_new = t1 - f1 * (t1 - t0) / (f1 - f0)\n",
    "        # Ensure t_new stays within [0, 1].\n",
    "        t_new = np.clip(t_new, 0.0, 1.0)\n",
    "        \n",
    "        f_new = f(t_new)\n",
    "        if abs(f_new) < tol:\n",
    "            return t_new\n",
    "        \n",
    "        # Update our guesses.\n",
    "        t0, f0 = t1, f1\n",
    "        t1, f1 = t_new, f_new\n",
    "\n",
    "    return t1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_new_features(X, model, thresh):\n",
    "    # toy \"optimization\", either stay w/ current features or move by epsilon\n",
    "    # to new features, depending on which has higher utility cost\n",
    "\n",
    "    s = np.abs(model.coef_).argmax()\n",
    "    onehot = np.zeros((1, len(model.coef_[0])))\n",
    "    onehot[0, s] = 1\n",
    "    sign = np.sign(model.coef_[0, s])\n",
    "\n",
    "    # utility of not moving\n",
    "    stay_utility_cost = np.squeeze(1 - piecewise_fn(model.predict_proba(X)[:,1], thresh))\n",
    "\n",
    "    # utility of moving by epsilon\n",
    "    X_move = X + sign * args.epsilon * onehot\n",
    "\n",
    "    move_utility = np.squeeze(1 - piecewise_fn(model.predict_proba(X_move)[:,1], thresh))\n",
    "    move_cost = (1 / (2 * args.epsilon / args.L) * np.square(X_move - X)).sum(axis=1)\n",
    "    move_utility_cost = move_utility - move_cost\n",
    "\n",
    "    mask = move_utility_cost > stay_utility_cost\n",
    "\n",
    "    result = np.where(mask[:, np.newaxis], X_move, X)\n",
    "    return result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_iters(X, Y, verbose=False):\n",
    "\n",
    "    losses = []\n",
    "    threshes = []\n",
    "\n",
    "    thresh = args.lambda_max\n",
    "    thresh_diff = args.lambda_max\n",
    "\n",
    "    iters = tqdm(range(args.T)) if verbose else range(args.T)\n",
    "\n",
    "    for _ in tqdm(range(args.T)):\n",
    "\n",
    "        # Deploy threshold\n",
    "        X_i = get_new_features(X, model, thresh)\n",
    "        Y_proba = model.predict_proba(X_i)[:,1]\n",
    "\n",
    "        # Calculate loss\n",
    "        loss_i = piecewise_loss(Y, Y_proba, thresh).mean()\n",
    "\n",
    "        # Update to new threshold, expect thresh difference to continue decreasing\n",
    "        thresh_new = get_next_thresh(Y,\n",
    "                                     Y_proba,\n",
    "                                     init_range=(thresh - thresh_diff, thresh + thresh_diff),)\n",
    "        thresh_diff = abs(thresh - thresh_new)\n",
    "        thresh = thresh_new\n",
    "\n",
    "        losses.append(loss_i)\n",
    "        threshes.append(thresh)\n",
    "\n",
    "    return thresh, losses, threshes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def simulate_thresh_sensitivity(X_cv, Y_cv, num_trials=2):\n",
    "    # Run on the full dataset to get the original threshold.\n",
    "    orig_thresh, _, _ = run_iters(X_cv, Y_cv)\n",
    "\n",
    "    thresh_list = []\n",
    "    n = len(X_cv)\n",
    "    \n",
    "    # Ensure we don't exceed the number of available points.\n",
    "    if num_trials > n:\n",
    "        raise ValueError(\"num_trials cannot exceed the number of data points in X_cv.\")\n",
    "\n",
    "    # Get a random permutation of indices and select the first num_trials indices\n",
    "    indices = np.random.permutation(n)[:num_trials]\n",
    "\n",
    "    for idx in tqdm(indices):\n",
    "        # Remove the selected data point from X_cv and Y_cv\n",
    "        X_new = np.delete(X_cv, idx, axis=0)\n",
    "        Y_new = np.delete(Y_cv, idx, axis=0)\n",
    "        \n",
    "        # Run run_iters on the modified dataset\n",
    "        new_thresh, _, _ = run_iters(X_new, Y_new)\n",
    "        thresh_list.append(new_thresh)\n",
    "    \n",
    "    # Convert to a NumPy array for vectorized operations\n",
    "    thresh_array = np.array(thresh_list)\n",
    "    \n",
    "    # Calculate the maximum absolute difference from the original threshold\n",
    "    max_diff = np.max(np.abs(thresh_array - orig_thresh))\n",
    "    \n",
    "    return max_diff\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/5 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:15<00:00,  3.11s/it]\n",
      "100%|██████████| 5/5 [00:15<00:00,  3.07s/it]\n",
      "100%|██████████| 5/5 [00:15<00:00,  3.06s/it]t]\n",
      "100%|██████████| 5/5 [00:15<00:00,  3.07s/it]t]\n",
      "100%|██████████| 5/5 [00:15<00:00,  3.05s/it]t]\n",
      "100%|██████████| 5/5 [00:15<00:00,  3.07s/it]t]\n",
      "100%|██████████| 5/5 [00:15<00:00,  3.06s/it]t]\n",
      "100%|██████████| 5/5 [00:15<00:00,  3.07s/it]t]\n",
      "100%|██████████| 5/5 [00:15<00:00,  3.06s/it]t]\n",
      "100%|██████████| 5/5 [00:15<00:00,  3.07s/it]t]\n",
      "100%|██████████| 5/5 [00:15<00:00,  3.06s/it]t]\n",
      "100%|██████████| 5/5 [00:15<00:00,  3.07s/it]it]\n",
      "100%|██████████| 5/5 [00:15<00:00,  3.06s/it]it]\n",
      "100%|██████████| 5/5 [00:15<00:00,  3.07s/it]it]\n",
      "100%|██████████| 5/5 [00:15<00:00,  3.05s/it]it]\n",
      "100%|██████████| 5/5 [00:15<00:00,  3.08s/it]it]\n",
      "100%|██████████| 5/5 [00:15<00:00,  3.05s/it]it]\n",
      "100%|██████████| 5/5 [00:15<00:00,  3.08s/it]it]\n",
      "100%|██████████| 5/5 [00:15<00:00,  3.06s/it]it]\n",
      "100%|██████████| 5/5 [00:15<00:00,  3.08s/it]it]\n",
      "100%|██████████| 5/5 [00:15<00:00,  3.05s/it]it]\n",
      "100%|██████████| 5/5 [00:15<00:00,  3.08s/it]it]\n",
      "100%|██████████| 5/5 [00:15<00:00,  3.05s/it]it]\n",
      "100%|██████████| 5/5 [00:15<00:00,  3.08s/it]it]\n",
      "100%|██████████| 5/5 [00:15<00:00,  3.06s/it]it]\n",
      "100%|██████████| 5/5 [00:15<00:00,  3.08s/it]it]\n",
      "100%|██████████| 5/5 [00:15<00:00,  3.05s/it]it]\n",
      "100%|██████████| 5/5 [00:15<00:00,  3.08s/it]it]\n",
      "100%|██████████| 5/5 [00:15<00:00,  3.05s/it]it]\n",
      "100%|██████████| 5/5 [00:15<00:00,  3.08s/it]it]\n",
      "100%|██████████| 5/5 [00:15<00:00,  3.06s/it]it]\n",
      "100%|██████████| 5/5 [00:15<00:00,  3.08s/it]it]\n",
      "100%|██████████| 5/5 [00:15<00:00,  3.06s/it]it]\n",
      "100%|██████████| 5/5 [00:15<00:00,  3.08s/it]it]\n",
      "100%|██████████| 5/5 [00:15<00:00,  3.05s/it]it]\n",
      "100%|██████████| 5/5 [00:15<00:00,  3.08s/it]it]\n",
      "100%|██████████| 5/5 [00:15<00:00,  3.05s/it]it]\n",
      "100%|██████████| 5/5 [00:15<00:00,  3.08s/it]it]\n",
      "100%|██████████| 5/5 [00:15<00:00,  3.05s/it]it]\n",
      "100%|██████████| 5/5 [00:15<00:00,  3.08s/it]it]\n",
      "100%|██████████| 5/5 [00:15<00:00,  3.06s/it]it]\n",
      "100%|██████████| 5/5 [00:15<00:00,  3.08s/it]it]\n",
      "100%|██████████| 5/5 [00:15<00:00,  3.05s/it]it]\n",
      "100%|██████████| 5/5 [00:15<00:00,  3.08s/it]it]\n",
      "100%|██████████| 5/5 [00:15<00:00,  3.05s/it]it]\n",
      "100%|██████████| 5/5 [00:15<00:00,  3.08s/it]it]\n",
      "100%|██████████| 5/5 [00:15<00:00,  3.05s/it]it]\n",
      "100%|██████████| 5/5 [00:15<00:00,  3.08s/it]it]\n",
      "100%|██████████| 5/5 [00:15<00:00,  3.05s/it]it]\n",
      "100%|██████████| 5/5 [00:15<00:00,  3.08s/it]it]\n",
      "100%|██████████| 5/5 [00:15<00:00,  3.06s/it]it]\n",
      "100%|██████████| 5/5 [00:15<00:00,  3.08s/it]it]\n",
      "100%|██████████| 5/5 [00:15<00:00,  3.05s/it]it]\n",
      "100%|██████████| 5/5 [00:15<00:00,  3.08s/it]it]\n",
      "100%|██████████| 5/5 [00:15<00:00,  3.05s/it]it]\n",
      "100%|██████████| 5/5 [00:15<00:00,  3.08s/it]it]\n",
      "100%|██████████| 5/5 [00:15<00:00,  3.05s/it]it]\n",
      "100%|██████████| 5/5 [00:15<00:00,  3.08s/it]it]\n",
      "100%|██████████| 5/5 [00:15<00:00,  3.05s/it]it]\n",
      "100%|██████████| 5/5 [00:15<00:00,  3.08s/it]it]\n",
      "100%|██████████| 5/5 [00:15<00:00,  3.05s/it]it]\n",
      "100%|██████████| 5/5 [00:15<00:00,  3.08s/it]it]\n",
      "100%|██████████| 5/5 [00:15<00:00,  3.05s/it]it]\n",
      "100%|██████████| 5/5 [00:15<00:00,  3.08s/it]it]\n",
      "100%|██████████| 5/5 [00:15<00:00,  3.06s/it]it]\n",
      "100%|██████████| 5/5 [00:15<00:00,  3.08s/it]it]\n",
      "100%|██████████| 5/5 [00:15<00:00,  3.06s/it]it]\n",
      "100%|██████████| 5/5 [00:15<00:00,  3.08s/it]it]\n",
      "100%|██████████| 5/5 [00:15<00:00,  3.05s/it]it]\n",
      "100%|██████████| 5/5 [00:15<00:00,  3.08s/it]it]\n",
      "100%|██████████| 5/5 [00:15<00:00,  3.05s/it]it]\n",
      "100%|██████████| 5/5 [00:15<00:00,  3.08s/it]it]\n",
      "100%|██████████| 5/5 [00:15<00:00,  3.05s/it]it]\n",
      "100%|██████████| 5/5 [00:15<00:00,  3.08s/it]it]\n",
      "100%|██████████| 5/5 [00:15<00:00,  3.05s/it]it]\n",
      "100%|██████████| 5/5 [00:15<00:00,  3.08s/it]it]\n",
      "100%|██████████| 5/5 [00:15<00:00,  3.08s/it]it]\n",
      "100%|██████████| 5/5 [00:15<00:00,  3.10s/it]it]\n",
      "100%|██████████| 5/5 [00:15<00:00,  3.08s/it]it]\n",
      "100%|██████████| 5/5 [00:15<00:00,  3.10s/it]it]\n",
      "100%|██████████| 5/5 [00:15<00:00,  3.08s/it]it]\n",
      "100%|██████████| 5/5 [00:15<00:00,  3.10s/it]it]\n",
      "100%|██████████| 5/5 [00:15<00:00,  3.08s/it]it]\n",
      "100%|██████████| 5/5 [00:15<00:00,  3.10s/it]it]\n",
      "100%|██████████| 5/5 [00:15<00:00,  3.08s/it]it]\n",
      "100%|██████████| 5/5 [00:15<00:00,  3.10s/it]it]\n",
      "100%|██████████| 5/5 [00:15<00:00,  3.08s/it]it]\n",
      "100%|██████████| 5/5 [00:15<00:00,  3.10s/it]it]\n",
      "100%|██████████| 5/5 [00:15<00:00,  3.08s/it]it]\n",
      "100%|██████████| 5/5 [00:15<00:00,  3.10s/it]it]\n",
      "100%|██████████| 5/5 [00:15<00:00,  3.08s/it]it]\n",
      "100%|██████████| 5/5 [00:15<00:00,  3.10s/it]it]\n",
      "100%|██████████| 5/5 [00:15<00:00,  3.08s/it]it]\n",
      "100%|██████████| 5/5 [00:15<00:00,  3.10s/it]it]\n",
      "100%|██████████| 5/5 [00:15<00:00,  3.08s/it]it]\n",
      "100%|██████████| 5/5 [00:15<00:00,  3.10s/it]it]\n",
      "100%|██████████| 5/5 [00:15<00:00,  3.08s/it]it]\n",
      "100%|██████████| 5/5 [00:15<00:00,  3.10s/it]it]\n",
      "100%|██████████| 5/5 [00:15<00:00,  3.08s/it]it]\n",
      "100%|██████████| 5/5 [00:15<00:00,  3.10s/it]it]\n",
      "100%|██████████| 5/5 [00:15<00:00,  3.08s/it]it]\n",
      "100%|██████████| 5/5 [00:15<00:00,  3.10s/it]/it]\n",
      "100%|██████████| 5/5 [00:15<00:00,  3.08s/it]/it]\n",
      "100%|██████████| 5/5 [00:15<00:00,  3.10s/it]/it]\n",
      "100%|██████████| 5/5 [00:15<00:00,  3.08s/it]/it]\n",
      "100%|██████████| 5/5 [00:15<00:00,  3.10s/it]/it]\n",
      "100%|██████████| 5/5 [00:15<00:00,  3.08s/it]/it]\n",
      "100%|██████████| 5/5 [00:15<00:00,  3.10s/it]/it]\n",
      "100%|██████████| 5/5 [00:15<00:00,  3.08s/it]/it]\n",
      "100%|██████████| 5/5 [00:15<00:00,  3.10s/it]/it]\n",
      "100%|██████████| 5/5 [00:15<00:00,  3.08s/it]/it]\n",
      "100%|██████████| 5/5 [00:15<00:00,  3.10s/it]/it]\n",
      "100%|██████████| 5/5 [00:15<00:00,  3.08s/it]/it]\n",
      "100%|██████████| 5/5 [00:15<00:00,  3.10s/it]/it]\n",
      "100%|██████████| 5/5 [00:15<00:00,  3.08s/it]/it]\n",
      "100%|██████████| 5/5 [00:15<00:00,  3.10s/it]/it]\n",
      "100%|██████████| 5/5 [00:15<00:00,  3.08s/it]/it]\n",
      "100%|██████████| 5/5 [00:15<00:00,  3.10s/it]/it]\n",
      "100%|██████████| 5/5 [00:15<00:00,  3.08s/it]/it]\n",
      "100%|██████████| 5/5 [00:15<00:00,  3.10s/it]/it]\n",
      "100%|██████████| 5/5 [00:15<00:00,  3.08s/it]/it]\n",
      "100%|██████████| 5/5 [00:15<00:00,  3.10s/it]/it]\n",
      "100%|██████████| 5/5 [00:15<00:00,  3.08s/it]/it]\n",
      "100%|██████████| 5/5 [00:15<00:00,  3.06s/it]/it]\n",
      "100%|██████████| 5/5 [00:15<00:00,  3.06s/it]/it]\n",
      "100%|██████████| 5/5 [00:15<00:00,  3.05s/it]/it]\n",
      "100%|██████████| 5/5 [00:15<00:00,  3.04s/it]/it]\n",
      "100%|██████████| 5/5 [00:15<00:00,  3.05s/it]/it]\n",
      "100%|██████████| 5/5 [00:15<00:00,  3.04s/it]/it]\n",
      "100%|██████████| 5/5 [00:15<00:00,  3.05s/it]/it]\n",
      "100%|██████████| 5/5 [00:15<00:00,  3.04s/it]/it]\n",
      "100%|██████████| 5/5 [00:15<00:00,  3.05s/it]/it]\n",
      "100%|██████████| 5/5 [00:15<00:00,  3.04s/it]/it]\n",
      "100%|██████████| 5/5 [00:15<00:00,  3.06s/it]/it]\n",
      "100%|██████████| 5/5 [00:15<00:00,  3.05s/it]/it]\n",
      "100%|██████████| 5/5 [00:15<00:00,  3.08s/it]/it]\n",
      "100%|██████████| 5/5 [00:15<00:00,  3.08s/it]/it]\n",
      "100%|██████████| 5/5 [00:15<00:00,  3.06s/it]/it]\n",
      "100%|██████████| 5/5 [00:15<00:00,  3.05s/it]/it]\n",
      "100%|██████████| 5/5 [00:15<00:00,  3.07s/it]/it]\n",
      "100%|██████████| 5/5 [00:15<00:00,  3.06s/it]/it]\n",
      "100%|██████████| 5/5 [00:15<00:00,  3.08s/it]/it]\n",
      "100%|██████████| 5/5 [00:15<00:00,  3.05s/it]/it]\n",
      "100%|██████████| 5/5 [00:15<00:00,  3.06s/it]/it]\n",
      "100%|██████████| 5/5 [00:15<00:00,  3.06s/it]/it]\n",
      "100%|██████████| 5/5 [00:15<00:00,  3.06s/it]/it]\n",
      "100%|██████████| 5/5 [00:15<00:00,  3.05s/it]/it]\n",
      "100%|██████████| 5/5 [00:15<00:00,  3.07s/it]/it]\n",
      "100%|██████████| 5/5 [00:15<00:00,  3.05s/it]/it]\n",
      "100%|██████████| 5/5 [00:15<00:00,  3.09s/it]/it]\n",
      "100%|██████████| 5/5 [00:15<00:00,  3.05s/it]/it]\n",
      "100%|██████████| 5/5 [00:15<00:00,  3.06s/it]/it]\n",
      "100%|██████████| 5/5 [00:15<00:00,  3.05s/it]/it]\n",
      "100%|██████████| 5/5 [00:15<00:00,  3.06s/it]/it]\n",
      "100%|██████████| 5/5 [00:15<00:00,  3.05s/it]/it]\n",
      "100%|██████████| 5/5 [00:15<00:00,  3.06s/it]/it]\n",
      "100%|██████████| 5/5 [00:15<00:00,  3.05s/it]/it]\n",
      "100%|██████████| 5/5 [00:15<00:00,  3.08s/it]/it]\n",
      "100%|██████████| 5/5 [00:15<00:00,  3.05s/it]/it]\n",
      "100%|██████████| 5/5 [00:15<00:00,  3.06s/it]/it]\n",
      "100%|██████████| 5/5 [00:15<00:00,  3.05s/it]/it]\n",
      "100%|██████████| 5/5 [00:15<00:00,  3.06s/it]/it]\n",
      "100%|██████████| 5/5 [00:15<00:00,  3.05s/it]/it]\n",
      "100%|██████████| 5/5 [00:15<00:00,  3.05s/it]/it]\n",
      "100%|██████████| 5/5 [00:15<00:00,  3.04s/it]/it]\n",
      "100%|██████████| 5/5 [00:15<00:00,  3.05s/it]/it]\n",
      "100%|██████████| 5/5 [00:15<00:00,  3.04s/it]/it]\n",
      "100%|██████████| 5/5 [00:15<00:00,  3.05s/it]/it]\n",
      "100%|██████████| 5/5 [00:15<00:00,  3.04s/it]/it]\n",
      "100%|██████████| 5/5 [00:15<00:00,  3.05s/it]/it]\n",
      "100%|██████████| 5/5 [00:15<00:00,  3.04s/it]/it]\n",
      "100%|██████████| 5/5 [00:15<00:00,  3.05s/it]/it]\n",
      "100%|██████████| 5/5 [00:15<00:00,  3.04s/it]/it]\n",
      "100%|██████████| 5/5 [00:15<00:00,  3.05s/it]/it]\n",
      "100%|██████████| 5/5 [00:15<00:00,  3.05s/it]/it]\n",
      "100%|██████████| 5/5 [00:15<00:00,  3.06s/it]/it]\n",
      "100%|██████████| 5/5 [00:15<00:00,  3.04s/it]/it]\n",
      "100%|██████████| 5/5 [00:15<00:00,  3.05s/it]/it]\n",
      "100%|██████████| 5/5 [00:15<00:00,  3.04s/it]/it]\n",
      "100%|██████████| 5/5 [00:15<00:00,  3.05s/it]/it]\n",
      "100%|██████████| 5/5 [00:15<00:00,  3.04s/it]/it]\n",
      "100%|██████████| 5/5 [00:15<00:00,  3.05s/it]/it]\n",
      "100%|██████████| 5/5 [00:15<00:00,  3.04s/it]/it]\n",
      "100%|██████████| 5/5 [00:15<00:00,  3.05s/it]/it]\n",
      "100%|██████████| 5/5 [00:15<00:00,  3.04s/it]/it]\n",
      "100%|██████████| 5/5 [00:15<00:00,  3.05s/it]/it]\n",
      "100%|██████████| 5/5 [00:15<00:00,  3.04s/it]/it]\n",
      "100%|██████████| 5/5 [00:15<00:00,  3.05s/it]/it]\n",
      "100%|██████████| 5/5 [00:15<00:00,  3.04s/it]/it]\n",
      "100%|██████████| 5/5 [00:15<00:00,  3.05s/it]/it]\n",
      "100%|██████████| 5/5 [00:15<00:00,  3.04s/it]/it]\n",
      "100%|██████████| 5/5 [00:15<00:00,  3.05s/it]/it]\n",
      "100%|██████████| 5/5 [00:15<00:00,  3.04s/it]/it]\n",
      "100%|██████████| 5/5 [00:15<00:00,  3.06s/it]/it]\n",
      "100%|██████████| 5/5 [00:15<00:00,  3.04s/it]/it]\n",
      "100%|██████████| 5/5 [00:15<00:00,  3.06s/it]/it]\n",
      "100%|██████████| 5/5 [00:15<00:00,  3.04s/it]/it]\n",
      "100%|██████████| 5/5 [00:15<00:00,  3.05s/it]/it]\n",
      "100%|██████████| 5/5 [00:15<00:00,  3.04s/it]/it]\n",
      "100%|██████████| 5/5 [00:15<00:00,  3.05s/it]/it]\n",
      "100%|██████████| 5/5 [00:15<00:00,  3.04s/it]/it]\n",
      "100%|██████████| 200/200 [51:06<00:00, 15.33s/it]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "np.float64(3.620011382010624e-05)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_diff = simulate_thresh_sensitivity(X_cv, Y_cv, num_trials=200)\n",
    "max_diff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rcpp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
