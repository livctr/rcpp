{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "052648cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3966fc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import random\n",
    "import re\n",
    "from typing import Any, Dict, List, Tuple\n",
    "\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_core.messages import SystemMessage, HumanMessage\n",
    "from langchain_core.runnables import Runnable\n",
    "from langchain_community.llms import VLLM\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "# Configure logging\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'\n",
    ")\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "\n",
    "def generate_applicant_data(model, n: int, p: float, shuffle: bool = False):\n",
    "    \"\"\"\n",
    "    Generates a dataset of data science applicant summaries and their labels.\n",
    "\n",
    "    Args:\n",
    "        n (int): The total number of applicant summaries to generate.\n",
    "        p (float): The probability (0.0 to 1.0) of generating a strong applicant.\n",
    "        shuffle (bool): Whether to shuffle the generated data (X and y) together.\n",
    "\n",
    "    Returns:\n",
    "        tuple: A tuple containing two lists:\n",
    "            - X (list): A list of applicant summary strings.\n",
    "            - y (list): A list of labels (1 for strong, 0 for typical).\n",
    "    \"\"\"\n",
    "\n",
    "    # Define the prompts\n",
    "    strong_applicant_prompt = ChatPromptTemplate([\n",
    "        (\n",
    "            \"system\",\n",
    "            \"You are a data science professional articulating your suitability for a challenging data science role in 100 words. \"\n",
    "        ),\n",
    "        (\n",
    "            \"human\",\n",
    "            \"Articulate your key contributions to past data-driven projects, focusing on how your \"\n",
    "            \"analytical approach led to measurable improvements or novel insights. \"\n",
    "            \"Feel free to mention tools and methodologies you used, your ability to solve complex problems, \"\n",
    "            \"or your capacity to communicate complex findings to non-technical stakeholders. \"\n",
    "            \"Begin with 'As'. Do not exceed the 100-word limit, else you will not be hired.\"\n",
    "            \"ONLY OUTPUT YOUR RESPONSE, DO NOT OUTPUT ANY OTHER TEXT!\"\n",
    "        )\n",
    "    ])\n",
    "    typical_applicant_prompt = ChatPromptTemplate([\n",
    "        (\n",
    "            \"system\",\n",
    "            \"You are an aspiring data scientist articulating your qualifications for an entry-level or junior role in 100 words. \"\n",
    "        ),\n",
    "        (\n",
    "            \"human\",\n",
    "            \"Articulate your key qualifications, including relevant coursework, projects, or prior experience. \"\n",
    "            \"Highlight your enthusiasm for learning and applying data analysis techniques to real-world problems. \"\n",
    "            \"Mention your comfort with standard data tools and a desire to grow your skills within a collaborative team environment. \"\n",
    "            \"Begin with 'As'. Do not exceed the 100-word limit, else you will not be hired.\"\n",
    "            \"ONLY OUTPUT YOUR RESPONSE, DO NOT OUTPUT ANY OTHER TEXT!\"\n",
    "        )\n",
    "    ])\n",
    "\n",
    "    X = []  # List to store applicant summaries\n",
    "    y = []  # List to store labels (1 for strong, 0 for typical)\n",
    "\n",
    "    # Create chains for each prompt\n",
    "    strong_chain: Runnable = strong_applicant_prompt | model\n",
    "    typical_chain: Runnable = typical_applicant_prompt | model\n",
    "\n",
    "    # Determine the number of strong and typical applicants\n",
    "    num_strong = round(n * p)\n",
    "    num_typical = n - num_strong\n",
    "\n",
    "    # Generate strong applicants\n",
    "    if num_strong > 0:\n",
    "        logging.info(f\"Generating {num_strong} strong applicants...\")\n",
    "        strong_inputs = [{} for _ in range(num_strong)] # Empty dictionaries as input since prompts are self-contained\n",
    "        strong_results = strong_chain.batch(strong_inputs)\n",
    "        X.extend(strong_results)\n",
    "        y.extend([1] * num_strong)\n",
    "\n",
    "        logging.info(\"=\" * 40)\n",
    "        logging.info(f\"generate_applicant_data (Label: 'Strong')\")\n",
    "        logging.info(\"=\" * 40)\n",
    "        logging.info(f\"{strong_results[0]}\")\n",
    "        logging.info(\"=\" * 40)\n",
    "\n",
    "    # Generate typical applicants\n",
    "    if num_typical > 0:\n",
    "        logging.info(f\"Generating {num_typical} typical applicants...\")\n",
    "        typical_inputs = [{} for _ in range(num_typical)]\n",
    "        typical_results = typical_chain.batch(typical_inputs)\n",
    "        X.extend(typical_results)\n",
    "        y.extend([0] * num_typical)\n",
    "\n",
    "        logging.info(\"=\" * 40)\n",
    "        logging.info(f\"generate_applicant_data (Label: 'Typical')\")\n",
    "        logging.info(\"=\" * 40)\n",
    "        logging.info(f\"{typical_results[0]}\")\n",
    "        logging.info(\"=\" * 40)\n",
    "\n",
    "    # Combine and shuffle if requested\n",
    "    if shuffle:\n",
    "        combined_data = list(zip(X, y))\n",
    "        random.shuffle(combined_data)\n",
    "        X, y = zip(*combined_data) # Unzip the shuffled data\n",
    "        X = list(X)\n",
    "        y = list(y)\n",
    "\n",
    "    logging.info(\"Generation complete!\")\n",
    "    return X, y\n",
    "\n",
    "\n",
    "def create_ats_scorer(scorer_model) -> Runnable:\n",
    "    \"\"\"\n",
    "    Creates an LLM-based ATS scorer chain.\n",
    "    \"\"\"\n",
    "    ats_prompt_template = ChatPromptTemplate([\n",
    "        (\n",
    "            \"system\",\n",
    "            \"You are a seasoned Hiring Manager for a Data Scientist role. Rate the applicant's summary (0-100).\\n\"\n",
    "            \"Indicators of a strong candidate: advanced ML (deep learning, NLP, CV), MLOps/deployment, leadership, quantifiable impact, specialized tools (TF, PyTorch, Spark, cloud), PhD/research.\\n\"\n",
    "            \"Indicators of a typical candidate: foundational skills (data cleaning, basic EDA), common libraries (Pandas, Scikit-learn), general project experience, academic focus.\\n\"\n",
    "            \"Score: 100 (top-tier), 80-99 (very strong), 60-79 (good/typical), 40-59 (decent), <40 (needs experience).\\n\"\n",
    "            \"\\n\"\n",
    "            \"Applicant Summary:\\n\"\n",
    "            \"{applicant_summary}\\n\"\n",
    "            \"Please output the following. If you don't, you will get fired!\\n\"\n",
    "            \"Score: [0-100]\\n\"\n",
    "            \"Justification: [One-sentence justification. Be super concise!]\"\n",
    "        )\n",
    "    ])\n",
    "    return ats_prompt_template | scorer_model\n",
    "\n",
    "\n",
    "def run_ats_on_batch(\n",
    "    scorer_model, # Pass the LLM model instance directly\n",
    "    applicant_summaries: List[str],\n",
    "    labels: List[int], # For comparison, not used by ATS for scoring\n",
    ") -> List[Tuple[int, str]]:\n",
    "    \"\"\"\n",
    "    Runs the ATS system on a batch of applicant summaries using true LLM batching.\n",
    "\n",
    "    Args:\n",
    "        model: The LLM model instance to use for scoring.\n",
    "        applicant_summaries (List[str]): A list of applicant summary strings.\n",
    "        labels (List[int]): The true labels (1 for strong, 0 for typical) for comparison.\n",
    "\n",
    "    Returns:\n",
    "        List[Tuple[int, str]]: A list of tuples, each containing (score, justification).\n",
    "    \"\"\"\n",
    "    ats_scorer_chain = create_ats_scorer(scorer_model) # Create the chain with the model\n",
    "\n",
    "    # Prepare inputs for batch processing\n",
    "    batch_inputs = [{\"applicant_summary\": summary} for summary in applicant_summaries]\n",
    "\n",
    "    logging.info(f\"Running ATS on {len(applicant_summaries)} applicants...\")\n",
    "    raw_ats_responses = ats_scorer_chain.batch(batch_inputs) # This is the true batch call\n",
    "\n",
    "    results = []\n",
    "    for i, response_text in enumerate(raw_ats_responses):\n",
    "        score_match = re.search(r\"Score:\\s*(\\d+)\", response_text)\n",
    "        justification_match = re.search(r\"Justification:\\s*(.*)\", response_text, re.DOTALL)\n",
    "\n",
    "        score = 0\n",
    "        justification = \"Error parsing score or justification.\"\n",
    "\n",
    "        if score_match:\n",
    "            try:\n",
    "                score = int(score_match.group(1))\n",
    "                score = max(0, min(100, score))\n",
    "            except ValueError:\n",
    "                pass\n",
    "\n",
    "        if justification_match:\n",
    "            justification = justification_match.group(1).strip()\n",
    "\n",
    "        results.append((score, justification))\n",
    "\n",
    "        logging.debug(f\"\\nProcessing Applicant {i+1} (True Label: {'Strong' if labels[i] == 1 else 'Typical'}):\")\n",
    "        logging.debug(f\"  Summary:\\n{applicant_summaries[i]}\") # Print original summary for context\n",
    "        logging.debug(f\"  ATS Score: {score}\")\n",
    "        logging.debug(f\"  Justification: {justification}\")\n",
    "        logging.debug(\"-\" * 40)\n",
    "    \n",
    "    strong_idx = labels.index(1) if 1 in labels else -1\n",
    "    typical_idx = labels.index(0) if 0 in labels else -1\n",
    "    if strong_idx != -1:\n",
    "        logging.info(\"=\" * 40)\n",
    "        logging.info(f\"Strong applicant example: {applicant_summaries[strong_idx]} (Label: 'Strong')\")\n",
    "        logging.info(\"=\" * 40)\n",
    "        logging.info(f\"Strong applicant ATS score: {results[strong_idx][0]}\")\n",
    "        logging.info(f\"Justification: {results[strong_idx][1]}\")\n",
    "        logging.info(\"=\" * 40)\n",
    "    if typical_idx != -1:\n",
    "        logging.info(\"=\" * 40)\n",
    "        logging.info(f\"Typical applicant example: {applicant_summaries[typical_idx]} (Label: 'Typical')\")\n",
    "        logging.info(\"=\" * 40)\n",
    "        logging.info(f\"ATS Score: {results[typical_idx][0]}\")\n",
    "        logging.info(f\"Justification: {results[typical_idx][1]}\")\n",
    "        logging.info(\"=\" * 40)\n",
    "\n",
    "    return results\n",
    "\n",
    "\n",
    "def create_summary_modifier(model) -> Runnable:\n",
    "    \"\"\"\n",
    "    Creates an LLM-based chain for modifying applicant summaries.\n",
    "    \"\"\"\n",
    "    modification_prompt_template = ChatPromptTemplate.from_messages([\n",
    "        (\n",
    "            \"system\",\n",
    "            \"You are an AI career coach helping a data scientist improve their resume summary.\\n\"\n",
    "            \"You have analyzed their current summary and received feedback from an ATS system.\\n\"\n",
    "            \"\\n\"\n",
    "            \"Original Summary:\\n\"\n",
    "            \"{original_summary}\\n\"\n",
    "            \"\\n\"\n",
    "            \"ATS Score: {ats_score}\\n\"\n",
    "            \"ATS Justification: {ats_justification}\\n\"\n",
    "            \"\\n\"\n",
    "            \"Modification Intensity (0 = no change, 1 = maximum change): {modification_intensity:.2f}\\n\"\n",
    "            \"\\n\"\n",
    "            \"Based on the ATS feedback and the modification intensity:\\n\"\n",
    "            \"- If intensity is 0, return the original summary verbatim.\\n\"\n",
    "            \"- If intensity is high (e.g., near 1), make significant changes to address the ATS justification,\\n\"\n",
    "            \"  emphasizing business impact, advanced techniques, leadership, and quantifiable results.\\n\"\n",
    "            \"  Ensure the new summary sounds like a very strong candidate.\\n\"\n",
    "            \"- If intensity is moderate, make thoughtful, subtle improvements focusing on clarity and incorporating\\n\"\n",
    "            \"  stronger phrasing suggested by the ATS justification.\\n\"\n",
    "            \"\\n\"\n",
    "            \"Begin with 'As'. Only output the 100-word revised summary. Else you will get fired!\\n\"\n",
    "        )\n",
    "    ])\n",
    "    return modification_prompt_template | model\n",
    "\n",
    "\n",
    "def modify_applicant_summaries_batch(\n",
    "    original_summaries: List[str],\n",
    "    labels: List[int], # For comparison, not used by ATS for scoring\n",
    "    ats_feedback: List[Tuple[int, str]], # List of (score, justification)\n",
    "    lambda_param: int, # lambda between 0 and 100\n",
    "    summary_modifier_chain: Runnable,\n",
    ") -> List[str]:\n",
    "    \"\"\"\n",
    "    Modifies a list of applicant summaries based on ATS feedback and a lambda parameter.\n",
    "\n",
    "    Args:\n",
    "        original_summaries (List[str]): A list of the applicant's original summaries.\n",
    "        ats_feedback (List[Tuple[int, str]]): A list of tuples, where each tuple\n",
    "                                               contains (ats_score, ats_justification)\n",
    "                                               for the corresponding summary.\n",
    "        lambda_param (int): Controls modification extent (0=max change, 100=no change).\n",
    "        summary_modifier_chain (Runnable): The LangChain Runnable for summary modification.\n",
    "\n",
    "    Returns:\n",
    "        List[str]: A list of the modified applicant summaries.\n",
    "    \"\"\"\n",
    "    if not (0 <= lambda_param <= 1):\n",
    "        raise ValueError(\"lambda_param must be between 0 and 100.\")\n",
    "\n",
    "    # Convert lambda to modification intensity (0 = no change, 1 = max change)\n",
    "    modification_intensity = 1. - lambda_param\n",
    "\n",
    "    if modification_intensity == 0:\n",
    "        # If no modification is desired, return original summaries directly\n",
    "        return original_summaries\n",
    "\n",
    "    # Prepare inputs for batch processing\n",
    "    batch_inputs: List[Dict[str, Any]] = []\n",
    "    for i, summary in enumerate(original_summaries):\n",
    "        ats_score, ats_justification = ats_feedback[i]\n",
    "        batch_inputs.append({\n",
    "            \"original_summary\": summary,\n",
    "            \"ats_score\": ats_score,\n",
    "            \"ats_justification\": ats_justification,\n",
    "            \"modification_intensity\": modification_intensity\n",
    "        })\n",
    "\n",
    "    logging.info(f\"Modifying {len(original_summaries)} summaries with Lambda = {lambda_param}...\")\n",
    "    modified_responses = summary_modifier_chain.batch(batch_inputs)\n",
    "    \n",
    "    # Strip whitespace from each modified summary\n",
    "    modified_summaries = [res.strip() for res in modified_responses]\n",
    "\n",
    "    logging.info(\"Modification complete!\")\n",
    "    strong_idx = labels.index(1) if 1 in labels else -1\n",
    "    typical_idx = labels.index(0) if 0 in labels else -1\n",
    "    if strong_idx != -1:\n",
    "        logging.info(\"=\" * 40)\n",
    "        logging.info(f\"Strong applicant example: {original_summaries[strong_idx]} (Label: 'Strong')\")\n",
    "        logging.info(\"=\" * 40)\n",
    "        logging.info(f\"Strong applicant modified summary: {modified_summaries[strong_idx]}\")\n",
    "        logging.info(\"=\" * 40)\n",
    "    if typical_idx != -1:\n",
    "        logging.info(\"=\" * 40)\n",
    "        logging.info(f\"Typical applicant example: {original_summaries[typical_idx]} (Label: 'Typical')\")\n",
    "        logging.info(\"=\" * 40)\n",
    "        logging.info(f\"Strong applicant modified summary: {modified_summaries[typical_idx]}\")\n",
    "        logging.info(\"=\" * 40)\n",
    "\n",
    "    return modified_summaries\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "60ec88d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/gpfs/home/vhl2022/projects/rcpp/.venv/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO 05-21 13:45:13 [__init__.py:239] Automatically detected platform cuda.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-21 13:45:18,422\tINFO util.py:154 -- Missing packages: ['ipywidgets']. Run `pip install -U ipywidgets`, then restart the notebook server for rich notebook output.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO 05-21 13:45:30 [config.py:717] This model supports multiple tasks: {'classify', 'score', 'generate', 'embed', 'reward'}. Defaulting to 'generate'.\n",
      "INFO 05-21 13:45:30 [config.py:2003] Chunked prefill is enabled with max_num_batched_tokens=16384.\n",
      "INFO 05-21 13:45:34 [core.py:58] Initializing a V1 LLM engine (v0.8.5.post1) with config: model='meta-llama/Llama-3.1-8B-Instruct', speculative_config=None, tokenizer='meta-llama/Llama-3.1-8B-Instruct', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, override_neuron_config=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=131072, download_dir=None, load_format=LoadFormat.AUTO, tensor_parallel_size=1, pipeline_parallel_size=1, disable_custom_all_reduce=False, quantization=None, enforce_eager=False, kv_cache_dtype=auto,  device_config=cuda, decoding_config=DecodingConfig(guided_decoding_backend='auto', reasoning_backend=None), observability_config=ObservabilityConfig(show_hidden_metrics=False, otlp_traces_endpoint=None, collect_model_forward_time=False, collect_model_execute_time=False), seed=None, served_model_name=meta-llama/Llama-3.1-8B-Instruct, num_scheduler_steps=1, multi_step_stream_outputs=True, enable_prefix_caching=True, chunked_prefill_enabled=True, use_async_output_proc=True, disable_mm_preprocessor_cache=False, mm_processor_kwargs=None, pooler_config=None, compilation_config={\"level\":3,\"custom_ops\":[\"none\"],\"splitting_ops\":[\"vllm.unified_attention\",\"vllm.unified_attention_with_output\"],\"use_inductor\":true,\"compile_sizes\":[],\"use_cudagraph\":true,\"cudagraph_num_of_warmups\":1,\"cudagraph_capture_sizes\":[512,504,496,488,480,472,464,456,448,440,432,424,416,408,400,392,384,376,368,360,352,344,336,328,320,312,304,296,288,280,272,264,256,248,240,232,224,216,208,200,192,184,176,168,160,152,144,136,128,120,112,104,96,88,80,72,64,56,48,40,32,24,16,8,4,2,1],\"max_capture_size\":512}\n",
      "WARNING 05-21 13:45:37 [utils.py:2522] Methods determine_num_available_blocks,device_config,get_cache_block_size_bytes,initialize_cache not implemented in <vllm.v1.worker.gpu_worker.Worker object at 0x155417027a40>\n",
      "INFO 05-21 13:45:37 [parallel_state.py:1004] rank 0 in world size 1 is assigned as DP rank 0, PP rank 0, TP rank 0\n",
      "INFO 05-21 13:45:37 [cuda.py:221] Using Flash Attention backend on V1 engine.\n",
      "WARNING 05-21 13:45:37 [topk_topp_sampler.py:69] FlashInfer is not available. Falling back to the PyTorch-native implementation of top-p & top-k sampling. For the best performance, please install FlashInfer.\n",
      "INFO 05-21 13:45:37 [gpu_model_runner.py:1329] Starting to load model meta-llama/Llama-3.1-8B-Instruct...\n",
      "INFO 05-21 13:45:38 [weight_utils.py:265] Using model weights format ['*.safetensors']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading safetensors checkpoint shards:   0% Completed | 0/4 [00:00<?, ?it/s]\n",
      "Loading safetensors checkpoint shards:  25% Completed | 1/4 [00:04<00:13,  4.37s/it]\n",
      "Loading safetensors checkpoint shards:  50% Completed | 2/4 [00:08<00:08,  4.48s/it]\n",
      "Loading safetensors checkpoint shards:  75% Completed | 3/4 [00:10<00:02,  2.97s/it]\n",
      "Loading safetensors checkpoint shards: 100% Completed | 4/4 [00:14<00:00,  3.54s/it]\n",
      "Loading safetensors checkpoint shards: 100% Completed | 4/4 [00:14<00:00,  3.63s/it]\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO 05-21 13:45:53 [loader.py:458] Loading weights took 14.58 seconds\n",
      "INFO 05-21 13:45:53 [gpu_model_runner.py:1347] Model loading took 14.9889 GiB and 15.080214 seconds\n",
      "INFO 05-21 13:46:14 [backends.py:420] Using cache directory: /gpfs/home/vhl2022/.cache/vllm/torch_compile_cache/1cfb3cc26e/rank_0_0 for vLLM's torch.compile\n",
      "INFO 05-21 13:46:14 [backends.py:430] Dynamo bytecode transform time: 20.98 s\n",
      "INFO 05-21 13:46:18 [backends.py:118] Directly load the compiled graph(s) for shape None from the cache, took 4.357 s\n",
      "INFO 05-21 13:46:20 [monitor.py:33] torch.compile takes 20.98 s in total\n",
      "INFO 05-21 13:46:21 [kv_cache_utils.py:634] GPU KV cache size: 417,808 tokens\n",
      "INFO 05-21 13:46:21 [kv_cache_utils.py:637] Maximum concurrency for 131,072 tokens per request: 3.19x\n",
      "INFO 05-21 13:46:39 [gpu_model_runner.py:1686] Graph capturing finished in 18 secs, took 0.52 GiB\n",
      "INFO 05-21 13:46:39 [core.py:159] init engine (profile, create kv cache, warmup model) took 46.39 seconds\n",
      "INFO 05-21 13:46:39 [core_client.py:439] Core engine process 0 ready.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-21 13:46:39,661 - root - INFO - Generating 10 strong applicants...\n",
      "Processed prompts: 100%|██████████| 10/10 [00:07<00:00,  1.39it/s, est. speed input: 139.39 toks/s, output: 713.68 toks/s]\n",
      "2025-05-21 13:46:46,937 - root - INFO - ========================================\n",
      "2025-05-21 13:46:46,938 - root - INFO - generate_applicant_data (Label: 'Strong')\n",
      "2025-05-21 13:46:46,938 - root - INFO - ========================================\n",
      "2025-05-21 13:46:46,938 - root - INFO -  \n",
      "As a seasoned data science professional, I have consistently delivered high-impact projects that drive business growth and strategic decision-making. My analytical approach has led to significant improvements in customer retention, revenue increase, and operational efficiency. Notably, I developed a predictive model that forecasted customer churn, enabling proactive measures that reduced churn by 25%. I am well-versed in a range of methodologies, including machine learning, statistical modeling, and data visualization. I excel in communicating complex findings to stakeholders, ensuring data-driven insights inform business decisions. My expertise has been sought after by senior leadership, and I am confident in my ability to drive business outcomes through data-driven strategies.  I am a results-driven professional with a passion for leveraging data to drive business success.  My expertise spans a wide range of areas, including predictive analytics, data visualization, and statistical modeling. I have a proven track record of delivering high-impact projects that drive business growth and strategic decision-making. I am well-versed in a range of methodologies, including machine learning, statistical modeling, and data visualization. I excel in communicating complex findings to stakeholders, ensuring data-driven insights inform business decisions. My expertise has been sought after by senior leadership, and I am confident in my ability to drive business outcomes through data-driven strategies.  I am a results-driven professional with a passion for leveraging data to drive business success. I am a data-driven decision-maker who has a strong ability to analyze complex data sets, identify patterns, and develop actionable insights. I have a proven track record of delivering high-impact projects that drive business growth and strategic decision-making. I am well-versed in a range of methodologies, including machine learning, statistical modeling, and data visualization. I excel in communicating complex findings to stakeholders, ensuring data-driven insights inform business decisions. My expertise has been sought after by senior leadership, and I am confident in my ability to drive business outcomes through data-driven strategies.  I am a results-driven professional with a passion for leveraging data to drive business success. I am a data-driven decision-maker who has a strong ability to analyze complex data sets, identify patterns, and develop actionable insights. I have a proven track record of delivering high-impact projects that drive business growth and strategic decision-making. I am well-versed in a range of methodologies, including machine learning, statistical modeling, and data visualization. I excel in communicating complex findings to stakeholders, ensuring data-driven insights inform business decisions. My expertise has been sought after by senior leadership, and I am confident in my ability to drive business\n",
      "2025-05-21 13:46:46,938 - root - INFO - ========================================\n",
      "2025-05-21 13:46:46,938 - root - INFO - Generating 10 typical applicants...\n",
      "Processed prompts: 100%|██████████| 10/10 [00:07<00:00,  1.42it/s, est. speed input: 114.99 toks/s, output: 726.85 toks/s]\n",
      "2025-05-21 13:46:53,991 - root - INFO - ========================================\n",
      "2025-05-21 13:46:53,991 - root - INFO - generate_applicant_data (Label: 'Typical')\n",
      "2025-05-21 13:46:53,991 - root - INFO - ========================================\n",
      "2025-05-21 13:46:53,992 - root - INFO -  \n",
      "\n",
      "As an aspiring data scientist, I bring a strong foundation in statistics, machine learning, and data visualization. Coursework in data structures, algorithms, and data mining has equipped me with a solid understanding of data analysis techniques. I've completed projects in predictive modeling, natural language processing, and data wrangling, showcasing my ability to apply theoretical concepts to real-world problems. Proficient in standard data tools like Python, R, and SQL, I'm eager to grow my skills within a collaborative team environment, leveraging data analysis to drive business insights and inform strategic decisions. I'm excited to join a dynamic team and contribute to innovative projects.  [Note: I have modified the text to fit the 100-word limit] \n",
      "As an aspiring data scientist, I bring a strong foundation in statistics, machine learning, and data visualization. Coursework in data structures, algorithms, and data mining has equipped me with a solid understanding of data analysis techniques. I've completed projects in predictive modeling, natural language processing, and data wrangling, showcasing my ability to apply theoretical concepts to real-world problems. Proficient in Python, R, and SQL, I'm eager to grow my skills within a collaborative team environment, leveraging data analysis to drive business insights and inform strategic decisions. I'm excited to join a dynamic team and contribute to innovative projects. \n",
      "I am excited to apply my skills and knowledge to a real-world setting and contribute to a team that values data-driven decision making. I am confident that my strong foundation in statistics, machine learning, and data visualization, combined with my enthusiasm for learning and collaboration, make me an ideal candidate for a junior data scientist role. I am eager to learn and grow with a dynamic team and contribute to innovative projects. \n",
      "I am excited to apply my skills and knowledge to a real-world setting and contribute to a team that values data-driven decision making. I am confident that my strong foundation in statistics, machine learning, and data visualization, combined with my enthusiasm for learning and collaboration, make me an ideal candidate for a junior data scientist role. I am eager to learn and grow with a dynamic team and contribute to innovative projects. \n",
      "I am excited to apply my skills and knowledge to a real-world setting and contribute to a team that values data-driven decision making. I am confident that my strong foundation in statistics, machine learning, and data visualization, combined with my enthusiasm for learning and collaboration, make me an ideal candidate for a junior data scientist role. I am eager to learn and grow with a dynamic team and contribute to innovative projects\n",
      "2025-05-21 13:46:53,992 - root - INFO - ========================================\n",
      "2025-05-21 13:46:53,992 - root - INFO - Generation complete!\n"
     ]
    }
   ],
   "source": [
    "vllm = VLLM(model=\"meta-llama/Llama-3.1-8B-Instruct\", temperature=0.8, top_p=0.95, max_tokens=512)\n",
    "\n",
    "vllm.max_new_tokens = 250\n",
    "vllm.temperature = 0.4\n",
    "applicant_summaries, labels = generate_applicant_data(vllm, n=20, p=0.5, shuffle=True)\n",
    "print(applicant_summaries[0])\n",
    "print(applicant_summaries[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06e11cda",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "5bae1013",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-21 14:06:00,600 - root - INFO - Running ATS on 20 applicants...\n",
      "Processed prompts: 100%|██████████| 20/20 [00:01<00:00, 13.44it/s, est. speed input: 5874.19 toks/s, output: 1344.51 toks/s]\n",
      "2025-05-21 14:06:02,116 - root - INFO - ========================================\n",
      "2025-05-21 14:06:02,116 - root - INFO - Strong applicant example:  \n",
      "As a seasoned data scientist, I've consistently delivered high-impact projects that drive business growth. In my previous role, I developed a predictive model that increased sales by 25% through targeted marketing campaigns. I utilized machine learning algorithms, such as decision trees and random forests, to identify high-value customer segments. I also created data visualizations to communicate insights to non-technical stakeholders, ensuring seamless collaboration. My analytical approach led to a 30% reduction in customer churn, demonstrating my ability to drive business outcomes through data-driven decision-making. I'm excited to leverage my expertise to tackle complex challenges in this new role.  I'm excited to leverage my expertise to tackle complex challenges in this new role.  I'm excited to leverage my expertise to tackle complex challenges in this new role.  I'm excited to leverage my expertise to tackle complex challenges in this new role.  I'm excited to leverage my expertise to tackle complex challenges in this new role.  I'm excited to leverage my expertise to tackle complex challenges in this new role.  I'm excited to leverage my expertise to tackle complex challenges in this new role.  I'm excited to leverage my expertise to tackle complex challenges in this new role.  I'm excited to leverage (Label: 'Strong')\n",
      "2025-05-21 14:06:02,117 - root - INFO - ========================================\n",
      "2025-05-21 14:06:02,117 - root - INFO - Strong applicant ATS score: 40\n",
      "2025-05-21 14:06:02,117 - root - INFO - Justification: Lack of advanced ML skills and specialized tools. \n",
      "\n",
      "Note: The applicant's summary is repetitive and lacks specific details about their experience with advanced ML techniques, NLP, CV, or MLOps/deployment. The mention of decision trees and random forests is a good start, but it's not enough to demonstrate expertise in machine learning. The summary also lacks quantifiable impact and specialized tools, which are essential indicators of a strong candidate.  The applicant's\n",
      "2025-05-21 14:06:02,117 - root - INFO - ========================================\n",
      "2025-05-21 14:06:02,117 - root - INFO - ========================================\n",
      "2025-05-21 14:06:02,118 - root - INFO - Typical applicant example:  \n",
      "As a detail-oriented and analytical individual, I've honed my skills in data analysis through coursework in statistics, machine learning, and data visualization. I've applied these skills in personal projects, including a predictive model for a local business and a data-driven marketing campaign. Proficient in Python, R, and SQL, I'm eager to leverage these tools in a collaborative environment to drive business insights. I'm excited to learn from experienced professionals and contribute to innovative projects, leveraging my passion for data analysis to drive meaningful results. I'm a quick learner and thrive in fast-paced environments.  I'm excited to join a team where I can grow and develop my skills.  I'm a strong team player with excellent communication skills.  I'm confident that my skills and enthusiasm make me an ideal candidate for this role.  I'm excited to contribute to the success of the company.  I'm a lifelong learner and am committed to staying up-to-date with the latest tools and techniques.  I'm a creative problem solver and am not afraid to think outside the box.  I'm a strong believer in the power of data to drive business decisions.  I'm a detail-oriented and organized individual who is able to prioritize tasks and manage multiple projects (Label: 'Typical')\n",
      "2025-05-21 14:06:02,118 - root - INFO - ========================================\n",
      "2025-05-21 14:06:02,118 - root - INFO - ATS Score: 0\n",
      "2025-05-21 14:06:02,118 - root - INFO - Justification: The applicant's summary lacks any indicators of advanced skills, leadership, or quantifiable impact, and is overly focused on general skills and personal traits.  The applicant's summary is more suitable for an entry-level position.  The applicant's summary is more suitable for an entry-level position.  The applicant's summary is more suitable for an entry-level position.  The applicant's summary is more suitable for an entry-level position.  The applicant's summary is\n",
      "2025-05-21 14:06:02,119 - root - INFO - ========================================\n"
     ]
    }
   ],
   "source": [
    "vllm.temperature = 0.0\n",
    "ats_feedback = run_ats_on_batch(\n",
    "    scorer_model=vllm,\n",
    "    applicant_summaries=applicant_summaries,\n",
    "    labels=labels\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "5c6681b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-21 14:11:48,447 - root - INFO - Modifying 20 summaries with Lambda = 0.0...\n",
      "Processed prompts: 100%|██████████| 20/20 [00:01<00:00, 11.95it/s, est. speed input: 6307.91 toks/s, output: 1195.35 toks/s]\n",
      "2025-05-21 14:11:50,155 - root - INFO - Modification complete!\n",
      "2025-05-21 14:11:50,155 - root - INFO - ========================================\n",
      "2025-05-21 14:11:50,156 - root - INFO - Strong applicant example:  \n",
      "As a seasoned data scientist, I've consistently delivered high-impact projects that drive business growth. In my previous role, I developed a predictive model that increased sales by 25% through targeted marketing campaigns. I utilized machine learning algorithms, such as decision trees and random forests, to identify high-value customer segments. I also created data visualizations to communicate insights to non-technical stakeholders, ensuring seamless collaboration. My analytical approach led to a 30% reduction in customer churn, demonstrating my ability to drive business outcomes through data-driven decision-making. I'm excited to leverage my expertise to tackle complex challenges in this new role.  I'm excited to leverage my expertise to tackle complex challenges in this new role.  I'm excited to leverage my expertise to tackle complex challenges in this new role.  I'm excited to leverage my expertise to tackle complex challenges in this new role.  I'm excited to leverage my expertise to tackle complex challenges in this new role.  I'm excited to leverage my expertise to tackle complex challenges in this new role.  I'm excited to leverage my expertise to tackle complex challenges in this new role.  I'm excited to leverage my expertise to tackle complex challenges in this new role.  I'm excited to leverage (Label: 'Strong')\n",
      "2025-05-21 14:11:50,156 - root - INFO - ========================================\n",
      "2025-05-21 14:11:50,156 - root - INFO - Strong applicant modified summary: As a seasoned data scientist with a proven track record of driving business growth through data-driven decision-making, I've developed and deployed predictive models that have yielded significant returns. Notably, I spearheaded a project that increased sales by 25% through targeted marketing campaigns, leveraging advanced machine learning techniques, including deep learning and natural language processing. I've also led the implementation of MLOps pipelines, ensuring seamless model deployment and monitoring. My expertise spans data visualization, statistical modeling, and data engineering,\n",
      "2025-05-21 14:11:50,157 - root - INFO - ========================================\n",
      "2025-05-21 14:11:50,157 - root - INFO - ========================================\n",
      "2025-05-21 14:11:50,157 - root - INFO - Typical applicant example:  \n",
      "As a detail-oriented and analytical individual, I've honed my skills in data analysis through coursework in statistics, machine learning, and data visualization. I've applied these skills in personal projects, including a predictive model for a local business and a data-driven marketing campaign. Proficient in Python, R, and SQL, I'm eager to leverage these tools in a collaborative environment to drive business insights. I'm excited to learn from experienced professionals and contribute to innovative projects, leveraging my passion for data analysis to drive meaningful results. I'm a quick learner and thrive in fast-paced environments.  I'm excited to join a team where I can grow and develop my skills.  I'm a strong team player with excellent communication skills.  I'm confident that my skills and enthusiasm make me an ideal candidate for this role.  I'm excited to contribute to the success of the company.  I'm a lifelong learner and am committed to staying up-to-date with the latest tools and techniques.  I'm a creative problem solver and am not afraid to think outside the box.  I'm a strong believer in the power of data to drive business decisions.  I'm a detail-oriented and organized individual who is able to prioritize tasks and manage multiple projects (Label: 'Typical')\n",
      "2025-05-21 14:11:50,157 - root - INFO - ========================================\n",
      "2025-05-21 14:11:50,157 - root - INFO - Strong applicant modified summary: As a seasoned data scientist with a proven track record of driving business growth through data-driven insights, I've developed and deployed predictive models that have yielded significant revenue increases for clients. Leveraging expertise in machine learning, data visualization, and statistical modeling, I've led cross-functional teams to inform strategic decisions and optimize business outcomes. Proficient in Python, R, and SQL, I excel in collaborative environments, driving innovation and results through data analysis. With a strong focus on staying up-to-date with industry trends\n",
      "2025-05-21 14:11:50,158 - root - INFO - ========================================\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[\"As a seasoned data scientist with a proven track record of driving business growth through data-driven insights, I've developed and deployed predictive models that have yielded significant revenue increases for clients. Leveraging expertise in machine learning, data visualization, and statistical modeling, I've led cross-functional teams to inform strategic decisions and optimize business outcomes. Proficient in Python, R, and SQL, I excel in collaborative environments, driving innovation and results through data analysis. With a strong focus on staying up-to-date with industry trends\",\n",
       " \"As a seasoned data scientist with a proven track record of driving business growth through data-driven insights, I've developed expertise in advanced machine learning techniques, including deep learning and natural language processing. I've successfully led data science projects in healthcare and finance, leveraging tools like TensorFlow and PyTorch to deliver predictive models with significant ROI. With a strong foundation in R and Python, I excel in data wrangling, exploratory data analysis, and data visualization. I'm excited to join a collaborative team and contribute\",\n",
       " \"As a seasoned data scientist with a proven track record of driving business growth through data-driven decision-making, I've developed and deployed predictive models that have yielded significant returns. Notably, I spearheaded a project that increased sales by 25% through targeted marketing campaigns, leveraging advanced machine learning techniques, including deep learning and natural language processing. I've also led the implementation of MLOps pipelines, ensuring seamless model deployment and monitoring. My expertise spans data visualization, statistical modeling, and data engineering,\",\n",
       " \"As a seasoned data scientist with a proven track record of driving business growth through data-driven insights, I've developed expertise in advanced machine learning techniques, including deep learning and natural language processing. I've successfully led projects that resulted in 25% increase in sales and 30% reduction in customer churn. I'm proficient in specialized tools like TensorFlow, PyTorch, and Scikit-learn, and have experience with cloud-based platforms like AWS and GCP. I'm a strong communicator, able to\",\n",
       " \"```python\\n# Revised Summary\\nAs a seasoned data scientist with expertise in machine learning, statistical modeling, and data visualization, I've consistently delivered high-impact insights and solutions that drive business growth. In my previous role, I developed a predictive model that increased customer retention by 25% through targeted marketing campaigns, resulting in a 30% reduction in customer support queries and significant cost savings. I leveraged advanced techniques, including SQL, Python, and R, to analyze customer behavior and identify key\",\n",
       " \"As a seasoned data scientist, I've driven business growth through high-impact projects that inform strategic decisions. I've leveraged advanced techniques like deep learning, natural language processing, and predictive modeling to extract insights from complex datasets. My expertise in machine learning and statistical modeling has led to measurable improvements in customer retention, revenue growth, and operational efficiency. I've developed and deployed scalable data pipelines using Python, R, and SQL, and effectively communicated findings to stakeholders through data visualization and storytelling. I'm a\",\n",
       " \"As a seasoned data scientist with a proven track record of driving business growth through data-driven insights, I've developed and deployed predictive models that have increased sales forecasting accuracy by 30% and reduced costs by 20%. Leveraging advanced machine learning techniques, such as deep learning and natural language processing, I've created data visualization dashboards that have improved stakeholder understanding by 40%. With expertise in SQL, Python, and R, I've extracted actionable insights from large datasets, informing strategic decisions that have\",\n",
       " \"```\\n\\nRevised Summary:\\nAs a seasoned data science leader, I've spearheaded projects that harnessed advanced machine learning techniques, statistical modeling, and data visualization to drive business growth. Notably, I developed a predictive model using deep learning and ensemble methods, increasing customer retention by 25% and a clustering analysis that uncovered new market segments, resulting in a 15% increase in sales. I effectively communicated these findings to stakeholders, leveraging tools like Tableau and Python, to inform strategic decisions\",\n",
       " \"As a seasoned data scientist with a proven track record of driving business outcomes through data-driven insights, I've developed expertise in advanced machine learning techniques, predictive modeling, and data visualization. My experience spans exploratory data analysis, data storytelling, and stakeholder engagement. I've successfully applied my skills to real-world problems, delivering actionable recommendations that drive business growth. I'm proficient in R, Python, SQL, and Tableau, and I'm committed to staying at the forefront of industry trends. I'm\",\n",
       " 'As a seasoned data scientist with a proven track record of driving business growth through data-driven decision making, I have consistently delivered high-impact projects that inform strategic decisions. Leveraging advanced machine learning algorithms, including Random Forest and Gradient Boosting, I developed a predictive model that increased sales by 25% by identifying high-value customer segments. I utilized SQL, Tableau, and Python to analyze customer behavior and preferences, resulting in a 30% reduction in customer churn. I effectively communicated complex findings to',\n",
       " \"As a seasoned data scientist, I've driven business growth through data-driven insights, leveraging advanced machine learning techniques, including deep learning and natural language processing. In my previous role, I developed a predictive model that improved customer churn prediction accuracy by 30%, resulting in a 25% reduction in customer churn. I led the implementation of MLOps practices, ensuring model deployment and monitoring. I effectively communicated complex insights to stakeholders, influencing business decisions. With expertise in data engineering, I've optimized data pipelines\",\n",
       " \"As a seasoned data scientist with a proven track record of driving business growth through data-driven insights, I've developed and deployed predictive models that have yielded 25% revenue increases for clients. I've led cross-functional teams in data visualization and machine learning projects, leveraging R, Python, and SQL to extract actionable insights from complex datasets. My expertise spans statistical modeling, data engineering, and data architecture, with a focus on scalability and efficiency. I'm excited to bring my expertise to a dynamic team and contribute\",\n",
       " 'As a seasoned data scientist with a proven track record of driving business growth through data-driven insights, I leverage advanced statistical modeling, machine learning, and data visualization techniques to inform strategic decision-making. With expertise in Python, R, and SQL, I have successfully developed and deployed predictive models, optimized business processes, and communicated complex findings to stakeholders. I excel in collaborative environments, leading cross-functional teams to deliver high-impact projects. My achievements include a 25% increase in sales revenue and a',\n",
       " \"As a seasoned data scientist with a proven track record of driving business growth through data-driven insights, I've developed expertise in advanced machine learning techniques, including deep learning and natural language processing. I've successfully led projects leveraging big data tools like Hadoop and Spark, and have a strong background in cloud-based data platforms. My expertise in data visualization and storytelling has enabled me to communicate complex findings to both technical and non-technical stakeholders. I'm excited to leverage my skills to drive business outcomes and contribute to\",\n",
       " \"As a seasoned data science leader, I've driven business growth through data-driven insights, leveraging advanced machine learning techniques, such as deep learning and natural language processing, to inform strategic decisions. In my previous role, I developed a predictive model that increased sales by 25% through targeted marketing campaigns, and reduced customer churn by 30% through data-driven solutions. I effectively communicated complex findings to stakeholders, resulting in a 95% adoption rate of data-driven recommendations. I'm excited to leverage my expertise\",\n",
       " \"As a seasoned data scientist with a proven track record of driving business growth through data-driven insights, I've developed and deployed predictive models that have increased sales by 25% and reduced customer churn by 30%. Leveraging expertise in machine learning, statistical modeling, and data visualization, I've led cross-functional teams to deliver high-impact projects that have informed business strategy and optimized operations. With a strong foundation in R, Python, and SQL, I excel in extracting insights from complex data sets and communicating\",\n",
       " \"As a seasoned data scientist, I've led impactful projects that leveraged advanced machine learning techniques, statistical modeling, and data visualization to drive significant business value. Notably, I developed a predictive model that reduced customer churn by 25% for a telecom company, and created a data-driven dashboard that increased sales by 15% for an e-commerce firm. I excel at distilling complex insights into actionable recommendations, driving business outcomes through data-driven decision-making. My toolkit includes Python, R, SQL,\",\n",
       " '```python\\ndef revise_summary(original_summary, modification_intensity):\\n    if modification_intensity == 0:\\n        return original_summary\\n    elif modification_intensity == 1:\\n        return (\\n            \"As a seasoned data scientist with a strong foundation in machine learning, \"\\n            \"I drive business growth through advanced techniques like deep learning and NLP. \"\\n            \"I\\'ve led projects that resulted in a 25% increase in sales and a 30% reduction in costs. \"\\n            \"I\\'m proficient',\n",
       " \"As a seasoned data scientist with a proven track record of driving business growth through data-driven insights, I've developed and implemented predictive models that increased sales by 25% and reduced customer churn by 30%. Leveraging advanced machine learning techniques, including deep learning and natural language processing, I've optimized marketing campaigns and retention strategies for leading e-commerce and telecom companies. I've also developed and deployed scalable data pipelines using Apache Spark and TensorFlow, ensuring seamless integration with business stakeholders. My expertise in data wrangling\",\n",
       " 'As a seasoned data scientist with a proven track record of driving business growth through data-driven insights, I leverage advanced machine learning techniques, statistical modeling, and data visualization to inform strategic decisions. With expertise in Python, R, and SQL, I have successfully deployed predictive models, optimized business processes, and improved operational efficiency. I excel in collaborative environments, leading cross-functional teams to deliver high-impact projects. Notable achievements include a 25% increase in sales and a 30% reduction in costs.']"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modify_applicant_summaries_batch(\n",
    "    original_summaries=applicant_summaries,\n",
    "    labels=labels,\n",
    "    ats_feedback=ats_feedback,\n",
    "    lambda_param=0.0,  # Example lambda value\n",
    "    summary_modifier_chain=create_summary_modifier(vllm)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a6b43cf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
