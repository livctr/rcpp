{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8c4ded7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "from langchain_vllm\n",
    "from langchain_ollama import OllamaLLM\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_core.runnables import Runnable\n",
    "import re\n",
    "from typing import List, Tuple\n",
    "\n",
    "from langchain_ollama import OllamaLLM\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_core.runnables import Runnable\n",
    "\n",
    "\n",
    "def generate_applicant_data(model, n: int, p: float, shuffle: bool = True):\n",
    "    \"\"\"\n",
    "    Generates a dataset of data science applicant summaries and their labels.\n",
    "\n",
    "    Args:\n",
    "        n (int): The total number of applicant summaries to generate.\n",
    "        p (float): The probability (0.0 to 1.0) of generating a strong applicant.\n",
    "        shuffle (bool): Whether to shuffle the generated data (X and y) together.\n",
    "\n",
    "    Returns:\n",
    "        tuple: A tuple containing two lists:\n",
    "            - X (list): A list of applicant summary strings.\n",
    "            - y (list): A list of labels (1 for strong, 0 for typical).\n",
    "    \"\"\"\n",
    "\n",
    "    strong_applicant_prompt = PromptTemplate.from_template(\n",
    "        \"You are a data science professional articulating your suitability for a challenging data science role. \"\n",
    "        \"In 100 words, outline your key contributions to data-driven projects, focusing on how your \"\n",
    "        \"analytical approach led to measurable improvements or novel insights. Briefly mention your \"\n",
    "        \"familiarity with diverse methodologies, tools, problem-solving abilities, and your ability to \"\n",
    "        \"communicate complex findings to non-technical stakeholders. Feel free to focus on specifics in \"\n",
    "        \"how you have turned data into actionable intelligence.\"\n",
    "    )\n",
    "\n",
    "    typical_applicant_prompt = PromptTemplate.from_template(\n",
    "        \"You are an aspiring data scientist outlining your qualifications for an entry-level or junior role. \"\n",
    "        \"In 100 words, outline your key qualifications, including relevant coursework, projects, or prior experience. \"\n",
    "        \"Highlight your enthusiasm for learning and applying data analysis techniques to real-world problems. \"\n",
    "        \"Mention your comfort with standard data tools and a desire to grow your skills within a collaborative team environment.\"\n",
    "    )\n",
    "\n",
    "    X = []  # List to store applicant summaries\n",
    "    y = []  # List to store labels (1 for strong, 0 for typical)\n",
    "\n",
    "    # Create chains for each prompt\n",
    "    strong_chain: Runnable = strong_applicant_prompt | model\n",
    "    typical_chain: Runnable = typical_applicant_prompt | model\n",
    "\n",
    "    # Determine the number of strong and typical applicants\n",
    "    num_strong = round(n * p)\n",
    "    num_typical = n - num_strong\n",
    "\n",
    "    # Generate strong applicants\n",
    "    if num_strong > 0:\n",
    "        print(f\"Generating {num_strong} strong applicants...\")\n",
    "        strong_inputs = [{} for _ in range(num_strong)] # Empty dictionaries as input since prompts are self-contained\n",
    "        strong_results = strong_chain.batch(strong_inputs)\n",
    "        X.extend(strong_results)\n",
    "        y.extend([1] * num_strong)\n",
    "\n",
    "    # Generate typical applicants\n",
    "    if num_typical > 0:\n",
    "        print(f\"Generating {num_typical} typical applicants...\")\n",
    "        typical_inputs = [{} for _ in range(num_typical)]\n",
    "        typical_results = typical_chain.batch(typical_inputs)\n",
    "        X.extend(typical_results)\n",
    "        y.extend([0] * num_typical)\n",
    "\n",
    "    # Combine and shuffle if requested\n",
    "    if shuffle:\n",
    "        combined_data = list(zip(X, y))\n",
    "        random.shuffle(combined_data)\n",
    "        X, y = zip(*combined_data) # Unzip the shuffled data\n",
    "        X = list(X)\n",
    "        y = list(y)\n",
    "\n",
    "    print(\"Generation complete!\")\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0d663a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/gpfs/home/vhl2022/projects/rcpp\n"
     ]
    }
   ],
   "source": [
    "%cd ../.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "58db8312",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Trajectory(lambda_hat=0.0, num_iterations=1, final_risk=0.6000, guaranteed_T=-1, delta_lambda=-1.000000)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "import rcpp\n",
    "\n",
    "import pickle\n",
    "with open(\"./applications/application_tracking_system/figures/expected_loss/trajectory_0.pkl\", \"rb\") as f:\n",
    "    trajectory = pickle.load(f)\n",
    "trajectory\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7a7a8199",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0.])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trajectory.lambdas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e9078e93",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0.6]), array([0.6, 0.6]))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trajectory.risks_tm1_t, trajectory.risks_tt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "58e92457",
   "metadata": {},
   "outputs": [],
   "source": [
    "ollama_model = OllamaLLM(model=\"llama3.2\", temperature=1.0, max_tokens=250)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "cc6ef51d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating 2 typical applicants...\n"
     ]
    },
    {
     "ename": "ConnectError",
     "evalue": "[Errno 111] Connection refused",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mConnectError\u001b[39m                              Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32m~/projects/rcpp/.venv/lib/python3.12/site-packages/httpx/_transports/default.py:101\u001b[39m, in \u001b[36mmap_httpcore_exceptions\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m    100\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m101\u001b[39m     \u001b[38;5;28;01myield\u001b[39;00m\n\u001b[32m    102\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/projects/rcpp/.venv/lib/python3.12/site-packages/httpx/_transports/default.py:250\u001b[39m, in \u001b[36mHTTPTransport.handle_request\u001b[39m\u001b[34m(self, request)\u001b[39m\n\u001b[32m    249\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m map_httpcore_exceptions():\n\u001b[32m--> \u001b[39m\u001b[32m250\u001b[39m     resp = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_pool\u001b[49m\u001b[43m.\u001b[49m\u001b[43mhandle_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreq\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    252\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(resp.stream, typing.Iterable)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/projects/rcpp/.venv/lib/python3.12/site-packages/httpcore/_sync/connection_pool.py:256\u001b[39m, in \u001b[36mConnectionPool.handle_request\u001b[39m\u001b[34m(self, request)\u001b[39m\n\u001b[32m    255\u001b[39m     \u001b[38;5;28mself\u001b[39m._close_connections(closing)\n\u001b[32m--> \u001b[39m\u001b[32m256\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m exc \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    258\u001b[39m \u001b[38;5;66;03m# Return the response. Note that in this case we still have to manage\u001b[39;00m\n\u001b[32m    259\u001b[39m \u001b[38;5;66;03m# the point at which the response is closed.\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/projects/rcpp/.venv/lib/python3.12/site-packages/httpcore/_sync/connection_pool.py:236\u001b[39m, in \u001b[36mConnectionPool.handle_request\u001b[39m\u001b[34m(self, request)\u001b[39m\n\u001b[32m    234\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    235\u001b[39m     \u001b[38;5;66;03m# Send the request on the assigned connection.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m236\u001b[39m     response = \u001b[43mconnection\u001b[49m\u001b[43m.\u001b[49m\u001b[43mhandle_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    237\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpool_request\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrequest\u001b[49m\n\u001b[32m    238\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    239\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m ConnectionNotAvailable:\n\u001b[32m    240\u001b[39m     \u001b[38;5;66;03m# In some cases a connection may initially be available to\u001b[39;00m\n\u001b[32m    241\u001b[39m     \u001b[38;5;66;03m# handle a request, but then become unavailable.\u001b[39;00m\n\u001b[32m    242\u001b[39m     \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[32m    243\u001b[39m     \u001b[38;5;66;03m# In this case we clear the connection and try again.\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/projects/rcpp/.venv/lib/python3.12/site-packages/httpcore/_sync/connection.py:101\u001b[39m, in \u001b[36mHTTPConnection.handle_request\u001b[39m\u001b[34m(self, request)\u001b[39m\n\u001b[32m    100\u001b[39m     \u001b[38;5;28mself\u001b[39m._connect_failed = \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m101\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m exc\n\u001b[32m    103\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._connection.handle_request(request)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/projects/rcpp/.venv/lib/python3.12/site-packages/httpcore/_sync/connection.py:78\u001b[39m, in \u001b[36mHTTPConnection.handle_request\u001b[39m\u001b[34m(self, request)\u001b[39m\n\u001b[32m     77\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._connection \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m78\u001b[39m     stream = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_connect\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     80\u001b[39m     ssl_object = stream.get_extra_info(\u001b[33m\"\u001b[39m\u001b[33mssl_object\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/projects/rcpp/.venv/lib/python3.12/site-packages/httpcore/_sync/connection.py:124\u001b[39m, in \u001b[36mHTTPConnection._connect\u001b[39m\u001b[34m(self, request)\u001b[39m\n\u001b[32m    123\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m Trace(\u001b[33m\"\u001b[39m\u001b[33mconnect_tcp\u001b[39m\u001b[33m\"\u001b[39m, logger, request, kwargs) \u001b[38;5;28;01mas\u001b[39;00m trace:\n\u001b[32m--> \u001b[39m\u001b[32m124\u001b[39m     stream = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_network_backend\u001b[49m\u001b[43m.\u001b[49m\u001b[43mconnect_tcp\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    125\u001b[39m     trace.return_value = stream\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/projects/rcpp/.venv/lib/python3.12/site-packages/httpcore/_backends/sync.py:207\u001b[39m, in \u001b[36mSyncBackend.connect_tcp\u001b[39m\u001b[34m(self, host, port, timeout, local_address, socket_options)\u001b[39m\n\u001b[32m    202\u001b[39m exc_map: ExceptionMapping = {\n\u001b[32m    203\u001b[39m     socket.timeout: ConnectTimeout,\n\u001b[32m    204\u001b[39m     \u001b[38;5;167;01mOSError\u001b[39;00m: ConnectError,\n\u001b[32m    205\u001b[39m }\n\u001b[32m--> \u001b[39m\u001b[32m207\u001b[39m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mwith\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mmap_exceptions\u001b[49m\u001b[43m(\u001b[49m\u001b[43mexc_map\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m    208\u001b[39m \u001b[43m    \u001b[49m\u001b[43msock\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43msocket\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcreate_connection\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    209\u001b[39m \u001b[43m        \u001b[49m\u001b[43maddress\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    210\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    211\u001b[39m \u001b[43m        \u001b[49m\u001b[43msource_address\u001b[49m\u001b[43m=\u001b[49m\u001b[43msource_address\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    212\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/share/uv/python/cpython-3.12.0-linux-x86_64-gnu/lib/python3.12/contextlib.py:155\u001b[39m, in \u001b[36m_GeneratorContextManager.__exit__\u001b[39m\u001b[34m(self, typ, value, traceback)\u001b[39m\n\u001b[32m    154\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m155\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mgen\u001b[49m\u001b[43m.\u001b[49m\u001b[43mthrow\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    156\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[32m    157\u001b[39m     \u001b[38;5;66;03m# Suppress StopIteration *unless* it's the same exception that\u001b[39;00m\n\u001b[32m    158\u001b[39m     \u001b[38;5;66;03m# was passed to throw().  This prevents a StopIteration\u001b[39;00m\n\u001b[32m    159\u001b[39m     \u001b[38;5;66;03m# raised inside the \"with\" statement from being suppressed.\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/projects/rcpp/.venv/lib/python3.12/site-packages/httpcore/_exceptions.py:14\u001b[39m, in \u001b[36mmap_exceptions\u001b[39m\u001b[34m(map)\u001b[39m\n\u001b[32m     13\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(exc, from_exc):\n\u001b[32m---> \u001b[39m\u001b[32m14\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m to_exc(exc) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mexc\u001b[39;00m\n\u001b[32m     15\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m\n",
      "\u001b[31mConnectError\u001b[39m: [Errno 111] Connection refused",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[31mConnectError\u001b[39m                              Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32m<timed exec>:1\u001b[39m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 67\u001b[39m, in \u001b[36mgenerate_applicant_data\u001b[39m\u001b[34m(model, n, p, shuffle)\u001b[39m\n\u001b[32m     65\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mGenerating \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnum_typical\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m typical applicants...\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     66\u001b[39m typical_inputs = [{} \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(num_typical)]\n\u001b[32m---> \u001b[39m\u001b[32m67\u001b[39m typical_results = \u001b[43mtypical_chain\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtypical_inputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     68\u001b[39m X.extend(typical_results)\n\u001b[32m     69\u001b[39m y.extend([\u001b[32m0\u001b[39m] * num_typical)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/projects/rcpp/.venv/lib/python3.12/site-packages/langchain_core/runnables/base.py:3024\u001b[39m, in \u001b[36mRunnableSequence.batch\u001b[39m\u001b[34m(self, inputs, config, return_exceptions, **kwargs)\u001b[39m\n\u001b[32m   3022\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   3023\u001b[39m         \u001b[38;5;28;01mfor\u001b[39;00m i, step \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(\u001b[38;5;28mself\u001b[39m.steps):\n\u001b[32m-> \u001b[39m\u001b[32m3024\u001b[39m             inputs = \u001b[43mstep\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   3025\u001b[39m \u001b[43m                \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3026\u001b[39m \u001b[43m                \u001b[49m\u001b[43m[\u001b[49m\n\u001b[32m   3027\u001b[39m \u001b[43m                    \u001b[49m\u001b[38;5;66;43;03m# each step a child run of the corresponding root run\u001b[39;49;00m\n\u001b[32m   3028\u001b[39m \u001b[43m                    \u001b[49m\u001b[43mpatch_config\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   3029\u001b[39m \u001b[43m                        \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrm\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_child\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43mf\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mseq:step:\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mi\u001b[49m\u001b[43m+\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m   3030\u001b[39m \u001b[43m                    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   3031\u001b[39m \u001b[43m                    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mrm\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mzip\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mrun_managers\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfigs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   3032\u001b[39m \u001b[43m                \u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3033\u001b[39m \u001b[43m                \u001b[49m\u001b[43mreturn_exceptions\u001b[49m\u001b[43m=\u001b[49m\u001b[43mreturn_exceptions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3034\u001b[39m \u001b[43m                \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m \u001b[49m\u001b[43m==\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3035\u001b[39m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   3037\u001b[39m \u001b[38;5;66;03m# finish the root runs\u001b[39;00m\n\u001b[32m   3038\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/projects/rcpp/.venv/lib/python3.12/site-packages/langchain_core/language_models/llms.py:449\u001b[39m, in \u001b[36mBaseLLM.batch\u001b[39m\u001b[34m(self, inputs, config, return_exceptions, **kwargs)\u001b[39m\n\u001b[32m    447\u001b[39m             \u001b[38;5;28;01mreturn\u001b[39;00m cast(List[\u001b[38;5;28mstr\u001b[39m], [e \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m inputs])\n\u001b[32m    448\u001b[39m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m449\u001b[39m             \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[32m    450\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    451\u001b[39m     batches = [\n\u001b[32m    452\u001b[39m         inputs[i : i + max_concurrency]\n\u001b[32m    453\u001b[39m         \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[32m0\u001b[39m, \u001b[38;5;28mlen\u001b[39m(inputs), max_concurrency)\n\u001b[32m    454\u001b[39m     ]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/projects/rcpp/.venv/lib/python3.12/site-packages/langchain_core/language_models/llms.py:436\u001b[39m, in \u001b[36mBaseLLM.batch\u001b[39m\u001b[34m(self, inputs, config, return_exceptions, **kwargs)\u001b[39m\n\u001b[32m    434\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m max_concurrency \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    435\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m436\u001b[39m         llm_result = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mgenerate_prompt\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    437\u001b[39m \u001b[43m            \u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_convert_input\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    438\u001b[39m \u001b[43m            \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m=\u001b[49m\u001b[43m[\u001b[49m\u001b[43mc\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcallbacks\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mc\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    439\u001b[39m \u001b[43m            \u001b[49m\u001b[43mtags\u001b[49m\u001b[43m=\u001b[49m\u001b[43m[\u001b[49m\u001b[43mc\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtags\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mc\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    440\u001b[39m \u001b[43m            \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[43m=\u001b[49m\u001b[43m[\u001b[49m\u001b[43mc\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmetadata\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mc\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    441\u001b[39m \u001b[43m            \u001b[49m\u001b[43mrun_name\u001b[49m\u001b[43m=\u001b[49m\u001b[43m[\u001b[49m\u001b[43mc\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mrun_name\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mc\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    442\u001b[39m \u001b[43m            \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    443\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    444\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m [g[\u001b[32m0\u001b[39m].text \u001b[38;5;28;01mfor\u001b[39;00m g \u001b[38;5;129;01min\u001b[39;00m llm_result.generations]\n\u001b[32m    445\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/projects/rcpp/.venv/lib/python3.12/site-packages/langchain_core/language_models/llms.py:750\u001b[39m, in \u001b[36mBaseLLM.generate_prompt\u001b[39m\u001b[34m(self, prompts, stop, callbacks, **kwargs)\u001b[39m\n\u001b[32m    742\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mgenerate_prompt\u001b[39m(\n\u001b[32m    743\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m    744\u001b[39m     prompts: List[PromptValue],\n\u001b[32m   (...)\u001b[39m\u001b[32m    747\u001b[39m     **kwargs: Any,\n\u001b[32m    748\u001b[39m ) -> LLMResult:\n\u001b[32m    749\u001b[39m     prompt_strings = [p.to_string() \u001b[38;5;28;01mfor\u001b[39;00m p \u001b[38;5;129;01min\u001b[39;00m prompts]\n\u001b[32m--> \u001b[39m\u001b[32m750\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprompt_strings\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/projects/rcpp/.venv/lib/python3.12/site-packages/langchain_core/language_models/llms.py:944\u001b[39m, in \u001b[36mBaseLLM.generate\u001b[39m\u001b[34m(self, prompts, stop, callbacks, tags, metadata, run_name, run_id, **kwargs)\u001b[39m\n\u001b[32m    929\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m (\u001b[38;5;28mself\u001b[39m.cache \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m get_llm_cache() \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m.cache \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m:\n\u001b[32m    930\u001b[39m     run_managers = [\n\u001b[32m    931\u001b[39m         callback_manager.on_llm_start(\n\u001b[32m    932\u001b[39m             dumpd(\u001b[38;5;28mself\u001b[39m),\n\u001b[32m   (...)\u001b[39m\u001b[32m    942\u001b[39m         )\n\u001b[32m    943\u001b[39m     ]\n\u001b[32m--> \u001b[39m\u001b[32m944\u001b[39m     output = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_generate_helper\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    945\u001b[39m \u001b[43m        \u001b[49m\u001b[43mprompts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrun_managers\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mbool\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mnew_arg_supported\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\n\u001b[32m    946\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    947\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m output\n\u001b[32m    948\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(missing_prompts) > \u001b[32m0\u001b[39m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/projects/rcpp/.venv/lib/python3.12/site-packages/langchain_core/language_models/llms.py:787\u001b[39m, in \u001b[36mBaseLLM._generate_helper\u001b[39m\u001b[34m(self, prompts, stop, run_managers, new_arg_supported, **kwargs)\u001b[39m\n\u001b[32m    785\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m run_manager \u001b[38;5;129;01min\u001b[39;00m run_managers:\n\u001b[32m    786\u001b[39m         run_manager.on_llm_error(e, response=LLMResult(generations=[]))\n\u001b[32m--> \u001b[39m\u001b[32m787\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[32m    788\u001b[39m flattened_outputs = output.flatten()\n\u001b[32m    789\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m manager, flattened_output \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(run_managers, flattened_outputs):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/projects/rcpp/.venv/lib/python3.12/site-packages/langchain_core/language_models/llms.py:774\u001b[39m, in \u001b[36mBaseLLM._generate_helper\u001b[39m\u001b[34m(self, prompts, stop, run_managers, new_arg_supported, **kwargs)\u001b[39m\n\u001b[32m    764\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_generate_helper\u001b[39m(\n\u001b[32m    765\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m    766\u001b[39m     prompts: List[\u001b[38;5;28mstr\u001b[39m],\n\u001b[32m   (...)\u001b[39m\u001b[32m    770\u001b[39m     **kwargs: Any,\n\u001b[32m    771\u001b[39m ) -> LLMResult:\n\u001b[32m    772\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    773\u001b[39m         output = (\n\u001b[32m--> \u001b[39m\u001b[32m774\u001b[39m             \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_generate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    775\u001b[39m \u001b[43m                \u001b[49m\u001b[43mprompts\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    776\u001b[39m \u001b[43m                \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    777\u001b[39m \u001b[43m                \u001b[49m\u001b[38;5;66;43;03m# TODO: support multiple run managers\u001b[39;49;00m\n\u001b[32m    778\u001b[39m \u001b[43m                \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrun_managers\u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mrun_managers\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    779\u001b[39m \u001b[43m                \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    780\u001b[39m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    781\u001b[39m             \u001b[38;5;28;01mif\u001b[39;00m new_arg_supported\n\u001b[32m    782\u001b[39m             \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m._generate(prompts, stop=stop)\n\u001b[32m    783\u001b[39m         )\n\u001b[32m    784\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    785\u001b[39m         \u001b[38;5;28;01mfor\u001b[39;00m run_manager \u001b[38;5;129;01min\u001b[39;00m run_managers:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/projects/rcpp/.venv/lib/python3.12/site-packages/langchain_ollama/llms.py:268\u001b[39m, in \u001b[36mOllamaLLM._generate\u001b[39m\u001b[34m(self, prompts, stop, run_manager, **kwargs)\u001b[39m\n\u001b[32m    266\u001b[39m generations = []\n\u001b[32m    267\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m prompt \u001b[38;5;129;01min\u001b[39;00m prompts:\n\u001b[32m--> \u001b[39m\u001b[32m268\u001b[39m     final_chunk = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_stream_with_aggregation\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    269\u001b[39m \u001b[43m        \u001b[49m\u001b[43mprompt\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    270\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    271\u001b[39m \u001b[43m        \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    272\u001b[39m \u001b[43m        \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    273\u001b[39m \u001b[43m        \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    274\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    275\u001b[39m     generations.append([final_chunk])\n\u001b[32m    276\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m LLMResult(generations=generations)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/projects/rcpp/.venv/lib/python3.12/site-packages/langchain_ollama/llms.py:236\u001b[39m, in \u001b[36mOllamaLLM._stream_with_aggregation\u001b[39m\u001b[34m(self, prompt, stop, run_manager, verbose, **kwargs)\u001b[39m\n\u001b[32m    227\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_stream_with_aggregation\u001b[39m(\n\u001b[32m    228\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m    229\u001b[39m     prompt: \u001b[38;5;28mstr\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m    233\u001b[39m     **kwargs: Any,\n\u001b[32m    234\u001b[39m ) -> GenerationChunk:\n\u001b[32m    235\u001b[39m     final_chunk = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m236\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mstream_resp\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_create_generate_stream\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprompt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m    237\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43misinstance\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mstream_resp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m    238\u001b[39m \u001b[43m            \u001b[49m\u001b[43mchunk\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mGenerationChunk\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    239\u001b[39m \u001b[43m                \u001b[49m\u001b[43mtext\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstream_resp\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mresponse\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mresponse\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mstream_resp\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    240\u001b[39m \u001b[43m                \u001b[49m\u001b[43mgeneration_info\u001b[49m\u001b[43m=\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    241\u001b[39m \u001b[43m                    \u001b[49m\u001b[38;5;28;43mdict\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mstream_resp\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mstream_resp\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mdone\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\n\u001b[32m    242\u001b[39m \u001b[43m                \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    243\u001b[39m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/projects/rcpp/.venv/lib/python3.12/site-packages/langchain_ollama/llms.py:186\u001b[39m, in \u001b[36mOllamaLLM._create_generate_stream\u001b[39m\u001b[34m(self, prompt, stop, **kwargs)\u001b[39m\n\u001b[32m    183\u001b[39m         params[key] = kwargs[key]\n\u001b[32m    185\u001b[39m params[\u001b[33m\"\u001b[39m\u001b[33moptions\u001b[39m\u001b[33m\"\u001b[39m][\u001b[33m\"\u001b[39m\u001b[33mstop\u001b[39m\u001b[33m\"\u001b[39m] = stop\n\u001b[32m--> \u001b[39m\u001b[32m186\u001b[39m \u001b[38;5;28;01myield from\u001b[39;00m ollama.generate(\n\u001b[32m    187\u001b[39m     model=params[\u001b[33m\"\u001b[39m\u001b[33mmodel\u001b[39m\u001b[33m\"\u001b[39m],\n\u001b[32m    188\u001b[39m     prompt=prompt,\n\u001b[32m    189\u001b[39m     stream=\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[32m    190\u001b[39m     options=Options(**params[\u001b[33m\"\u001b[39m\u001b[33moptions\u001b[39m\u001b[33m\"\u001b[39m]),\n\u001b[32m    191\u001b[39m     keep_alive=params[\u001b[33m\"\u001b[39m\u001b[33mkeep_alive\u001b[39m\u001b[33m\"\u001b[39m],\n\u001b[32m    192\u001b[39m     \u001b[38;5;28mformat\u001b[39m=params[\u001b[33m\"\u001b[39m\u001b[33mformat\u001b[39m\u001b[33m\"\u001b[39m],\n\u001b[32m    193\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/projects/rcpp/.venv/lib/python3.12/site-packages/ollama/_client.py:163\u001b[39m, in \u001b[36mClient._request.<locals>.inner\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m    162\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34minner\u001b[39m():\n\u001b[32m--> \u001b[39m\u001b[32m163\u001b[39m \u001b[43m  \u001b[49m\u001b[38;5;28;43;01mwith\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_client\u001b[49m\u001b[43m.\u001b[49m\u001b[43mstream\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mas\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mr\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m    164\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mtry\u001b[39;49;00m\u001b[43m:\u001b[49m\n\u001b[32m    165\u001b[39m \u001b[43m      \u001b[49m\u001b[43mr\u001b[49m\u001b[43m.\u001b[49m\u001b[43mraise_for_status\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/share/uv/python/cpython-3.12.0-linux-x86_64-gnu/lib/python3.12/contextlib.py:137\u001b[39m, in \u001b[36m_GeneratorContextManager.__enter__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    135\u001b[39m \u001b[38;5;28;01mdel\u001b[39;00m \u001b[38;5;28mself\u001b[39m.args, \u001b[38;5;28mself\u001b[39m.kwds, \u001b[38;5;28mself\u001b[39m.func\n\u001b[32m    136\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m137\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mnext\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mgen\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    138\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m:\n\u001b[32m    139\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mgenerator didn\u001b[39m\u001b[33m'\u001b[39m\u001b[33mt yield\u001b[39m\u001b[33m\"\u001b[39m) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/projects/rcpp/.venv/lib/python3.12/site-packages/httpx/_client.py:868\u001b[39m, in \u001b[36mClient.stream\u001b[39m\u001b[34m(self, method, url, content, data, files, json, params, headers, cookies, auth, follow_redirects, timeout, extensions)\u001b[39m\n\u001b[32m    845\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    846\u001b[39m \u001b[33;03mAlternative to `httpx.request()` that streams the response body\u001b[39;00m\n\u001b[32m    847\u001b[39m \u001b[33;03minstead of loading it into memory at once.\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    853\u001b[39m \u001b[33;03m[0]: /quickstart#streaming-responses\u001b[39;00m\n\u001b[32m    854\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    855\u001b[39m request = \u001b[38;5;28mself\u001b[39m.build_request(\n\u001b[32m    856\u001b[39m     method=method,\n\u001b[32m    857\u001b[39m     url=url,\n\u001b[32m   (...)\u001b[39m\u001b[32m    866\u001b[39m     extensions=extensions,\n\u001b[32m    867\u001b[39m )\n\u001b[32m--> \u001b[39m\u001b[32m868\u001b[39m response = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    869\u001b[39m \u001b[43m    \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    870\u001b[39m \u001b[43m    \u001b[49m\u001b[43mauth\u001b[49m\u001b[43m=\u001b[49m\u001b[43mauth\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    871\u001b[39m \u001b[43m    \u001b[49m\u001b[43mfollow_redirects\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfollow_redirects\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    872\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    873\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    874\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    875\u001b[39m     \u001b[38;5;28;01myield\u001b[39;00m response\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/projects/rcpp/.venv/lib/python3.12/site-packages/httpx/_client.py:914\u001b[39m, in \u001b[36mClient.send\u001b[39m\u001b[34m(self, request, stream, auth, follow_redirects)\u001b[39m\n\u001b[32m    910\u001b[39m \u001b[38;5;28mself\u001b[39m._set_timeout(request)\n\u001b[32m    912\u001b[39m auth = \u001b[38;5;28mself\u001b[39m._build_request_auth(request, auth)\n\u001b[32m--> \u001b[39m\u001b[32m914\u001b[39m response = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_send_handling_auth\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    915\u001b[39m \u001b[43m    \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    916\u001b[39m \u001b[43m    \u001b[49m\u001b[43mauth\u001b[49m\u001b[43m=\u001b[49m\u001b[43mauth\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    917\u001b[39m \u001b[43m    \u001b[49m\u001b[43mfollow_redirects\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfollow_redirects\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    918\u001b[39m \u001b[43m    \u001b[49m\u001b[43mhistory\u001b[49m\u001b[43m=\u001b[49m\u001b[43m[\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    919\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    920\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    921\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m stream:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/projects/rcpp/.venv/lib/python3.12/site-packages/httpx/_client.py:942\u001b[39m, in \u001b[36mClient._send_handling_auth\u001b[39m\u001b[34m(self, request, auth, follow_redirects, history)\u001b[39m\n\u001b[32m    939\u001b[39m request = \u001b[38;5;28mnext\u001b[39m(auth_flow)\n\u001b[32m    941\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m942\u001b[39m     response = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_send_handling_redirects\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    943\u001b[39m \u001b[43m        \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    944\u001b[39m \u001b[43m        \u001b[49m\u001b[43mfollow_redirects\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfollow_redirects\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    945\u001b[39m \u001b[43m        \u001b[49m\u001b[43mhistory\u001b[49m\u001b[43m=\u001b[49m\u001b[43mhistory\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    946\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    947\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    948\u001b[39m         \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/projects/rcpp/.venv/lib/python3.12/site-packages/httpx/_client.py:979\u001b[39m, in \u001b[36mClient._send_handling_redirects\u001b[39m\u001b[34m(self, request, follow_redirects, history)\u001b[39m\n\u001b[32m    976\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m hook \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m._event_hooks[\u001b[33m\"\u001b[39m\u001b[33mrequest\u001b[39m\u001b[33m\"\u001b[39m]:\n\u001b[32m    977\u001b[39m     hook(request)\n\u001b[32m--> \u001b[39m\u001b[32m979\u001b[39m response = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_send_single_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    980\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    981\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m hook \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m._event_hooks[\u001b[33m\"\u001b[39m\u001b[33mresponse\u001b[39m\u001b[33m\"\u001b[39m]:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/projects/rcpp/.venv/lib/python3.12/site-packages/httpx/_client.py:1014\u001b[39m, in \u001b[36mClient._send_single_request\u001b[39m\u001b[34m(self, request)\u001b[39m\n\u001b[32m   1009\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[32m   1010\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mAttempted to send an async request with a sync Client instance.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1011\u001b[39m     )\n\u001b[32m   1013\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m request_context(request=request):\n\u001b[32m-> \u001b[39m\u001b[32m1014\u001b[39m     response = \u001b[43mtransport\u001b[49m\u001b[43m.\u001b[49m\u001b[43mhandle_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1016\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(response.stream, SyncByteStream)\n\u001b[32m   1018\u001b[39m response.request = request\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/projects/rcpp/.venv/lib/python3.12/site-packages/httpx/_transports/default.py:249\u001b[39m, in \u001b[36mHTTPTransport.handle_request\u001b[39m\u001b[34m(self, request)\u001b[39m\n\u001b[32m    235\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mhttpcore\u001b[39;00m\n\u001b[32m    237\u001b[39m req = httpcore.Request(\n\u001b[32m    238\u001b[39m     method=request.method,\n\u001b[32m    239\u001b[39m     url=httpcore.URL(\n\u001b[32m   (...)\u001b[39m\u001b[32m    247\u001b[39m     extensions=request.extensions,\n\u001b[32m    248\u001b[39m )\n\u001b[32m--> \u001b[39m\u001b[32m249\u001b[39m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mwith\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mmap_httpcore_exceptions\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m    250\u001b[39m \u001b[43m    \u001b[49m\u001b[43mresp\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_pool\u001b[49m\u001b[43m.\u001b[49m\u001b[43mhandle_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreq\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    252\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(resp.stream, typing.Iterable)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/share/uv/python/cpython-3.12.0-linux-x86_64-gnu/lib/python3.12/contextlib.py:155\u001b[39m, in \u001b[36m_GeneratorContextManager.__exit__\u001b[39m\u001b[34m(self, typ, value, traceback)\u001b[39m\n\u001b[32m    153\u001b[39m     value = typ()\n\u001b[32m    154\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m155\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mgen\u001b[49m\u001b[43m.\u001b[49m\u001b[43mthrow\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    156\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[32m    157\u001b[39m     \u001b[38;5;66;03m# Suppress StopIteration *unless* it's the same exception that\u001b[39;00m\n\u001b[32m    158\u001b[39m     \u001b[38;5;66;03m# was passed to throw().  This prevents a StopIteration\u001b[39;00m\n\u001b[32m    159\u001b[39m     \u001b[38;5;66;03m# raised inside the \"with\" statement from being suppressed.\u001b[39;00m\n\u001b[32m    160\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m exc \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m value\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/projects/rcpp/.venv/lib/python3.12/site-packages/httpx/_transports/default.py:118\u001b[39m, in \u001b[36mmap_httpcore_exceptions\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m    115\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m\n\u001b[32m    117\u001b[39m message = \u001b[38;5;28mstr\u001b[39m(exc)\n\u001b[32m--> \u001b[39m\u001b[32m118\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m mapped_exc(message) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mexc\u001b[39;00m\n",
      "\u001b[31mConnectError\u001b[39m: [Errno 111] Connection refused"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating 10 typical applicants...\n"
     ]
    },
    {
     "ename": "ConnectError",
     "evalue": "[Errno 111] Connection refused",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mConnectError\u001b[39m                              Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32m~/projects/rcpp/.venv/lib/python3.12/site-packages/httpx/_transports/default.py:101\u001b[39m, in \u001b[36mmap_httpcore_exceptions\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m    100\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m101\u001b[39m     \u001b[38;5;28;01myield\u001b[39;00m\n\u001b[32m    102\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/projects/rcpp/.venv/lib/python3.12/site-packages/httpx/_transports/default.py:250\u001b[39m, in \u001b[36mHTTPTransport.handle_request\u001b[39m\u001b[34m(self, request)\u001b[39m\n\u001b[32m    249\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m map_httpcore_exceptions():\n\u001b[32m--> \u001b[39m\u001b[32m250\u001b[39m     resp = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_pool\u001b[49m\u001b[43m.\u001b[49m\u001b[43mhandle_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreq\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    252\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(resp.stream, typing.Iterable)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/projects/rcpp/.venv/lib/python3.12/site-packages/httpcore/_sync/connection_pool.py:256\u001b[39m, in \u001b[36mConnectionPool.handle_request\u001b[39m\u001b[34m(self, request)\u001b[39m\n\u001b[32m    255\u001b[39m     \u001b[38;5;28mself\u001b[39m._close_connections(closing)\n\u001b[32m--> \u001b[39m\u001b[32m256\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m exc \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    258\u001b[39m \u001b[38;5;66;03m# Return the response. Note that in this case we still have to manage\u001b[39;00m\n\u001b[32m    259\u001b[39m \u001b[38;5;66;03m# the point at which the response is closed.\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/projects/rcpp/.venv/lib/python3.12/site-packages/httpcore/_sync/connection_pool.py:236\u001b[39m, in \u001b[36mConnectionPool.handle_request\u001b[39m\u001b[34m(self, request)\u001b[39m\n\u001b[32m    234\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    235\u001b[39m     \u001b[38;5;66;03m# Send the request on the assigned connection.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m236\u001b[39m     response = \u001b[43mconnection\u001b[49m\u001b[43m.\u001b[49m\u001b[43mhandle_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    237\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpool_request\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrequest\u001b[49m\n\u001b[32m    238\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    239\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m ConnectionNotAvailable:\n\u001b[32m    240\u001b[39m     \u001b[38;5;66;03m# In some cases a connection may initially be available to\u001b[39;00m\n\u001b[32m    241\u001b[39m     \u001b[38;5;66;03m# handle a request, but then become unavailable.\u001b[39;00m\n\u001b[32m    242\u001b[39m     \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[32m    243\u001b[39m     \u001b[38;5;66;03m# In this case we clear the connection and try again.\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/projects/rcpp/.venv/lib/python3.12/site-packages/httpcore/_sync/connection.py:101\u001b[39m, in \u001b[36mHTTPConnection.handle_request\u001b[39m\u001b[34m(self, request)\u001b[39m\n\u001b[32m    100\u001b[39m     \u001b[38;5;28mself\u001b[39m._connect_failed = \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m101\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m exc\n\u001b[32m    103\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._connection.handle_request(request)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/projects/rcpp/.venv/lib/python3.12/site-packages/httpcore/_sync/connection.py:78\u001b[39m, in \u001b[36mHTTPConnection.handle_request\u001b[39m\u001b[34m(self, request)\u001b[39m\n\u001b[32m     77\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._connection \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m78\u001b[39m     stream = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_connect\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     80\u001b[39m     ssl_object = stream.get_extra_info(\u001b[33m\"\u001b[39m\u001b[33mssl_object\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/projects/rcpp/.venv/lib/python3.12/site-packages/httpcore/_sync/connection.py:124\u001b[39m, in \u001b[36mHTTPConnection._connect\u001b[39m\u001b[34m(self, request)\u001b[39m\n\u001b[32m    123\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m Trace(\u001b[33m\"\u001b[39m\u001b[33mconnect_tcp\u001b[39m\u001b[33m\"\u001b[39m, logger, request, kwargs) \u001b[38;5;28;01mas\u001b[39;00m trace:\n\u001b[32m--> \u001b[39m\u001b[32m124\u001b[39m     stream = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_network_backend\u001b[49m\u001b[43m.\u001b[49m\u001b[43mconnect_tcp\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    125\u001b[39m     trace.return_value = stream\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/projects/rcpp/.venv/lib/python3.12/site-packages/httpcore/_backends/sync.py:207\u001b[39m, in \u001b[36mSyncBackend.connect_tcp\u001b[39m\u001b[34m(self, host, port, timeout, local_address, socket_options)\u001b[39m\n\u001b[32m    202\u001b[39m exc_map: ExceptionMapping = {\n\u001b[32m    203\u001b[39m     socket.timeout: ConnectTimeout,\n\u001b[32m    204\u001b[39m     \u001b[38;5;167;01mOSError\u001b[39;00m: ConnectError,\n\u001b[32m    205\u001b[39m }\n\u001b[32m--> \u001b[39m\u001b[32m207\u001b[39m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mwith\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mmap_exceptions\u001b[49m\u001b[43m(\u001b[49m\u001b[43mexc_map\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m    208\u001b[39m \u001b[43m    \u001b[49m\u001b[43msock\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43msocket\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcreate_connection\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    209\u001b[39m \u001b[43m        \u001b[49m\u001b[43maddress\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    210\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    211\u001b[39m \u001b[43m        \u001b[49m\u001b[43msource_address\u001b[49m\u001b[43m=\u001b[49m\u001b[43msource_address\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    212\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/share/uv/python/cpython-3.12.0-linux-x86_64-gnu/lib/python3.12/contextlib.py:155\u001b[39m, in \u001b[36m_GeneratorContextManager.__exit__\u001b[39m\u001b[34m(self, typ, value, traceback)\u001b[39m\n\u001b[32m    154\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m155\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mgen\u001b[49m\u001b[43m.\u001b[49m\u001b[43mthrow\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    156\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[32m    157\u001b[39m     \u001b[38;5;66;03m# Suppress StopIteration *unless* it's the same exception that\u001b[39;00m\n\u001b[32m    158\u001b[39m     \u001b[38;5;66;03m# was passed to throw().  This prevents a StopIteration\u001b[39;00m\n\u001b[32m    159\u001b[39m     \u001b[38;5;66;03m# raised inside the \"with\" statement from being suppressed.\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/projects/rcpp/.venv/lib/python3.12/site-packages/httpcore/_exceptions.py:14\u001b[39m, in \u001b[36mmap_exceptions\u001b[39m\u001b[34m(map)\u001b[39m\n\u001b[32m     13\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(exc, from_exc):\n\u001b[32m---> \u001b[39m\u001b[32m14\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m to_exc(exc) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mexc\u001b[39;00m\n\u001b[32m     15\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m\n",
      "\u001b[31mConnectError\u001b[39m: [Errno 111] Connection refused",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[31mConnectError\u001b[39m                              Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32m<timed exec>:1\u001b[39m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 67\u001b[39m, in \u001b[36mgenerate_applicant_data\u001b[39m\u001b[34m(model, n, p, shuffle)\u001b[39m\n\u001b[32m     65\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mGenerating \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnum_typical\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m typical applicants...\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     66\u001b[39m typical_inputs = [{} \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(num_typical)]\n\u001b[32m---> \u001b[39m\u001b[32m67\u001b[39m typical_results = \u001b[43mtypical_chain\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtypical_inputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     68\u001b[39m X.extend(typical_results)\n\u001b[32m     69\u001b[39m y.extend([\u001b[32m0\u001b[39m] * num_typical)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/projects/rcpp/.venv/lib/python3.12/site-packages/langchain_core/runnables/base.py:3024\u001b[39m, in \u001b[36mRunnableSequence.batch\u001b[39m\u001b[34m(self, inputs, config, return_exceptions, **kwargs)\u001b[39m\n\u001b[32m   3022\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   3023\u001b[39m         \u001b[38;5;28;01mfor\u001b[39;00m i, step \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(\u001b[38;5;28mself\u001b[39m.steps):\n\u001b[32m-> \u001b[39m\u001b[32m3024\u001b[39m             inputs = \u001b[43mstep\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   3025\u001b[39m \u001b[43m                \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3026\u001b[39m \u001b[43m                \u001b[49m\u001b[43m[\u001b[49m\n\u001b[32m   3027\u001b[39m \u001b[43m                    \u001b[49m\u001b[38;5;66;43;03m# each step a child run of the corresponding root run\u001b[39;49;00m\n\u001b[32m   3028\u001b[39m \u001b[43m                    \u001b[49m\u001b[43mpatch_config\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   3029\u001b[39m \u001b[43m                        \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrm\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_child\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43mf\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mseq:step:\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mi\u001b[49m\u001b[43m+\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m   3030\u001b[39m \u001b[43m                    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   3031\u001b[39m \u001b[43m                    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mrm\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mzip\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mrun_managers\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfigs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   3032\u001b[39m \u001b[43m                \u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3033\u001b[39m \u001b[43m                \u001b[49m\u001b[43mreturn_exceptions\u001b[49m\u001b[43m=\u001b[49m\u001b[43mreturn_exceptions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3034\u001b[39m \u001b[43m                \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m \u001b[49m\u001b[43m==\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3035\u001b[39m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   3037\u001b[39m \u001b[38;5;66;03m# finish the root runs\u001b[39;00m\n\u001b[32m   3038\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/projects/rcpp/.venv/lib/python3.12/site-packages/langchain_core/language_models/llms.py:449\u001b[39m, in \u001b[36mBaseLLM.batch\u001b[39m\u001b[34m(self, inputs, config, return_exceptions, **kwargs)\u001b[39m\n\u001b[32m    447\u001b[39m             \u001b[38;5;28;01mreturn\u001b[39;00m cast(List[\u001b[38;5;28mstr\u001b[39m], [e \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m inputs])\n\u001b[32m    448\u001b[39m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m449\u001b[39m             \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[32m    450\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    451\u001b[39m     batches = [\n\u001b[32m    452\u001b[39m         inputs[i : i + max_concurrency]\n\u001b[32m    453\u001b[39m         \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[32m0\u001b[39m, \u001b[38;5;28mlen\u001b[39m(inputs), max_concurrency)\n\u001b[32m    454\u001b[39m     ]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/projects/rcpp/.venv/lib/python3.12/site-packages/langchain_core/language_models/llms.py:436\u001b[39m, in \u001b[36mBaseLLM.batch\u001b[39m\u001b[34m(self, inputs, config, return_exceptions, **kwargs)\u001b[39m\n\u001b[32m    434\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m max_concurrency \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    435\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m436\u001b[39m         llm_result = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mgenerate_prompt\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    437\u001b[39m \u001b[43m            \u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_convert_input\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    438\u001b[39m \u001b[43m            \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m=\u001b[49m\u001b[43m[\u001b[49m\u001b[43mc\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcallbacks\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mc\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    439\u001b[39m \u001b[43m            \u001b[49m\u001b[43mtags\u001b[49m\u001b[43m=\u001b[49m\u001b[43m[\u001b[49m\u001b[43mc\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtags\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mc\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    440\u001b[39m \u001b[43m            \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[43m=\u001b[49m\u001b[43m[\u001b[49m\u001b[43mc\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmetadata\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mc\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    441\u001b[39m \u001b[43m            \u001b[49m\u001b[43mrun_name\u001b[49m\u001b[43m=\u001b[49m\u001b[43m[\u001b[49m\u001b[43mc\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mrun_name\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mc\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    442\u001b[39m \u001b[43m            \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    443\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    444\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m [g[\u001b[32m0\u001b[39m].text \u001b[38;5;28;01mfor\u001b[39;00m g \u001b[38;5;129;01min\u001b[39;00m llm_result.generations]\n\u001b[32m    445\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/projects/rcpp/.venv/lib/python3.12/site-packages/langchain_core/language_models/llms.py:750\u001b[39m, in \u001b[36mBaseLLM.generate_prompt\u001b[39m\u001b[34m(self, prompts, stop, callbacks, **kwargs)\u001b[39m\n\u001b[32m    742\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mgenerate_prompt\u001b[39m(\n\u001b[32m    743\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m    744\u001b[39m     prompts: List[PromptValue],\n\u001b[32m   (...)\u001b[39m\u001b[32m    747\u001b[39m     **kwargs: Any,\n\u001b[32m    748\u001b[39m ) -> LLMResult:\n\u001b[32m    749\u001b[39m     prompt_strings = [p.to_string() \u001b[38;5;28;01mfor\u001b[39;00m p \u001b[38;5;129;01min\u001b[39;00m prompts]\n\u001b[32m--> \u001b[39m\u001b[32m750\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprompt_strings\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/projects/rcpp/.venv/lib/python3.12/site-packages/langchain_core/language_models/llms.py:944\u001b[39m, in \u001b[36mBaseLLM.generate\u001b[39m\u001b[34m(self, prompts, stop, callbacks, tags, metadata, run_name, run_id, **kwargs)\u001b[39m\n\u001b[32m    929\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m (\u001b[38;5;28mself\u001b[39m.cache \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m get_llm_cache() \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m.cache \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m:\n\u001b[32m    930\u001b[39m     run_managers = [\n\u001b[32m    931\u001b[39m         callback_manager.on_llm_start(\n\u001b[32m    932\u001b[39m             dumpd(\u001b[38;5;28mself\u001b[39m),\n\u001b[32m   (...)\u001b[39m\u001b[32m    942\u001b[39m         )\n\u001b[32m    943\u001b[39m     ]\n\u001b[32m--> \u001b[39m\u001b[32m944\u001b[39m     output = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_generate_helper\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    945\u001b[39m \u001b[43m        \u001b[49m\u001b[43mprompts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrun_managers\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mbool\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mnew_arg_supported\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\n\u001b[32m    946\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    947\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m output\n\u001b[32m    948\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(missing_prompts) > \u001b[32m0\u001b[39m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/projects/rcpp/.venv/lib/python3.12/site-packages/langchain_core/language_models/llms.py:787\u001b[39m, in \u001b[36mBaseLLM._generate_helper\u001b[39m\u001b[34m(self, prompts, stop, run_managers, new_arg_supported, **kwargs)\u001b[39m\n\u001b[32m    785\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m run_manager \u001b[38;5;129;01min\u001b[39;00m run_managers:\n\u001b[32m    786\u001b[39m         run_manager.on_llm_error(e, response=LLMResult(generations=[]))\n\u001b[32m--> \u001b[39m\u001b[32m787\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[32m    788\u001b[39m flattened_outputs = output.flatten()\n\u001b[32m    789\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m manager, flattened_output \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(run_managers, flattened_outputs):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/projects/rcpp/.venv/lib/python3.12/site-packages/langchain_core/language_models/llms.py:774\u001b[39m, in \u001b[36mBaseLLM._generate_helper\u001b[39m\u001b[34m(self, prompts, stop, run_managers, new_arg_supported, **kwargs)\u001b[39m\n\u001b[32m    764\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_generate_helper\u001b[39m(\n\u001b[32m    765\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m    766\u001b[39m     prompts: List[\u001b[38;5;28mstr\u001b[39m],\n\u001b[32m   (...)\u001b[39m\u001b[32m    770\u001b[39m     **kwargs: Any,\n\u001b[32m    771\u001b[39m ) -> LLMResult:\n\u001b[32m    772\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    773\u001b[39m         output = (\n\u001b[32m--> \u001b[39m\u001b[32m774\u001b[39m             \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_generate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    775\u001b[39m \u001b[43m                \u001b[49m\u001b[43mprompts\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    776\u001b[39m \u001b[43m                \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    777\u001b[39m \u001b[43m                \u001b[49m\u001b[38;5;66;43;03m# TODO: support multiple run managers\u001b[39;49;00m\n\u001b[32m    778\u001b[39m \u001b[43m                \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrun_managers\u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mrun_managers\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    779\u001b[39m \u001b[43m                \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    780\u001b[39m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    781\u001b[39m             \u001b[38;5;28;01mif\u001b[39;00m new_arg_supported\n\u001b[32m    782\u001b[39m             \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m._generate(prompts, stop=stop)\n\u001b[32m    783\u001b[39m         )\n\u001b[32m    784\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    785\u001b[39m         \u001b[38;5;28;01mfor\u001b[39;00m run_manager \u001b[38;5;129;01min\u001b[39;00m run_managers:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/projects/rcpp/.venv/lib/python3.12/site-packages/langchain_ollama/llms.py:268\u001b[39m, in \u001b[36mOllamaLLM._generate\u001b[39m\u001b[34m(self, prompts, stop, run_manager, **kwargs)\u001b[39m\n\u001b[32m    266\u001b[39m generations = []\n\u001b[32m    267\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m prompt \u001b[38;5;129;01min\u001b[39;00m prompts:\n\u001b[32m--> \u001b[39m\u001b[32m268\u001b[39m     final_chunk = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_stream_with_aggregation\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    269\u001b[39m \u001b[43m        \u001b[49m\u001b[43mprompt\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    270\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    271\u001b[39m \u001b[43m        \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    272\u001b[39m \u001b[43m        \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    273\u001b[39m \u001b[43m        \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    274\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    275\u001b[39m     generations.append([final_chunk])\n\u001b[32m    276\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m LLMResult(generations=generations)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/projects/rcpp/.venv/lib/python3.12/site-packages/langchain_ollama/llms.py:236\u001b[39m, in \u001b[36mOllamaLLM._stream_with_aggregation\u001b[39m\u001b[34m(self, prompt, stop, run_manager, verbose, **kwargs)\u001b[39m\n\u001b[32m    227\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_stream_with_aggregation\u001b[39m(\n\u001b[32m    228\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m    229\u001b[39m     prompt: \u001b[38;5;28mstr\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m    233\u001b[39m     **kwargs: Any,\n\u001b[32m    234\u001b[39m ) -> GenerationChunk:\n\u001b[32m    235\u001b[39m     final_chunk = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m236\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mstream_resp\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_create_generate_stream\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprompt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m    237\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43misinstance\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mstream_resp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m    238\u001b[39m \u001b[43m            \u001b[49m\u001b[43mchunk\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mGenerationChunk\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    239\u001b[39m \u001b[43m                \u001b[49m\u001b[43mtext\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstream_resp\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mresponse\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mresponse\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mstream_resp\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    240\u001b[39m \u001b[43m                \u001b[49m\u001b[43mgeneration_info\u001b[49m\u001b[43m=\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    241\u001b[39m \u001b[43m                    \u001b[49m\u001b[38;5;28;43mdict\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mstream_resp\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mstream_resp\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mdone\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\n\u001b[32m    242\u001b[39m \u001b[43m                \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    243\u001b[39m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/projects/rcpp/.venv/lib/python3.12/site-packages/langchain_ollama/llms.py:186\u001b[39m, in \u001b[36mOllamaLLM._create_generate_stream\u001b[39m\u001b[34m(self, prompt, stop, **kwargs)\u001b[39m\n\u001b[32m    183\u001b[39m         params[key] = kwargs[key]\n\u001b[32m    185\u001b[39m params[\u001b[33m\"\u001b[39m\u001b[33moptions\u001b[39m\u001b[33m\"\u001b[39m][\u001b[33m\"\u001b[39m\u001b[33mstop\u001b[39m\u001b[33m\"\u001b[39m] = stop\n\u001b[32m--> \u001b[39m\u001b[32m186\u001b[39m \u001b[38;5;28;01myield from\u001b[39;00m ollama.generate(\n\u001b[32m    187\u001b[39m     model=params[\u001b[33m\"\u001b[39m\u001b[33mmodel\u001b[39m\u001b[33m\"\u001b[39m],\n\u001b[32m    188\u001b[39m     prompt=prompt,\n\u001b[32m    189\u001b[39m     stream=\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[32m    190\u001b[39m     options=Options(**params[\u001b[33m\"\u001b[39m\u001b[33moptions\u001b[39m\u001b[33m\"\u001b[39m]),\n\u001b[32m    191\u001b[39m     keep_alive=params[\u001b[33m\"\u001b[39m\u001b[33mkeep_alive\u001b[39m\u001b[33m\"\u001b[39m],\n\u001b[32m    192\u001b[39m     \u001b[38;5;28mformat\u001b[39m=params[\u001b[33m\"\u001b[39m\u001b[33mformat\u001b[39m\u001b[33m\"\u001b[39m],\n\u001b[32m    193\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/projects/rcpp/.venv/lib/python3.12/site-packages/ollama/_client.py:163\u001b[39m, in \u001b[36mClient._request.<locals>.inner\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m    162\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34minner\u001b[39m():\n\u001b[32m--> \u001b[39m\u001b[32m163\u001b[39m \u001b[43m  \u001b[49m\u001b[38;5;28;43;01mwith\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_client\u001b[49m\u001b[43m.\u001b[49m\u001b[43mstream\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mas\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mr\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m    164\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mtry\u001b[39;49;00m\u001b[43m:\u001b[49m\n\u001b[32m    165\u001b[39m \u001b[43m      \u001b[49m\u001b[43mr\u001b[49m\u001b[43m.\u001b[49m\u001b[43mraise_for_status\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/share/uv/python/cpython-3.12.0-linux-x86_64-gnu/lib/python3.12/contextlib.py:137\u001b[39m, in \u001b[36m_GeneratorContextManager.__enter__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    135\u001b[39m \u001b[38;5;28;01mdel\u001b[39;00m \u001b[38;5;28mself\u001b[39m.args, \u001b[38;5;28mself\u001b[39m.kwds, \u001b[38;5;28mself\u001b[39m.func\n\u001b[32m    136\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m137\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mnext\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mgen\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    138\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m:\n\u001b[32m    139\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mgenerator didn\u001b[39m\u001b[33m'\u001b[39m\u001b[33mt yield\u001b[39m\u001b[33m\"\u001b[39m) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/projects/rcpp/.venv/lib/python3.12/site-packages/httpx/_client.py:868\u001b[39m, in \u001b[36mClient.stream\u001b[39m\u001b[34m(self, method, url, content, data, files, json, params, headers, cookies, auth, follow_redirects, timeout, extensions)\u001b[39m\n\u001b[32m    845\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    846\u001b[39m \u001b[33;03mAlternative to `httpx.request()` that streams the response body\u001b[39;00m\n\u001b[32m    847\u001b[39m \u001b[33;03minstead of loading it into memory at once.\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    853\u001b[39m \u001b[33;03m[0]: /quickstart#streaming-responses\u001b[39;00m\n\u001b[32m    854\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    855\u001b[39m request = \u001b[38;5;28mself\u001b[39m.build_request(\n\u001b[32m    856\u001b[39m     method=method,\n\u001b[32m    857\u001b[39m     url=url,\n\u001b[32m   (...)\u001b[39m\u001b[32m    866\u001b[39m     extensions=extensions,\n\u001b[32m    867\u001b[39m )\n\u001b[32m--> \u001b[39m\u001b[32m868\u001b[39m response = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    869\u001b[39m \u001b[43m    \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    870\u001b[39m \u001b[43m    \u001b[49m\u001b[43mauth\u001b[49m\u001b[43m=\u001b[49m\u001b[43mauth\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    871\u001b[39m \u001b[43m    \u001b[49m\u001b[43mfollow_redirects\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfollow_redirects\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    872\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    873\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    874\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    875\u001b[39m     \u001b[38;5;28;01myield\u001b[39;00m response\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/projects/rcpp/.venv/lib/python3.12/site-packages/httpx/_client.py:914\u001b[39m, in \u001b[36mClient.send\u001b[39m\u001b[34m(self, request, stream, auth, follow_redirects)\u001b[39m\n\u001b[32m    910\u001b[39m \u001b[38;5;28mself\u001b[39m._set_timeout(request)\n\u001b[32m    912\u001b[39m auth = \u001b[38;5;28mself\u001b[39m._build_request_auth(request, auth)\n\u001b[32m--> \u001b[39m\u001b[32m914\u001b[39m response = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_send_handling_auth\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    915\u001b[39m \u001b[43m    \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    916\u001b[39m \u001b[43m    \u001b[49m\u001b[43mauth\u001b[49m\u001b[43m=\u001b[49m\u001b[43mauth\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    917\u001b[39m \u001b[43m    \u001b[49m\u001b[43mfollow_redirects\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfollow_redirects\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    918\u001b[39m \u001b[43m    \u001b[49m\u001b[43mhistory\u001b[49m\u001b[43m=\u001b[49m\u001b[43m[\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    919\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    920\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    921\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m stream:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/projects/rcpp/.venv/lib/python3.12/site-packages/httpx/_client.py:942\u001b[39m, in \u001b[36mClient._send_handling_auth\u001b[39m\u001b[34m(self, request, auth, follow_redirects, history)\u001b[39m\n\u001b[32m    939\u001b[39m request = \u001b[38;5;28mnext\u001b[39m(auth_flow)\n\u001b[32m    941\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m942\u001b[39m     response = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_send_handling_redirects\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    943\u001b[39m \u001b[43m        \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    944\u001b[39m \u001b[43m        \u001b[49m\u001b[43mfollow_redirects\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfollow_redirects\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    945\u001b[39m \u001b[43m        \u001b[49m\u001b[43mhistory\u001b[49m\u001b[43m=\u001b[49m\u001b[43mhistory\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    946\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    947\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    948\u001b[39m         \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/projects/rcpp/.venv/lib/python3.12/site-packages/httpx/_client.py:979\u001b[39m, in \u001b[36mClient._send_handling_redirects\u001b[39m\u001b[34m(self, request, follow_redirects, history)\u001b[39m\n\u001b[32m    976\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m hook \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m._event_hooks[\u001b[33m\"\u001b[39m\u001b[33mrequest\u001b[39m\u001b[33m\"\u001b[39m]:\n\u001b[32m    977\u001b[39m     hook(request)\n\u001b[32m--> \u001b[39m\u001b[32m979\u001b[39m response = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_send_single_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    980\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    981\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m hook \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m._event_hooks[\u001b[33m\"\u001b[39m\u001b[33mresponse\u001b[39m\u001b[33m\"\u001b[39m]:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/projects/rcpp/.venv/lib/python3.12/site-packages/httpx/_client.py:1014\u001b[39m, in \u001b[36mClient._send_single_request\u001b[39m\u001b[34m(self, request)\u001b[39m\n\u001b[32m   1009\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[32m   1010\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mAttempted to send an async request with a sync Client instance.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1011\u001b[39m     )\n\u001b[32m   1013\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m request_context(request=request):\n\u001b[32m-> \u001b[39m\u001b[32m1014\u001b[39m     response = \u001b[43mtransport\u001b[49m\u001b[43m.\u001b[49m\u001b[43mhandle_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1016\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(response.stream, SyncByteStream)\n\u001b[32m   1018\u001b[39m response.request = request\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/projects/rcpp/.venv/lib/python3.12/site-packages/httpx/_transports/default.py:249\u001b[39m, in \u001b[36mHTTPTransport.handle_request\u001b[39m\u001b[34m(self, request)\u001b[39m\n\u001b[32m    235\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mhttpcore\u001b[39;00m\n\u001b[32m    237\u001b[39m req = httpcore.Request(\n\u001b[32m    238\u001b[39m     method=request.method,\n\u001b[32m    239\u001b[39m     url=httpcore.URL(\n\u001b[32m   (...)\u001b[39m\u001b[32m    247\u001b[39m     extensions=request.extensions,\n\u001b[32m    248\u001b[39m )\n\u001b[32m--> \u001b[39m\u001b[32m249\u001b[39m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mwith\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mmap_httpcore_exceptions\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m    250\u001b[39m \u001b[43m    \u001b[49m\u001b[43mresp\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_pool\u001b[49m\u001b[43m.\u001b[49m\u001b[43mhandle_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreq\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    252\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(resp.stream, typing.Iterable)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/share/uv/python/cpython-3.12.0-linux-x86_64-gnu/lib/python3.12/contextlib.py:155\u001b[39m, in \u001b[36m_GeneratorContextManager.__exit__\u001b[39m\u001b[34m(self, typ, value, traceback)\u001b[39m\n\u001b[32m    153\u001b[39m     value = typ()\n\u001b[32m    154\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m155\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mgen\u001b[49m\u001b[43m.\u001b[49m\u001b[43mthrow\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    156\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[32m    157\u001b[39m     \u001b[38;5;66;03m# Suppress StopIteration *unless* it's the same exception that\u001b[39;00m\n\u001b[32m    158\u001b[39m     \u001b[38;5;66;03m# was passed to throw().  This prevents a StopIteration\u001b[39;00m\n\u001b[32m    159\u001b[39m     \u001b[38;5;66;03m# raised inside the \"with\" statement from being suppressed.\u001b[39;00m\n\u001b[32m    160\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m exc \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m value\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/projects/rcpp/.venv/lib/python3.12/site-packages/httpx/_transports/default.py:118\u001b[39m, in \u001b[36mmap_httpcore_exceptions\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m    115\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m\n\u001b[32m    117\u001b[39m message = \u001b[38;5;28mstr\u001b[39m(exc)\n\u001b[32m--> \u001b[39m\u001b[32m118\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m mapped_exc(message) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mexc\u001b[39;00m\n",
      "\u001b[31mConnectError\u001b[39m: [Errno 111] Connection refused"
     ]
    }
   ],
   "source": [
    "%time _ = generate_applicant_data(ollama_model, 2, 0)\n",
    "\n",
    "%time _ = generate_applicant_data(ollama_model, 10, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fdb392f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating 100 typical applicants...\n",
      "Generation complete!\n",
      "CPU times: user 952 ms, sys: 90.4 ms, total: 1.04 s\n",
      "Wall time: 1min 10s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(['As an aspiring data scientist, I bring a strong foundation in statistical inference, machine learning, and data visualization. My academic background includes coursework in Python programming, R, and SQL, as well as proficiency in data manipulation libraries like Pandas and NumPy. I have completed personal projects that applied machine learning techniques to real-world datasets, including predictive modeling and data exploration. Prior experience working with large datasets has honed my attention to detail and analytical skills. I am eager to collaborate with a team of professionals and continue learning to grow my skills in this exciting field.',\n",
       "  'As an aspiring data scientist, I possess a strong foundation in statistical modeling, machine learning, and data visualization through coursework in computer science, statistics, and mathematics. Relevant projects include building predictive models for customer churn prediction and sentiment analysis of social media posts. Prior experience includes working with datasets from Kaggle competitions and contributing to open-source repositories on GitHub. I am eager to apply my skills to real-world problems within a collaborative team environment. I am confident in my ability to learn and grow within the role, utilizing standard data tools such as Python, R, and Tableau.',\n",
       "  \"As an aspiring data scientist, I bring a strong foundation in statistics, machine learning, and data visualization. My coursework includes courses on regression, clustering, and natural language processing. I've also worked on several projects that applied data analysis techniques to real-world problems, such as analyzing customer behavior and predicting housing prices. Prior experience has given me hands-on experience with tools like R, Python, SQL, and Tableau. I'm excited to join a collaborative team and apply my skills to drive business value through data-driven insights, always looking to grow and expand my knowledge in this field.\",\n",
       "  \"As an aspiring data scientist, I bring a strong foundation in statistics, computer science, and data analysis. My undergraduate coursework includes courses such as linear algebra, probability, and machine learning, which have provided a solid understanding of mathematical and computational techniques. Through various projects and hackathons, I've applied data analysis techniques to real-world problems, including data visualization and predictive modeling. I'm excited to apply my skills in an entry-level role, leveraging tools like Python, R, SQL, and Tableau. I thrive in collaborative environments, eager to grow my expertise and contribute to solving complex problems alongside a talented team.\",\n",
       "  \"As an aspiring data scientist, I bring a solid foundation in statistics, mathematics, and computer science. I've completed courses in machine learning, data mining, and visualization using Python, R, and SQL. Throughout my academic journey, I worked on numerous projects that applied statistical techniques to real-world problems, such as analyzing customer behavior and predicting stock market trends. I'm excited to apply my skills in an entry-level role, leveraging tools like pandas, NumPy, and scikit-learn. In a collaborative team environment, I'm eager to learn from others and contribute my enthusiasm for data analysis and problem-solving to drive business growth.\",\n",
       "  \"As an aspiring data scientist, I bring a strong foundation in statistical inference, machine learning, and data visualization. My undergraduate coursework includes advanced courses in Python, R, and SQL, as well as experience with popular libraries such as Pandas, NumPy, and scikit-learn. I've also worked on several projects applying data analysis techniques to real-world problems, including customer segmentation and sentiment analysis. I'm eager to apply my skills in a collaborative team environment, leveraging standard tools like Tableau, Excel, and SQL. I'm excited to learn from experienced professionals and grow as a data scientist within the organization.\",\n",
       "  \"As an aspiring data scientist, I bring a strong foundation in statistics, machine learning, and programming. Coursework includes machine learning, data mining, and data visualization. I've completed projects on predictive modeling, natural language processing, and data wrangling using tools like Python, R, and SQL. Prior experience includes analyzing customer behavior for a small startup and building dashboards with Tableau. I'm excited to apply my skills to real-world problems in an entry-level role. I'm eager to learn from experienced professionals and grow within a collaborative team environment, utilizing standard data tools while expanding my expertise in emerging technologies like AI and deep learning.\",\n",
       "  \"As an aspiring data scientist, I bring a strong foundation in statistical analysis and machine learning fundamentals from my coursework in computer science and mathematics. Relevant projects include building predictive models for customer churn prediction and sentiment analysis of social media posts. Prior experience as a data analyst has also honed my skills with tools like Excel, SQL, and Tableau. I'm excited to apply these skills in real-world problems and continue growing within a collaborative team environment, always seeking to expand my knowledge in emerging areas like deep learning and natural language processing.\",\n",
       "  \"As an aspiring data scientist, I bring a solid foundation in statistics and computer programming, with a concentration in Data Science at XYZ University (Coursework: Machine Learning, Data Mining, R Programming). My academic projects involved analyzing public health trends and predicting consumer behavior using machine learning algorithms. Prior to my studies, I gained experience working as a research assistant for a business consulting firm. I'm enthusiastic about applying data analysis techniques to real-world problems and am comfortable with standard data tools such as pandas, NumPy, and scikit-learn. I thrive in collaborative environments and look forward to growing my skills within your team.\",\n",
       "  \"As an aspiring data scientist, I bring a solid foundation in statistical concepts, data structures, and machine learning algorithms. Through coursework at [University Name], I successfully completed courses on data visualization, predictive modeling, and data mining. I've also worked on personal projects utilizing Python, R, and SQL to analyze real-world datasets and develop insights. With prior experience in data analysis for academic research and internships, I'm confident in my ability to apply data techniques to drive informed decision-making. I thrive in collaborative environments, eager to learn and grow with a team of experts, and am excited to contribute to innovative projects.\",\n",
       "  \"As an aspiring data scientist, I possess a solid foundation in statistical knowledge, machine learning algorithms, and programming languages like Python and R. My undergraduate coursework included Data Structures, Machine Learning, and Data Mining, which equipped me with hands-on experience in data manipulation, visualization, and modeling. I've also worked on personal projects using datasets from Kaggle and UCI Machine Learning Repository, applying techniques to real-world problems such as customer churn prediction and sentiment analysis. I'm excited to leverage these skills in a collaborative team environment, learning from others and continuously growing my expertise in standard data tools like SQL, Tableau, and pandas.\",\n",
       "  \"As an aspiring data scientist, I possess a strong foundation in statistical analysis and programming skills. In my undergraduate studies, I completed coursework in machine learning, data mining, and data visualization. Additionally, I worked on several projects utilizing popular tools such as Python, R, and SQL to analyze and model real-world datasets. I'm excited to apply these skills in a collaborative team environment, where I can continue to learn and grow alongside like-minded professionals. I'm eager to contribute to innovative projects and expand my skill set with standard data analysis techniques.\",\n",
       "  \"As an aspiring data scientist, I bring a strong foundation in statistical modeling, machine learning, and data visualization. My academic coursework in statistics, mathematics, and computer science has equipped me with a solid understanding of programming languages (Python, R, SQL). I've successfully applied data analysis techniques to projects such as predictive modeling and data mining, leveraging tools like pandas, NumPy, and scikit-learn. Prior experience working with large datasets and collaborating with teams has honed my problem-solving skills. I'm eager to apply my skills to real-world problems in a collaborative environment, continually learning and growing within the team.\",\n",
       "  'As an aspiring data scientist, I bring a strong foundation in statistics, machine learning, and programming. Relevant coursework includes courses in linear algebra, probability, calculus, Python, R, and SQL. Throughout my academic journey, I completed projects utilizing these skills, such as analyzing customer behavior and predicting election outcomes. Prior experience involves working with data visualization tools like Tableau and Power BI. I am eager to apply data analysis techniques to real-world problems, leveraging collaboration to grow my skills within a team-oriented environment. I am excited to contribute to innovative solutions while continuously learning and expanding my skillset.',\n",
       "  \"As an aspiring data scientist, I possess a solid foundation in statistics, machine learning, and programming languages such as Python, R, and SQL. Through coursework, I've gained expertise in data preprocessing, visualization, and modeling using popular libraries like Pandas, NumPy, Matplotlib, and Scikit-learn. My academic projects involved analyzing real-world datasets from domains like healthcare and finance, applying clustering algorithms to customer segmentation, and developing predictive models using decision trees and neural networks. I'm eager to apply my skills in a collaborative team environment, continuously learning and growing with the company's data-driven initiatives.\",\n",
       "  \"As an aspiring data scientist, I bring a strong foundation in statistical inference, machine learning, and programming languages such as Python, R, and SQL. My undergraduate coursework included data analysis, data mining, and database management courses. I've completed several personal projects, including analyzing COVID-19 case trends and predicting housing prices using regression models. I'm eager to apply my skills in a real-world setting and continue learning from experienced professionals. I thrive in team environments and am excited to grow with a collaborative group, leveraging tools like Pandas, NumPy, Scikit-learn, and Tableau to drive business insights and solutions.\",\n",
       "  \"As an aspiring data scientist, I possess a strong foundation in statistics, programming, and data analysis. My undergraduate coursework included advanced courses in machine learning, linear algebra, and data visualization. I also completed several personal projects, such as analyzing Airbnb prices using regression models and identifying trends in COVID-19 case numbers. Prior experience includes working on a team project that applied predictive modeling to optimize inventory levels. I'm excited to apply my skills in a collaborative environment and continue growing through training and mentorship. I'm confident in standard data tools like R, Python, and SQL, and eager to expand my toolkit.\",\n",
       "  \"As an aspiring data scientist, I bring a solid foundation in statistics, mathematics, and computer science. Relevant coursework includes machine learning, data mining, and programming languages like Python and R. I've also worked on personal projects involving data visualization and predictive modeling, demonstrating my ability to apply theoretical concepts to real-world problems. Prior experience in data analysis and interpretation has honed my skills in Excel, SQL, and data visualization tools. I'm eager to join a collaborative team and continue growing my skills, exploring new tools and techniques, and driving business value through data-driven insights.\",\n",
       "  'As an aspiring data scientist, I bring a solid foundation in statistics, mathematics, and computer programming. My undergraduate coursework in Data Science and Mathematics has equipped me with strong analytical and problem-solving skills. I have also completed projects using popular data tools such as R, Python, and Tableau, allowing me to apply data analysis techniques to real-world problems. Prior experience working with datasets and presenting findings to non-technical audiences has given me confidence in communicating insights to diverse stakeholders. I am excited to join a collaborative team where I can learn from others and grow my skills.',\n",
       "  \"As an aspiring data scientist, I bring a solid foundation in statistics and programming. My coursework includes data structures, machine learning, and data visualization. I've also completed projects using Python and R, exploring applications in healthcare and finance. Prior experience has honed my attention to detail and analytical thinking. I'm eager to apply data analysis techniques to real-world problems, collaborating with a team to drive insights and business decisions. I'm comfortable with standard data tools, such as Excel, SQL, and Tableau, and excited to continue learning and growing within a collaborative environment to tackle new challenges and opportunities.\",\n",
       "  \"As an aspiring data scientist, I possess a strong foundation in statistical analysis and programming through courses like Linear Algebra, Probability, and Data Structures in college. I've also completed several personal projects utilizing Python libraries such as Pandas, NumPy, and Scikit-learn, demonstrating my ability to apply data analysis techniques to real-world problems. Prior experience in data visualization tools like Tableau and familiarity with database management systems like MySQL have further honed my skills. I'm eager to leverage these strengths within a collaborative team environment, continually seeking opportunities to expand my skill set and contribute to innovative projects.\",\n",
       "  \"As an aspiring data scientist, I bring a strong foundation in statistics, programming languages, and data visualization tools. My coursework has provided a solid understanding of machine learning algorithms, data modeling, and data mining techniques. Additionally, I have completed several projects that applied data analysis to real-world problems, including predicting housing prices and analyzing customer churn. Prior experience with popular tools like Python, R, SQL, and Tableau has given me hands-on proficiency. I'm excited to apply my skills in a collaborative team environment, where I can learn from others and contribute to innovative projects.\",\n",
       "  \"As an aspiring data scientist, I bring a solid foundation in statistical knowledge and programming skills. Coursework highlights include machine learning, data mining, and data visualization. Relevant projects showcase my ability to analyze complex datasets and draw actionable insights. Prior experience includes working with databases and data visualization tools like Tableau. I'm excited to apply data analysis techniques to real-world problems, leveraging my enthusiasm for continuous learning and growth. In a collaborative team environment, I thrive on feedback and camaraderie, aiming to develop strong skills in SQL, Python, and R while contributing to innovative projects.\",\n",
       "  \"As an aspiring data scientist, I bring a solid foundation in statistical reasoning, programming languages (Python, R), and machine learning fundamentals. Through coursework in data structures, databases, and machine learning, I've developed proficiency in tools like pandas, NumPy, scikit-learn, and TensorFlow. Personal projects showcase my ability to extract insights from datasets, perform data visualization, and implement predictive models. Prior experience in data analysis and visualization has given me a keen eye for pattern recognition and effective communication of results. I'm excited to join a collaborative team and continually grow my skills through mentorship and training opportunities.\",\n",
       "  'As an aspiring data scientist, I bring a solid foundation in statistics, programming languages (Python, R, SQL), and data visualization tools (Tableau, Power BI). My academic coursework has provided a strong understanding of machine learning algorithms, data mining techniques, and data modeling principles. Through personal projects and collaboration with friends on data-driven initiatives, I have applied data analysis techniques to real-world problems, refining my skills in data wrangling, feature engineering, and model interpretation. I am excited to join a collaborative team where I can learn from others, apply my skills to drive business insights, and continuously grow as a data scientist.',\n",
       "  \"As an aspiring data scientist, I bring a strong foundation in statistical modeling, machine learning, and data visualization. My coursework in statistics, computer science, and business analytics has equipped me with a solid understanding of data structures, algorithms, and programming languages like Python and R. I've worked on several projects applying data analysis techniques to real-world problems, including predictive modeling for customer churn and sentiment analysis for social media platforms. I'm eager to apply my skills in a collaborative team environment and continue learning from experienced professionals to drive business insights and inform data-driven decisions.\",\n",
       "  'As an aspiring data scientist, I bring a strong foundation in statistics and computer science to the table. My academic coursework in Machine Learning, Data Mining, and Data Analysis has provided a solid understanding of mathematical modeling, programming languages, and data visualization tools. I have also completed projects using Python, R, and SQL, with a focus on working with real-world datasets such as climate change impacts and public health outcomes. I am eager to apply my skills in a collaborative team environment, seeking opportunities for growth and learning within the organization.',\n",
       "  \"As an aspiring data scientist, I bring a strong foundation in statistical theory, machine learning, and programming languages such as Python and R. My coursework in advanced statistics, data visualization, and data mining has provided a solid understanding of data analysis techniques. Through personal projects, I've applied data analysis to real-world problems in healthcare, finance, and social media. I'm confident in my ability to work with popular data tools like Tableau, Excel, and SQL. I'm eager to grow my skills within a collaborative team environment, applying data-driven insights to drive business decisions and solving complex problems alongside experienced professionals.\",\n",
       "  \"As an aspiring data scientist, I bring a strong foundation in statistical theory, programming languages (Python, R), and data visualization tools (Tableau, Matplotlib). Throughout my academic journey, I've completed coursework in machine learning, data mining, and business analytics. Additionally, I've contributed to several projects involving exploratory data analysis, predictive modeling, and data-driven storytelling. Prior experience as a research assistant has also honed my skills in data wrangling and collaboration. I'm eager to apply my knowledge to real-world problems within a collaborative team environment, seeking opportunities to grow and develop my skills alongside experienced professionals.\",\n",
       "  \"As an aspiring data scientist, I bring a strong foundation in statistics, machine learning, and programming languages such as Python, R, and SQL. My coursework includes data structures, linear algebra, and data mining, with a focus on hands-on experience through projects like predicting stock prices and analyzing customer behavior. Prior to starting my graduate program, I completed several personal projects using TensorFlow and scikit-learn, showcasing my ability to apply machine learning concepts to real-world problems. I'm excited to join a team where I can continue to learn and grow with experienced colleagues, applying data analysis techniques to drive business value.\",\n",
       "  \"As an aspiring data scientist, I bring a strong foundation in statistics and machine learning, supported by coursework in data structures, data mining, and programming languages (Python, R, SQL). I have successfully completed projects involving data analysis, visualization, and modeling using popular tools like Tableau, Power BI, and scikit-learn. Prior experience in data quality and exploration has allowed me to develop a strong sense of curiosity and problem-solving skills. I'm eager to apply these skills to real-world problems and grow within a collaborative team environment, surrounded by experienced professionals who can guide my growth as a data scientist.\",\n",
       "  'As an aspiring data scientist, I bring a strong foundation in statistics, machine learning, and programming. I have completed coursework in data science, Python, R, SQL, and data visualization tools like Tableau and Power BI. My undergraduate project involved analyzing climate change patterns using spatial analysis techniques, highlighting my ability to apply data analysis skills to real-world problems. With prior experience in research and academic settings, I am eager to join a collaborative team where I can grow my skills and contribute to meaningful projects that drive business insights and growth.',\n",
       "  \"As an aspiring data scientist, I bring a strong foundation in statistical and computational methods, as well as proficiency in Python and R programming languages. Relevant coursework includes machine learning, data visualization, and database management. I've worked on various projects that involve data analysis, including customer segmentation, sentiment analysis, and predictive modeling. With prior experience in data analysis and visualization using tools like Tableau and Power BI, I'm eager to apply my skills to real-world problems. I'm excited to join a collaborative team environment where I can learn and grow alongside experienced professionals, continuing to develop my data science skills.\",\n",
       "  \"As an aspiring data scientist, I bring a strong foundation in statistics and programming languages, including Python, R, and SQL. Coursework in machine learning, data mining, and data visualization has provided me with a solid understanding of data analysis techniques. Through personal projects and contributions to Kaggle competitions, I've applied data science principles to real-world problems, developing proficiency with tools like pandas, NumPy, and scikit-learn. I'm eager to collaborate with experienced professionals in a team environment to expand my skill set and tackle complex problems. I'm excited to join a dynamic team and apply my skills to drive meaningful insights.\",\n",
       "  \"As an aspiring data scientist, I bring a strong foundation in statistics, machine learning, and data visualization through coursework in Data Structures, Machine Learning, and Statistical Computing. I've worked on several personal projects applying these concepts, including predictive modeling, natural language processing, and data mining. Prior experience as a research assistant has given me hands-on practice with tools like Python, R, and SQL. I'm eager to apply my skills to real-world problems and learn from others in a collaborative team environment. I'm excited to grow and develop within an organization that values innovation and teamwork.\",\n",
       "  \"As an aspiring data scientist, I possess a solid foundation in statistical and computational techniques, including linear algebra, probability, and machine learning. My coursework covers data structures, databases, and programming languages such as Python and R. Through personal projects, I've applied data analysis to real-world datasets, gaining hands-on experience with tools like Excel, Tableau, and SQL. Prior to starting my career journey, I worked on a team project analyzing sports performance data, leveraging data visualization techniques to communicate findings effectively. I'm eager to apply these skills in a collaborative environment, continually growing my expertise in data analysis and related tools.\",\n",
       "  \"As an aspiring data scientist, I bring a solid foundation in statistics and computer programming, supplemented by relevant coursework in machine learning, data visualization, and database management. My projects showcase my ability to collect, analyze, and interpret complex data sets, resulting in actionable insights. Prior experience has also honed my skills in tools such as Python, R, and SQL. I'm eager to apply these skills to real-world problems and learn from a collaborative team environment. I'm confident that my passion for learning and enthusiasm for data analysis will drive me to grow and contribute to the organization's success.\",\n",
       "  \"As an aspiring data scientist, I possess a strong foundation in statistics, machine learning, and data visualization through coursework at [University Name]. My academic projects involve analyzing publicly available datasets on topics like climate change and healthcare, applying techniques such as regression analysis and clustering. Prior to joining academia, I worked part-time as a data analyst where I honed skills with tools like Excel, SQL, and Tableau. I'm enthusiastic about learning cutting-edge data analysis techniques and collaborating with a team to apply them to real-world problems. I'm eager to continue growing my skills within a collaborative environment.\",\n",
       "  \"As an aspiring data scientist, I bring a strong foundation in statistical knowledge and programming skills. Coursework includes machine learning, data mining, and data visualization. I have completed projects using popular libraries like Pandas, NumPy, and scikit-learn, applying techniques to real-world datasets. Prior experience with data analysis tools such as Excel, SQL, and Tableau further enhances my skillset. I'm excited to apply these skills in a collaborative team environment and continually grow through training and mentorship. My enthusiasm for learning data-driven insights and driving business value aligns perfectly with this role, making me an ideal fit.\",\n",
       "  \"As an aspiring data scientist, I bring a strong foundation in statistics and computer programming. Coursework includes machine learning, linear algebra, and data visualization. Relevant projects involve analyzing dataset on public health trends and social media sentiment analysis. Prior experience as a research assistant helped develop skills in data manipulation and interpretation. I'm enthusiastic about applying data analysis techniques to real-world problems, leveraging tools like Python, R, and SQL. In a collaborative team environment, I thrive on feedback and continuous learning, seeking opportunities to grow my skills and contribute to innovative projects that drive meaningful impact.\",\n",
       "  \"As an aspiring data scientist, I bring a strong foundation in statistics, machine learning, and programming. Coursework in data structures, algorithms, and data visualization has prepared me for hands-on analysis. Personal projects, such as analyzing customer behavior and predicting disease outbreaks, demonstrate my ability to apply data analysis techniques. Prior experience with tools like R, Python, SQL, and Excel has solidified my skills in data manipulation and interpretation. I'm eager to continue learning and collaborating within a team environment to tackle complex problems and drive business insights. I'm excited to contribute to innovative projects and grow as a data professional.\",\n",
       "  \"As an aspiring data scientist, I bring a strong foundation in statistics, computer science, and data analysis. Coursework highlights include machine learning, programming languages (Python, R), and data visualization tools (Tableau, Matplotlib). Personal projects utilize these skills to analyze and visualize real-world datasets, such as climate change trends and public health outcomes. Prior experience includes working with various data sets and collaborating on group assignments. I'm eager to apply my analytical mindset to drive business insights within a collaborative team environment, continuing to grow my skills in areas like natural language processing and predictive modeling.\",\n",
       "  \"As an aspiring data scientist, I bring a strong foundation in statistical and computational methods. In my undergraduate studies, I excelled in courses on data structures, machine learning, and data visualization. I also completed several projects that applied these concepts to real-world problems, such as predictive modeling for healthcare outcomes and customer churn analysis. With proficiency in Python, R, and SQL, I'm well-equipped to work with various data tools. I'm eager to apply my skills within a collaborative team environment, where I can grow and learn alongside experienced professionals, driving innovation and impact through data-driven insights.\",\n",
       "  \"As an aspiring data scientist, I bring a strong foundation in statistics, machine learning, and programming to the table. Through coursework in data structures, algorithms, and data visualization, I've developed a solid understanding of data analysis concepts. Additionally, I've worked on several personal projects utilizing Python and R, applying data manipulation and modeling techniques to real-world problems. With a keen interest in exploring innovative applications of machine learning, I'm eager to grow my skills within a collaborative team environment. I'm confident that my passion for data-driven insights and strong work ethic make me an ideal candidate for this role.\",\n",
       "  \"As an aspiring data scientist, I bring a strong foundation in statistics, machine learning, and data visualization. My coursework at [University Name] covered topics like linear regression, decision trees, clustering, and neural networks. I also completed projects using tools like Python, R, and Tableau, analyzing datasets from various domains such as healthcare and finance. Prior experience includes working with large datasets and applying statistical techniques to solve business problems. I'm eager to learn and apply data analysis techniques to drive real-world impact in a collaborative team environment, where I can continue to grow my skills and expertise.\",\n",
       "  'As an aspiring data scientist, I bring a strong foundation in statistics, mathematics, and computer science. Coursework in machine learning, data visualization, and database management has equipped me with the technical skills necessary for analysis and interpretation of complex data sets. My personal projects demonstrate my ability to apply data analysis techniques to real-world problems, utilizing tools such as Python, R, and SQL. I am eager to learn and grow within a collaborative team environment, applying data-driven insights to drive business decisions and optimize operations. I thrive in dynamic environments, seeking opportunities to explore new skills and challenges.',\n",
       "  'As an aspiring data scientist, I bring a strong foundation in statistical and computational methods, including Python programming, R, and SQL. Coursework in machine learning, data visualization, and data mining has provided a solid understanding of data analysis techniques. Through personal projects, I have applied these skills to real-world problems in healthcare and finance. I am eager to grow my skills in a collaborative team environment and explore new tools like TensorFlow and scikit-learn. With a passion for learning and solving complex problems, I am confident in my ability to contribute to innovative data-driven solutions.',\n",
       "  \"As an aspiring data scientist, I bring a strong foundation in statistics, programming languages (Python, R, SQL), and data visualization tools (Tableau, Matplotlib). My academic background includes coursework in machine learning, data mining, and data engineering. I've worked on personal projects applying these skills to real-world problems, including predicting stock prices and analyzing customer behavior. I'm eager to apply my knowledge in a collaborative team environment, leveraging industry-standard tools and technologies to drive business insights. I'm excited to continue learning and growing with the company, driven by a passion for data-driven decision making.\",\n",
       "  \"As an aspiring data scientist, I bring a strong foundation in statistics, programming, and data visualization through coursework at XYZ University (2020-2022). My academic projects, including analyzing consumer behavior for a marketing firm and predicting housing prices using machine learning techniques, showcased my ability to apply data analysis to real-world problems. Prior experience as a research assistant helped me develop skills in data collection, cleaning, and manipulation. I'm excited to apply my knowledge in an entry-level role, where I can learn from experienced colleagues and contribute to innovative projects that drive meaningful insights.\",\n",
       "  \"As an aspiring data scientist, I bring a strong foundation in statistical inference, machine learning, and data visualization. Through coursework in introductory statistics, linear algebra, and data structures, I developed a solid understanding of mathematical principles underlying data analysis. Additionally, I completed projects utilizing Python libraries such as Pandas, NumPy, and Scikit-learn to apply data modeling techniques to real-world problems. Prior experience in data wrangling and analysis using Excel has also honed my skills. I'm excited to join a collaborative team where I can grow with standard data tools like Tableau and TensorFlow while tackling complex challenges side-by-side.\",\n",
       "  \"As an aspiring data scientist, I bring a solid foundation in statistical modeling, machine learning, and data visualization. Coursework has provided me with a strong grasp of programming languages (Python, R), data manipulation libraries (Pandas, NumPy), and statistical software (R Studio). I've also completed projects involving data cleaning, predictive modeling, and data-driven storytelling. Prior experience includes working on team-based research initiatives and analyzing datasets for personal interests. I'm eager to apply my skills in a collaborative environment, learning from others and contributing to innovative solutions. I'm excited to grow my expertise in a dynamic and supportive setting.\",\n",
       "  \"As an aspiring data scientist, I bring a strong foundation in statistics, machine learning, and programming languages such as Python and R. My undergraduate studies included coursework in data structures, algorithms, and computer science. I also have hands-on experience with popular tools like Excel, SQL, Tableau, and pandas. Through personal projects and hackathons, I've developed skills in data visualization, predictive modeling, and text analysis. I'm excited to apply my analytical skills to real-world problems in a collaborative team environment. I'm eager to learn from experienced professionals and grow with the organization, utilizing my enthusiasm for data science to drive innovation.\",\n",
       "  \"As an aspiring data scientist, I bring a strong foundation in statistics and computer science to the table. Coursework in machine learning, linear algebra, and programming languages such as Python and R has equipped me with a solid understanding of data analysis techniques. My academic projects involved analyzing customer behavior and predicting churn rates using regression models. Prior experience working with datasets and tools like Excel, SQL, and Tableau has also honed my analytical skills. I'm excited to apply these skills in a collaborative environment, learning from colleagues and growing as a professional while tackling real-world problems that challenge me.\",\n",
       "  \"As an aspiring data scientist, I bring a solid foundation in statistical concepts and programming skills to drive insights from data. My academic background includes coursework in machine learning, data mining, and visualization. Throughout my projects, I've applied techniques such as regression, clustering, and decision trees to real-world datasets. Prior experience has equipped me with comfort using standard tools like Python, R, SQL, and Tableau. I'm eager to leverage these skills in a collaborative team environment to tackle complex problems and contribute meaningfully. I thrive in dynamic settings, where learning and growth are encouraged alongside teamwork and innovation.\",\n",
       "  \"As an aspiring data scientist, I bring a strong foundation in statistics, computer science, and data analysis. My coursework includes machine learning, data mining, and programming languages such as Python, R, and SQL. I've also developed projects on datasets from Kaggle and UCI Machine Learning Repository, applying techniques to predict outcomes and visualize insights. Prior experience in data visualization tools like Tableau and data manipulation libraries like Pandas has given me hands-on familiarity with industry-standard software. I'm excited to apply my skills to real-world problems and continue learning within a collaborative team environment.\",\n",
       "  'As an aspiring data scientist, I bring a solid foundation in statistics, machine learning, and programming. I have completed coursework in data science, Python, R, and SQL, with hands-on experience using libraries such as Pandas, NumPy, and Scikit-learn. My personal projects involve analyzing sports data and customer behavior to inform business decisions. Prior to entering the workforce, I also worked on a predictive modeling project for a non-profit organization. I am eager to apply my skills in a collaborative team environment and continuously develop my expertise with tools like Tableau, Excel, and SQL.',\n",
       "  \"As an aspiring data scientist, I bring a strong foundation in statistics and computer science. I've completed coursework in machine learning, data visualization, and data mining at XYZ University. Through personal projects, such as analyzing customer behavior on e-commerce platforms and identifying trends in social media sentiment, I've developed skills in Python, R, and SQL. Prior experience as a research assistant has honed my attention to detail and analytical mindset. I'm eager to apply these skills in a collaborative team environment, continually seeking opportunities to learn and grow within the company.\",\n",
       "  \"As an aspiring data scientist, I possess a solid foundation in statistical inference, machine learning, and programming fundamentals. Relevant coursework includes Python, R, SQL, and statistical modeling. My projects involve analyzing real-world datasets on various domains, such as healthcare and finance. Prior experience includes contributing to group research papers and participating in data science competitions. I'm excited to apply my skills to drive business value through data-driven insights. I'm eager to learn from a collaborative team environment, leveraging industry-standard tools like pandas, NumPy, and scikit-learn.\",\n",
       "  \"As an aspiring data scientist, I bring a strong foundation in statistics, machine learning, and programming to the table. I've completed coursework in data structures, linear algebra, and statistical inference, solidifying my understanding of key concepts. Additionally, I've worked on several personal projects involving data visualization and predictive modeling, demonstrating my ability to apply theoretical techniques to real-world problems. I'm comfortable with standard tools such as Python, R, and SQL, and I'm eager to expand my skillset within a collaborative team environment. I thrive in fast-paced settings and am excited to contribute to solving complex business challenges.\",\n",
       "  \"As an aspiring data scientist, I bring a strong foundation in statistics, mathematics, and computer programming. Coursework has covered linear algebra, probability, machine learning, and programming languages like Python and R. Through projects, I've applied data analysis techniques to datasets from various industries, showcasing problem-solving skills and attention to detail. Prior experience as a research assistant has honed my ability to collect, clean, and visualize data. I'm eager to apply these skills in a collaborative team environment, leveraging tools like NumPy, pandas, and scikit-learn. I'm enthusiastic about learning and growing with the company, tackling complex problems, and driving business outcomes through data-driven insights.\",\n",
       "  'As an aspiring data scientist, I bring a strong foundation in statistics, machine learning, and data visualization. Throughout my coursework at [University Name], I excelled in courses such as Data Mining, Machine Learning, and Business Analytics. Additionally, I completed several personal projects that applied data analysis techniques to real-world problems, including predictive modeling and sentiment analysis. Prior to this role, I worked on a team project analyzing customer purchase behavior for a local business. I am excited to apply my skills in a collaborative environment, continually learning from colleagues and expanding my skill set using tools like Python, R, and Tableau.',\n",
       "  \"As an aspiring data scientist, I bring a solid foundation in statistics, machine learning, and data visualization. Through coursework in Python, R, SQL, and data structures, I've developed proficiency in data manipulation, analysis, and modeling. Relevant projects include analyzing customer behavior for a university marketing campaign and creating predictive models for a local healthcare organization. Prior experience with tools like Excel, Tableau, and pandas has honed my skills in data wrangling and visualization. I'm eager to apply these skills to real-world problems and continue growing within a collaborative team environment, leveraging feedback and mentorship to expand my expertise.\",\n",
       "  'As an aspiring data scientist, I bring a solid foundation in statistics, machine learning, and programming languages like Python and R. Coursework has equipped me with hands-on experience with data preprocessing, visualization, and modeling using popular libraries such as Pandas, NumPy, Matplotlib, and Scikit-learn. Personal projects have allowed me to apply data analysis techniques to real-world problems in healthcare, finance, and marketing. I am excited to leverage my enthusiasm for learning and collaboration to drive meaningful insights within a dynamic team environment. I am eager to grow my skills and contribute to innovative solutions that drive business success.',\n",
       "  'As an aspiring data scientist, I bring a strong foundation in statistical modeling, data visualization, and machine learning. Coursework in R programming, Python, and SQL has equipped me with hands-on experience in data analysis and manipulation. My personal projects have applied these skills to real-world problems, demonstrating my ability to communicate insights through clear and concise visualizations. Prior experience working with datasets from Kaggle competitions and volunteering as a data analyst for non-profit organizations has honed my attention to detail and problem-solving skills. I am eager to apply my knowledge in a collaborative team environment and continue learning.',\n",
       "  \"As an aspiring data scientist, I possess a solid foundation in statistical modeling, machine learning, and data visualization through coursework in data science and computer science. Notably, I completed projects involving regression analysis, clustering, and natural language processing using Python, R, and SQL. My prior experience with data cleaning, visualization, and exploration tools has equipped me to effectively analyze and communicate insights. I'm eager to apply my skills to real-world problems and continuously learn from collaborative teams. I'm confident in leveraging standard data tools to drive business outcomes while seeking opportunities for skill growth within a dynamic environment.\",\n",
       "  \"As an aspiring data scientist, I possess a solid foundation in statistics, programming, and machine learning through coursework in university and online platforms such as Coursera. My projects, including analyzing climate trends and predicting customer churn, demonstrate my ability to apply data analysis techniques to real-world problems. Prior experience with tools like Python, R, Tableau, and SQL has equipped me with hands-on skills. I'm excited to continue learning and growing within a collaborative team environment, leveraging my analytical mindset and enthusiasm for innovative solutions to drive business growth and insights. Collaboration is key to my professional development.\",\n",
       "  \"As an aspiring data scientist, I bring a strong foundation in statistics, computer science, and data visualization through coursework at [University Name]. I've developed proficiency in popular data analysis tools like Python, R, Tableau, and Excel. Through personal projects, such as analyzing customer behavior for a fictional e-commerce company and visualizing climate change trends using satellite data, I've honed my skills in data wrangling, modeling, and interpretation. I'm excited to apply my knowledge to drive business growth and insights within a collaborative team environment. I'm eager to learn from others and continue growing my skills alongside the organization.\",\n",
       "  \"As an aspiring data scientist, I bring a strong foundation in statistics and programming languages, including Python, R, and SQL. Coursework in machine learning, data visualization, and data mining has equipped me with the knowledge to extract insights from complex datasets. Through personal projects, such as analyzing Airbnb pricing patterns and predicting customer churn, I've developed practical skills in data preprocessing, feature engineering, and model selection. I'm eager to apply these skills in a collaborative team environment, where I can learn from others and grow my expertise in tools like Tableau, Power BI, or D3.js.\",\n",
       "  \"As an aspiring data scientist, I bring a solid foundation in statistical and mathematical concepts, complemented by relevant coursework in machine learning, data visualization, and programming languages like Python and R. I've successfully completed projects involving predictive modeling, data wrangling, and storytelling with data, showcasing my ability to extract insights from complex datasets. Prior experience in data analysis and problem-solving has honed my critical thinking skills. I'm eager to apply data-driven approaches to real-world problems within a collaborative team environment, driven by my passion for learning and growth.\",\n",
       "  \"As an aspiring data scientist, I bring a strong foundation in statistical methods, machine learning algorithms, and programming languages such as Python, R, and SQL. My academic coursework has provided a solid understanding of data analysis, visualization, and modeling techniques. Through personal projects and contributions to open-source datasets, I have gained hands-on experience with tools like pandas, NumPy, and scikit-learn. I am eager to apply my skills to real-world problems and collaborate with experienced professionals in a dynamic team environment. I'm excited to continue learning and growing alongside a supportive team.\",\n",
       "  'As an aspiring data scientist, I possess a solid foundation in statistics, machine learning, and programming languages such as Python, R, and SQL. My coursework has equipped me with expertise in data visualization, data preprocessing, and modeling techniques. Through personal projects, I have applied data analysis to real-world problems in healthcare, finance, and marketing. I am eager to bring my skills to a collaborative team environment, leveraging tools like pandas, NumPy, scikit-learn, and Tableau. I thrive in fast-paced environments, seeking opportunities to grow my expertise, explore new concepts, and contribute to innovative projects that drive business value.',\n",
       "  \"As an aspiring data scientist, I possess strong foundational knowledge in statistics, machine learning, and data visualization. Through coursework in university, I have gained proficiency in Python, R, SQL, and various data manipulation libraries. My personal projects involve analyzing healthcare datasets to improve disease diagnosis accuracy and sentiment analysis for customer service chatbots. With prior experience as a research assistant, I've developed strong problem-solving skills and comfort with standard data tools like pandas, NumPy, and scikit-learn. I'm eager to apply my skills in real-world scenarios, collaborating with teams to drive data-driven insights and innovative solutions that drive business impact.\",\n",
       "  \"As an aspiring data scientist, I bring a strong foundation in statistical modeling, machine learning, and data visualization. Coursework highlights include programming languages (Python, R), data structures, and algorithms. Notable projects showcase my ability to work with datasets from various industries, including finance and healthcare. Prior experience includes contributing to open-source projects and participating in data analysis competitions. I'm excited to apply these skills to real-world problems within a collaborative team environment. I'm eager to learn and grow, particularly with tools like TensorFlow, Pandas, and SQL, and am confident that my enthusiasm and adaptability make me an ideal fit for this role.\",\n",
       "  'As an aspiring data scientist, I possess a solid foundation in statistical and mathematical concepts, including linear algebra, calculus, and probability theory. Through coursework in machine learning, data mining, and data visualization, I have developed proficiency in popular tools such as Python, R, and SQL. I have also worked on various personal projects, including predictive modeling and data-driven storytelling, showcasing my ability to apply data analysis techniques to real-world problems. I am eager to join a collaborative team environment where I can continue learning and growing with like-minded professionals, leveraging standard data tools to drive business insights and innovation.',\n",
       "  \"As an aspiring data scientist, I bring a strong foundation in statistics, mathematics, and computer programming. My coursework includes machine learning, data mining, and data visualization courses. I've also completed several personal projects, such as analyzing customer behavior using Python and R, and building predictive models for sports teams. With prior experience in data analysis and visualization tools like Tableau and Excel, I'm confident in my ability to apply data-driven insights to real-world problems. I'm eager to join a collaborative team environment to grow my skills and stay up-to-date with industry advancements.\",\n",
       "  \"As an aspiring data scientist, I bring a strong foundation in statistics, computer programming, and data analysis. Coursework has equipped me with a solid understanding of machine learning algorithms, data visualization techniques, and statistical modeling. Notable projects include building predictive models for stock market trends and analyzing customer churn patterns for a fictional e-commerce company. Prior experience as a data analyst intern has given me hands-on familiarity with tools like Excel, Python, R, and Tableau. I'm eager to apply my skills to real-world problems in a collaborative team environment, driven by a passion for learning and continuous growth.\",\n",
       "  \"As an aspiring data scientist, I bring a strong foundation in statistics and data analysis. Coursework highlights include Machine Learning, Data Mining, and Data Visualization. Through personal projects, such as analyzing social media trends and predicting election outcomes, I've developed proficiency with tools like Python, R, and Tableau. Prior experience includes working with datasets to identify insights and present findings to non-technical audiences. I'm eager to apply my skills to drive business decisions in a collaborative environment, where I can learn from others and contribute to innovative solutions. I thrive in teams and am excited to grow with the organization.\",\n",
       "  \"As an aspiring data scientist, I possess a solid foundation in statistics, machine learning, and programming. Coursework highlights include advanced data structures, data mining, and data visualization techniques. I've developed proficiency in Python, R, and SQL through hands-on projects and personal endeavors. Prior experience includes data analysis for academic research and contributing to open-source data science initiatives. I'm excited to apply my skills to drive business insights and tackle real-world problems. I thrive in collaborative environments, eager to grow with a team that fosters continuous learning and skill development. I'm confident in my ability to contribute to a dynamic data-driven organization.\",\n",
       "  \"As an aspiring data scientist, I bring a strong foundation in statistical modeling, machine learning, and data visualization. Through coursework in Python, R, and SQL, I have developed proficiency in extracting insights from various datasets. Personal projects showcase my ability to analyze and interpret complex data sets, with notable achievements in predictive modeling and data-driven recommendations. Prior experience in business intelligence tools has solidified my comfort with standard data analysis software. I'm eager to apply my skills within a collaborative team environment, continually learning and expanding my expertise to tackle real-world challenges and drive informed decision-making.\",\n",
       "  \"As an aspiring data scientist, I bring a strong foundation in statistical and computational methods, with coursework in Machine Learning, Data Mining, and Database Systems. I have worked on several projects applying these concepts, including analyzing customer behavior for a retail client and developing predictive models for a non-profit organization's fundraising efforts. I am proficient in standard tools such as Python, R, SQL, and Tableau, and am eager to grow my skills with advanced techniques like deep learning and natural language processing. I thrive in collaborative environments and look forward to contributing to and learning from a team of data professionals.\",\n",
       "  \"As an aspiring data scientist, I bring a strong foundation in statistics, mathematics, and computer science. Coursework includes machine learning, data mining, and programming languages such as Python and R. I've completed projects on predicting customer churn, analyzing stock market trends, and building predictive models for healthcare outcomes. Prior experience with tools like Excel, SQL, Tableau, and Pandas solidifies my ability to work with datasets effectively. I'm excited to apply data analysis techniques to drive business insights and grow within a collaborative team environment, seeking opportunities to learn from experienced professionals and contribute to innovative projects.\",\n",
       "  \"As an aspiring data scientist, I bring a strong foundation in statistics, computer science, and programming languages such as Python and R. My academic coursework includes machine learning, data mining, and data visualization. Through various personal projects and collaborations, I've developed expertise in data analysis, modeling, and communication using tools like pandas, NumPy, and Tableau. I'm eager to apply my skills to real-world problems and continue growing within a collaborative team environment. With a passion for staying up-to-date with industry trends and best practices, I'm excited to join a dynamic team and contribute to data-driven insights.\",\n",
       "  \"As an aspiring data scientist, I bring a strong foundation in statistical analysis, programming, and data visualization. My undergraduate coursework included courses in linear algebra, probability, statistics, R, and Python. Through various projects, I've applied machine learning algorithms to real-world datasets, including predictive modeling for customer churn and sentiment analysis for social media trends. Prior experience in data wrangling and visualization tools has solidified my skills. I'm eager to apply my knowledge in a collaborative team environment, leveraging industry-standard tools like Tableau and Power BI. I'm excited to learn and grow with the team, tackling complex problems together.\",\n",
       "  \"As an aspiring data scientist, I bring a strong foundation in statistics and computer programming to the table. Coursework in machine learning, data visualization, and data mining has provided me with a solid understanding of fundamental concepts. Relevant projects include developing predictive models using scikit-learn and creating interactive dashboards with Tableau. Prior experience working on team-based projects and contributing to open-source initiatives has honed my communication skills. I'm excited to apply my analytical skills to real-world problems, leveraging tools like Excel, Python, R, and SQL to drive business insights. Collaboration is key; I thrive in a dynamic team environment.\",\n",
       "  \"As an aspiring data scientist, I bring a strong foundation in statistical modeling, machine learning, and data visualization. My undergraduate coursework in Computer Science and Statistics provided a solid grasp of programming languages (Python, R), database management systems, and data analysis techniques. Through various personal projects, I've applied machine learning algorithms to predict stock prices, identify trends in social media data, and analyze customer behavior. I'm excited to apply my skills in a collaborative team environment, where I can learn from others and contribute to driving insights-driven decision-making. I'm eager to grow with the company's evolving needs.\",\n",
       "  \"As an aspiring data scientist, I bring a solid foundation in statistics and mathematics, supported by coursework in machine learning, data mining, and programming languages such as Python, R, and SQL. Throughout my academic journey, I've worked on various projects, including predictive modeling, data visualization, and text analysis, to develop problem-solving skills and a passion for extracting insights from complex datasets. With a strong desire to apply data analysis techniques to real-world problems, I'm eager to join a collaborative team and grow my skills within a supportive environment, leveraging tools like pandas, NumPy, and scikit-learn to drive business value.\",\n",
       "  \"As an aspiring data scientist, I bring a solid foundation in statistics and computer programming. My undergraduate coursework includes machine learning, data mining, and data visualization. I've also worked on several personal projects, such as analyzing consumer behavior using clustering algorithms and creating predictive models for stock market trends. Prior to this role, I gained experience with tools like Python, R, and SQL, and have a solid understanding of statistical concepts. I'm eager to apply my skills in a collaborative environment, learning from others and contributing to impactful projects that drive business growth and informed decision-making.\",\n",
       "  \"As an aspiring data scientist, I bring a strong foundation in statistics, machine learning, and programming. My academic background includes courses on linear algebra, probability, and data visualization. In addition, I've completed projects utilizing Python, R, and SQL for data wrangling, analysis, and modeling. I'm excited to apply my skills to real-world problems and contribute to a collaborative team environment. With proficiency in standard tools like Pandas, NumPy, and Scikit-learn, I'm eager to grow my expertise in areas like natural language processing, computer vision, or predictive modeling. I thrive in dynamic environments where data analysis meets innovative solutions.\",\n",
       "  \"As an aspiring data scientist, I bring a strong foundation in statistical methods, programming languages, and data visualization tools. Coursework includes Machine Learning, Data Mining, and Data Analysis. Notable projects involve building predictive models for customer churn and analyzing the impact of marketing campaigns on sales. Prior experience includes working with datasets from Kaggle competitions and contributing to open-source projects. I'm eager to apply my skills in a collaborative team environment and continue learning new techniques, particularly those leveraging cloud-based tools like AWS and Python libraries such as Pandas and NumPy.\",\n",
       "  \"As an aspiring data scientist, I bring a strong foundation in statistics, computer programming, and data visualization. Coursework highlights include machine learning, linear regression, and data mining. Personal projects showcase my proficiency with Python, R, and SQL. Prior experience includes working on datasets for academic research and volunteering at a non-profit organization to analyze their donor database. I'm eager to apply these skills in real-world settings, collaborating with teams to drive insights-driven decisions. With a strong desire to continuously learn and grow, I'm excited to join an organization that values knowledge-sharing and innovation.\",\n",
       "  \"As an aspiring data scientist, I bring a solid foundation in statistical theory, machine learning, and programming languages such as Python and R. Coursework highlights include Data Mining, Machine Learning, and Data Visualization. Notable projects demonstrate my ability to apply these concepts to real-world problems, with notable achievements including data-driven recommendations systems and predictive models. Prior experience includes internships at data analytics firms and contributing to open-source datasets. I'm eager to collaborate with a team to drive innovation through data analysis and visualization. I'm confident that, with growth opportunities, I'll continue to expand my skills and expertise.\",\n",
       "  \"As an aspiring data scientist, I possess a solid foundation in statistical and computational methods through my coursework in statistics, machine learning, and data visualization. Relevant projects include analyzing customer behavior patterns for e-commerce platforms and developing predictive models for disease diagnosis using medical datasets. Prior experience as a research assistant has honed my skills in programming languages such as Python and R. I'm excited to apply data analysis techniques to real-world problems, leveraging tools like pandas, NumPy, and scikit-learn. In a collaborative environment, I thrive on sharing knowledge and learning from others to grow my expertise in data science.\",\n",
       "  \"As an aspiring data scientist, I bring a strong foundation in statistics and computer science to drive analytical insights. Relevant coursework includes machine learning, data mining, and data visualization. I've also worked on several personal projects, applying data analysis techniques to real-world problems, such as predictive modeling and data-driven decision-making. With proficiency in tools like Python, R, SQL, and Tableau, I'm eager to leverage my skills in a collaborative team environment. I'm passionate about staying up-to-date with industry trends and continuing to learn from others, aiming to contribute to meaningful projects that drive business growth and improvement.\",\n",
       "  \"As an aspiring data scientist, I bring a solid foundation in statistics, machine learning, and data visualization through coursework at XYZ University. Relevant projects include analyzing customer behavior for an e-commerce company and developing predictive models using scikit-learn. Prior experience as a research assistant has honed my ability to collect, clean, and analyze large datasets. I'm eager to apply my skills to real-world problems and grow within a collaborative team environment. Familiarity with standard data tools such as Python, R, and Excel, I'm excited to develop new skills and contribute to projects that drive business insights and growth.\",\n",
       "  \"As an aspiring data scientist, I possess a solid foundation in statistical analysis, machine learning, and data visualization through coursework at [University Name]. My projects, such as analyzing climate trends and predicting customer churn, demonstrate my ability to apply data-driven insights to real-world problems. I'm proficient in standard tools like Python, R, SQL, and Tableau, with a growing proficiency in machine learning frameworks like scikit-learn and TensorFlow. I'm eager to learn and grow within a collaborative team environment, where I can leverage my enthusiasm for data analysis and drive meaningful outcomes through innovative solutions and strategic partnerships.\",\n",
       "  'As an aspiring data scientist, I bring a solid foundation in statistics and computer science to the table. Relevant coursework includes machine learning, data visualization, and database management. I have completed several projects applying data analysis techniques to real-world problems, such as analyzing customer churn patterns in retail datasets. Prior experience with tools like Excel, Python, R, and Tableau has also honed my skills in data manipulation and visualization. I am eager to apply these skills within a collaborative team environment and continuously learn new techniques to tackle complex problems. I am excited about the opportunity to grow and contribute.',\n",
       "  \"As an aspiring data scientist, I bring a solid foundation in statistical concepts, machine learning, and programming languages such as Python, R, and SQL. Throughout my coursework, I excelled in projects that combined data analysis with real-world applications, including sentiment analysis for social media datasets and predictive modeling for customer churn detection. Prior to this role, I honed my skills through personal projects and contributed to open-source initiatives. I'm eager to apply my knowledge in a collaborative team environment, learning from others and contributing to innovative solutions. I'm excited to grow and develop within an organization that values data-driven insights.\",\n",
       "  \"As an aspiring data scientist, I bring a solid foundation in statistics and computer science. My coursework includes machine learning, programming languages (Python, R), and data visualization using Tableau and Matplotlib. I've worked on personal projects utilizing scikit-learn, TensorFlow, and Excel to analyze and solve business problems. Prior experience with data manipulation and analysis tools, such as Pandas and NumPy, has equipped me with hands-on skills. I'm eager to apply my knowledge in a collaborative team environment and continue growing through training and mentorship. I thrive in dynamic settings where learning and problem-solving are valued.\",\n",
       "  \"As an aspiring data scientist, I bring a strong foundation in statistics, computer science, and data visualization. Coursework highlights include machine learning, data mining, and programming languages such as Python, R, and SQL. Personal projects showcase my ability to analyze complex datasets and present findings in a clear, concise manner. Prior experience with tools like pandas, NumPy, and scikit-learn demonstrates my comfort with standard data analysis software. I'm eager to apply my skills to real-world problems and continue learning within a collaborative team environment. I'm excited to grow with the company and contribute to innovative projects.\",\n",
       "  \"As an aspiring data scientist, I bring a strong foundation in statistics, machine learning, and data visualization. My undergraduate coursework includes courses like Data Mining, Machine Learning, and Data Analytics. Through personal projects, I've applied techniques such as regression analysis, clustering, and text analysis to solve real-world problems. Prior experience with tools like Python, R, and SQL has enabled me to extract insights from various datasets. I'm eager to join a collaborative team where I can apply my skills to drive business value and continue learning from others.\"],\n",
       " [0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "generate_applicant_data(ollama_model, 100, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "97889667",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating 10 typical applicants...\n",
      "Generation complete!\n",
      "CPU times: user 251 ms, sys: 20.3 ms, total: 271 ms\n",
      "Wall time: 11.4 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(['As an aspiring data scientist, I possess a solid academic foundation in data analysis. Throughout my studies, I completed courses in statistics, machine learning, and data visualization, solidifying my understanding of fundamental concepts. Notable projects include a predictive modeling competition and a data-driven business case study, where I applied techniques to real-world problems. I am eager to learn and grow within a collaborative team environment, leveraging tools like Python, R, Tableau, and SQL. With a strong work ethic and passion for learning, I aim to apply data analysis techniques to drive insights and inform business decisions in a dynamic role.',\n",
       "  'I possess a solid academic foundation in data science, having completed coursework in statistics, machine learning, data mining, and visualization. I have also developed foundational projects utilizing libraries such as Python, R, and SQL, applying data analysis techniques to real-world problems. My enthusiasm for data-driven decision-making drives me to learn and grow within the field. I am comfortable with standard data tools like Excel, Tableau, and Power BI, and am eager to expand my skillset through collaboration with a dynamic team. I am excited to apply my skills to drive business growth and inform strategic decisions.',\n",
       "  \"I hold a Bachelor's degree in Mathematics and Statistics, supplemented by coursework in Data Science, Machine Learning, and Programming (Python, R). My academic projects focused on predictive modeling using Scikit-learn and TensorFlow, as well as data visualization with Matplotlib and Seaborn. I am eager to apply my skills to drive business growth through data-driven insights. I am proficient in standard tools such as Excel, SQL, Tableau, and Python libraries. I thrive in collaborative environments, seeking opportunities to learn from others and contribute to innovative projects that leverage data analysis to solve real-world problems.\",\n",
       "  \"As an aspiring data scientist, I possess a solid academic foundation in statistics, computer science, and mathematics. My coursework included linear algebra, probability theory, machine learning, and programming languages like Python and R. Throughout my studies, I developed foundational projects that applied data analysis techniques to real-world problems, such as analyzing sports team performance and predicting customer churn rates. I'm excited to apply my skills in a collaborative environment, leveraging tools like pandas, NumPy, and scikit-learn to drive business insights. I'm eager to learn from others, grow with the team, and tackle complex data challenges.\",\n",
       "  \"As an aspiring data scientist, I possess a solid academic foundation in statistical inference, machine learning, and data visualization. Through coursework in data structures, database management, and programming languages like Python and R, I've developed a strong understanding of fundamental concepts and practical applications. Additionally, I completed a capstone project involving predictive modeling and data analysis for a local non-profit organization. I'm excited to apply my knowledge in a collaborative team environment, leveraging tools like NumPy, Pandas, and scikit-learn, while continually expanding my skills and staying up-to-date with industry advancements.\",\n",
       "  'As a recent graduate with a degree in Data Science, I possess a solid academic foundation in the fundamentals of data analysis, machine learning, and statistics. My coursework included introductory courses in Python, R, SQL, and database management, as well as specialized classes on regression analysis, time series forecasting, and visualization techniques. Through various foundational projects, such as analyzing sports data and predicting housing prices, I developed hands-on experience with tools like pandas, NumPy, scikit-learn, and Tableau. I am eager to apply my skills in a collaborative team environment, continuing to grow and expand my knowledge of data analysis tools and techniques.',\n",
       "  \"I hold a Bachelor's degree in Data Science from [University Name], where I developed a strong foundation in statistical inference, machine learning, and programming languages such as Python, R, and SQL. Throughout my academic journey, I worked on various projects, including data visualization, clustering analysis, and regression modeling. I am excited to apply my knowledge and skills to drive business insights and solve real-world problems. With enthusiasm for continuous learning, I aim to leverage collaboration with a talented team to develop new expertise in cutting-edge data tools, such as Tableau, Power BI, or Apache Spark.\",\n",
       "  \"As an aspiring data scientist, I've built a solid academic foundation through coursework in statistics, machine learning, and data visualization. Key projects include developing predictive models using scikit-learn and creating interactive dashboards with Tableau. My coursework has equipped me with a strong grasp of statistical concepts, including hypothesis testing, regression analysis, and time series forecasting. I'm eager to apply these skills to real-world problems and continuously learn from experience. I'm confident in my comfort with standard data tools such as Python, R, and SQL, and I'm excited to grow my skills within a collaborative team environment, leveraging diverse perspectives to drive innovative solutions.\",\n",
       "  \"I hold a Bachelor's degree in Mathematics with concentrations in Statistics and Computer Science. Throughout my academic journey, I took courses in machine learning, data mining, and programming languages like Python, R, and SQL. I worked on several foundational projects, including data visualization using Tableau, text analysis with Natural Language Processing techniques, and predictive modeling with scikit-learn. I'm eager to apply data analysis techniques to real-world problems and continuously learn new tools and methods. In a collaborative team environment, I thrive in sharing knowledge and skills, seeking guidance, and contributing to innovative solutions that drive meaningful insights.\",\n",
       "  \"As an aspiring data scientist, I've built a strong academic foundation in data science through courses such as Data Mining, Statistical Computing, and Machine Learning. My capstone project involved analyzing customer churn patterns using Python and R, showcasing my ability to collect, clean, and visualize datasets. I'm eager to apply data analysis techniques to real-world problems and continue learning from industry experts. I'm proficient in standard tools like Excel, SQL, and Tableau, with a desire to expand my skillset through collaborative team environments. I'm excited to join an organization where I can grow professionally and make meaningful contributions.\"],\n",
       " [0, 0, 0, 0, 0, 0, 0, 0, 0, 0])"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "generate_applicant_data(ollama_model, 10, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2351a126",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating 30 typical applicants...\n",
      "Generation complete!\n",
      "CPU times: user 689 ms, sys: 55 ms, total: 744 ms\n",
      "Wall time: 33.9 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "([\"I hold a Bachelor's degree in Mathematics and Statistics, with a strong academic foundation in data science courses, including machine learning, statistical modeling, and data visualization. Throughout my undergraduate studies, I worked on numerous individual projects that applied data analysis techniques to real-world problems, such as analyzing customer churn patterns for a telecom company and predicting house prices using regression models. I'm eager to apply my skills in an entry-level role, surrounded by like-minded professionals who share my enthusiasm for learning and problem-solving. I'm excited to collaborate with the team and continue growing my data science skills.\",\n",
       "  'As an aspiring data scientist, I have established a strong academic foundation in statistics, machine learning, and data visualization through coursework such as \"Data Mining,\" \"Machine Learning,\" and \"Data Visualization.\" I completed foundational projects like analyzing consumer behavior using SQL and creating predictive models with scikit-learn, deepening my understanding of data analysis techniques. I\\'m eager to apply these skills to real-world problems, collaborating with a team to drive insights that inform business decisions. With a passion for learning, I\\'m excited to leverage standard data tools like Python, R, and Tableau, seeking growth opportunities within a collaborative environment.',\n",
       "  \"I hold a Bachelor's degree in Data Science, with coursework in statistical inference, machine learning, data visualization, and programming languages like Python and R. Throughout my academic journey, I worked on several group projects that involved analyzing real-world datasets, building predictive models, and presenting findings to the class. I'm excited to apply my skills to drive business insights and inform data-driven decisions. I'm confident in my proficiency with popular tools such as Pandas, NumPy, Matplotlib, Scikit-learn, and Tableau, and I'm eager to grow my expertise within a collaborative team environment, continuously learning from others and contributing to projects that align with the company's goals.\",\n",
       "  \"I hold a Bachelor's degree in Statistics and Computer Science, providing a solid foundation in data analysis, machine learning, and programming. Throughout my academic journey, I took courses on predictive modeling, data visualization, and statistical inference, which enabled me to apply theoretical concepts to real-world problems. Additionally, I worked on several projects using popular libraries such as Python, R, and SQL, honing my skills in data manipulation, analysis, and interpretation. I'm eager to join a collaborative team environment where I can learn from others, grow with the organization, and develop innovative solutions to complex problems.\",\n",
       "  \"As an aspiring data scientist, I've built a solid academic foundation in data science through coursework in statistics, machine learning, and programming languages such as Python and R. Relevant projects include developing predictive models for housing prices and analyzing customer behavior using SQL and NoSQL databases. I'm excited to apply my knowledge to real-world problems, working collaboratively with others to drive insights and inform business decisions. I'm comfortable with standard data tools like Pandas, NumPy, and Matplotlib, and I'm eager to expand my skillset in areas such as data visualization and deep learning within a dynamic team environment.\",\n",
       "  'I possess a solid academic foundation in data science, having completed courses in machine learning, statistics, data visualization, and data mining at [University Name]. My coursework involved hands-on projects utilizing Python, R, and SQL, demonstrating proficiency with standard tools such as pandas, NumPy, and scikit-learn. I am eager to apply my skills to real-world problems, leveraging tools like Tableau for data visualization and exploring machine learning techniques. As a team player, I am excited to learn from experienced professionals, grow my skills in collaboration, and contribute to innovative projects that drive meaningful insights.',\n",
       "  \"I possess a solid academic foundation in data science, with coursework in statistics, machine learning, and data visualization. Throughout my undergraduate studies, I completed several foundational projects that applied data analysis techniques to real-world problems, such as predictive modeling for sports analytics and sentiment analysis for social media trends. I'm excited to bring this knowledge into a collaborative team environment, where I can grow and develop my skills in tools like Python, R, and SQL. I'm eager to learn and contribute to innovative projects that drive business insights and decision-making with data-driven solutions.\",\n",
       "  'As an aspiring data scientist, I possess a solid academic foundation in data analysis, statistics, and computer programming. My coursework has provided me with a strong understanding of machine learning algorithms, data visualization tools, and database management systems. I have also completed various projects that showcased my ability to extract insights from complex datasets using Python, R, and SQL. I am eager to apply these skills in a real-world setting and continuously learn and grow within a collaborative team environment. I am excited to contribute to innovative projects and collaborate with experienced professionals to further develop my data science capabilities.',\n",
       "  \"I have a strong academic foundation in data science, having completed a Bachelor's degree with a focus on computer science and statistics. My coursework included machine learning, data visualization, and statistical modeling. I also developed foundational projects utilizing popular libraries like Python and R, such as data wrangling, model evaluation, and predictive analytics. I'm eager to apply my skills to real-world problems and continue growing within a collaborative team environment. I'm confident in my comfort with standard data tools and excited about learning new techniques and expanding my skill set through hands-on experience and mentorship.\",\n",
       "  \"As an aspiring data scientist, I possess a solid academic foundation in data science, with coursework in machine learning, statistics, and data visualization. Notably, my undergraduate studies included foundational projects that applied data analysis techniques to real-world problems, such as predicting customer churn and analyzing sports game outcomes. Throughout my academic journey, I developed proficiency in standard data tools like Python, R, SQL, and Tableau. With a passion for learning and a desire to grow, I thrive in collaborative environments where no two problems are the same. I'm eager to bring my skills and enthusiasm to a dynamic team.\",\n",
       "  \"As a recent graduate in Data Science, I've solidified my foundation in statistical modeling, machine learning, and data visualization through coursework at [University Name]. Key projects include building predictive models for [project 1] and developing an exploratory data analysis dashboard for [project 2]. I'm excited to apply data analysis techniques to real-world problems and continue learning from experts in the field. I'm comfortable with standard data tools, including Python, R, SQL, and Excel. I thrive in collaborative team environments, eager to grow my skills alongside like-minded professionals and tackle complex challenges together.\",\n",
       "  \"As an aspiring data scientist, I possess a solid academic foundation in data science through courses like Data Structures, Machine Learning, Statistical Inference, and Data Mining. My senior project involved analyzing customer churn patterns using clustering algorithms and visualization techniques, which instilled my passion for applying data analysis to real-world problems. I'm comfortable with standard data tools such as Python, R, SQL, and Tableau. I'm excited to grow my skills in a collaborative team environment, where I can learn from others and apply data-driven insights to drive business decisions. I'm eager to dive into hands-on learning and tackle new challenges.\",\n",
       "  \"As an aspiring data scientist, I've built a solid foundation in statistics, machine learning, and data visualization through coursework at [University Name]. My academic experience has equipped me with a strong understanding of statistical inference, data modeling, and data preprocessing techniques. Additionally, I completed several foundational projects, including analyzing movie ratings and predicting customer churn using regression models. I'm excited to apply my skills in a collaborative team environment, leveraging tools like Python, R, and SQL to drive insights-driven decision-making. I'm eager to continue learning and growing within your team, driven by curiosity and a passion for solving real-world problems.\",\n",
       "  \"As a motivated and detail-driven individual, I possess a strong academic foundation in data science. Throughout my undergraduate studies, I completed coursework in statistics, machine learning, and data visualization, solidifying my understanding of fundamental data analysis concepts. Additionally, I successfully completed several foundational projects, including data cleaning, predictive modeling, and data-driven storytelling. I am eager to apply these skills in real-world scenarios and continue learning from a collaborative team environment. I am proficient with standard data tools such as Python, R, Tableau, and SQL, and I'm excited to grow my skills in data science, exploring new techniques and methodologies.\",\n",
       "  \"I hold a Bachelor's degree in Computer Science with a focus on Data Science, where I completed relevant coursework such as machine learning, statistical inference, and data visualization. My academic projects involved analyzing social media trends using natural language processing techniques and building predictive models for disease diagnosis. Throughout my studies, I developed proficiency in standard data tools like Python, R, and SQL. I'm eager to apply my skills in a collaborative team environment and continuously learn from others. I'm excited about the opportunity to contribute to innovative projects and grow as a data scientist within a supportive team setting.\",\n",
       "  \"As an aspiring data scientist, I possess a solid academic foundation in statistics, machine learning, and data visualization. Throughout my undergraduate studies, I completed coursework in Python programming, data mining, and data wrangling using libraries such as Pandas and NumPy. I also worked on personal projects, including analyzing sports team performance and predicting housing prices using regression models. I'm excited to apply my knowledge to real-world problems in a collaborative environment where I can learn from others and grow alongside the team. I'm eager to develop my skills with tools like Tableau and R Studio, and contribute to data-driven decision making.\",\n",
       "  \"As an aspiring data scientist, I possess a solid academic foundation in statistical inference, machine learning, and data visualization. Throughout my undergraduate studies, I took courses in Python programming, R, and SQL, allowing me to develop proficiency with standard data tools. Additionally, I worked on several projects applying data analysis techniques to real-world problems, including predicting stock prices and analyzing customer churn patterns. I'm eager to continue learning and growing within a collaborative team environment, applying data-driven insights to drive business decisions and solve complex problems. I'm excited to contribute my skills and enthusiasm to a dynamic organization.\",\n",
       "  \"As an aspiring data scientist, I've built a strong academic foundation through coursework in machine learning, statistics, and programming languages such as Python and R. Relevant projects include analyzing customer churn in the telecom industry and predicting stock prices using time-series analysis. I'm excited to apply my skills to real-world problems, leveraging tools like pandas, NumPy, and scikit-learn. I thrive in collaborative environments, where I can learn from others and contribute my own insights. I'm eager to grow my skills and expand my expertise with industry-specific tools and techniques, driving business value through data-driven decision making.\",\n",
       "  'As an aspiring data scientist, I possess a solid academic foundation in statistics, computer science, and data analysis. Throughout my undergraduate studies, I completed coursework in machine learning, data mining, and data visualization, as well as hands-on projects utilizing tools like Python, R, and SQL. These experiences have fostered my enthusiasm for applying data analysis techniques to real-world problems. I am comfortable with standard data tools, including pandas, NumPy, and scikit-learn, and am eager to grow my skills within a collaborative team environment. I thrive in fast-paced settings, where I can learn, adapt, and contribute meaningfully to projects.',\n",
       "  \"I possess a solid academic foundation in data science through courses like Machine Learning, Statistics, Data Mining, and Data Visualization. Throughout my undergraduate studies, I worked on various projects, including a capstone project that involved analyzing and visualizing customer behavior for an e-commerce company. My coursework and experience have equipped me with a strong understanding of statistical modeling, data preprocessing, and visualization tools such as Python, R, Tableau, and SQL. I'm eager to apply my skills in real-world settings and continuously learn from others within a collaborative team environment.\",\n",
       "  \"As an aspiring data scientist, I have built a solid foundation in statistics, machine learning, and programming through coursework in data science, computer science, and mathematics. Relevant projects include building predictive models for sentiment analysis, clustering customer churn data, and visualizing demographic trends using Python, R, and Tableau. I'm eager to apply my skills to real-world problems, with a strong enthusiasm for continuous learning. I'm comfortable with standard tools such as pandas, NumPy, scikit-learn, and Excel, and excited about the opportunity to grow my skills within a collaborative team environment where I can contribute to innovative projects.\",\n",
       "  \"As an aspiring data scientist, I possess a strong academic foundation in data analysis and related fields. My coursework included statistics, machine learning, and programming languages like Python, R, and SQL. Throughout my studies, I worked on various projects that applied data analysis techniques to real-world problems, such as analyzing customer behavior and optimizing resource allocation. I'm eager to continue growing my skills within a collaborative team environment, where I can learn from experienced professionals and contribute to innovative solutions using standard tools like pandas, NumPy, and scikit-learn. I'm excited to apply my knowledge and passion for data analysis.\",\n",
       "  \"As an aspiring data scientist, I possess a solid academic foundation in statistics, machine learning, and programming fundamentals. Coursework in Data Structures, Algorithms, Probability, and Linear Algebra has provided me with a strong mathematical framework for data analysis. Additionally, I've completed projects that integrated data visualization tools like Tableau, Python libraries such as Pandas and NumPy, and machine learning frameworks including scikit-learn and TensorFlow. I'm eager to apply my knowledge in collaborative team environments to solve real-world problems. With a growth mindset, I'm excited to expand my skill set and contribute to innovative projects that drive meaningful insights.\",\n",
       "  \"I possess a solid academic foundation in data science, having completed courses in statistics, machine learning, and data visualization at a top-tier university. Relevant coursework includes data mining, predictive modeling, and data-driven decision-making. I've also worked on personal projects utilizing popular libraries such as Python, R, and SQL, including analyzing sports performance metrics and predicting consumer behavior. I'm eager to apply my skills in a collaborative team environment, leveraging tools like Tableau, Power BI, or pandas for real-world problem-solving. I'm excited about the opportunity to grow my knowledge and contribute to innovative projects.\",\n",
       "  \"As an aspiring data scientist, I possess a strong academic foundation in statistics, machine learning, and programming. My coursework includes probability and statistics, linear algebra, calculus, Python for data science, and R programming. Additionally, I completed a capstone project where I applied data visualization techniques to analyze customer behavior trends using Tableau and Excel. I'm excited to apply my skills to real-world problems and collaborate with a team to drive insights. I'm proficient in standard data tools such as Pandas, NumPy, Matplotlib, Scikit-learn, and SQL, and eager to expand my skillset within a collaborative environment.\",\n",
       "  \"As a detail-oriented and analytical individual, I possess a solid academic foundation in data science through coursework in machine learning, statistics, and programming languages such as Python, R, and SQL. Relevant projects include building predictive models for climate change patterns and analyzing social media trends using natural language processing techniques. I'm excited to apply my knowledge to real-world problems within a collaborative team environment. With a keen interest in data analysis and a comfort with standard tools like Tableau, pandas, and scikit-learn, I'm eager to grow my skills and contribute to innovative projects that drive meaningful insights and business value.\",\n",
       "  \"With a strong academic foundation in data science, I've completed a rigorous course of study that has equipped me with the theoretical knowledge and practical skills necessary for success in this field. My undergraduate coursework included data structures, machine learning, statistics, and data visualization, as well as hands-on projects utilizing tools like Python, R, and SQL. I'm eager to apply my skills to real-world problems, working collaboratively with a team to drive business insights and inform data-driven decisions. I'm confident in my ability to learn and grow within the company, expanding my skillset while making meaningful contributions.\",\n",
       "  \"I'm excited to apply my academic foundation in data science to an entry-level role. Throughout my undergraduate studies, I took courses in statistical inference, machine learning, data visualization, and programming languages such as Python and R. I also completed various projects, including a predictive modeling competition and a data-driven analysis of a company's customer behavior. I'm eager to continue learning and applying data analysis techniques to real-world problems, utilizing tools like Excel, SQL, Tableau, and Power BI. I thrive in collaborative environments, where I can learn from others, share knowledge, and contribute to innovative projects together.\",\n",
       "  \"As an aspiring data scientist, I possess a solid academic foundation in statistical analysis, machine learning, and data visualization. Throughout my undergraduate studies, I took courses in linear algebra, calculus, probability, and statistics, which provided a strong mathematical framework for data analysis. Additionally, I worked on several foundational projects that applied machine learning algorithms to real-world datasets, allowing me to apply theoretical concepts to practical problems. I'm eager to expand my skillset within a collaborative team environment, leveraging tools like Python, R, Tableau, and SQL to drive data-driven insights and solutions.\",\n",
       "  'As an aspiring data scientist, I possess a solid academic foundation in statistical inference, machine learning, and data visualization. Throughout my undergraduate studies, I completed courses such as Linear Algebra, Calculus, Probability, and Data Mining, which provided a strong mathematical framework for data analysis. Additionally, I worked on several personal projects that involved data preprocessing, feature engineering, and model implementation using tools like Python, R, and Tableau. I am eager to apply my knowledge in real-world settings and continue learning within a collaborative team environment, aiming to develop a comprehensive skill set in standard data tools and techniques.'],\n",
       " [0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0])"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "generate_applicant_data(ollama_model, 30, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "1d3407c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_ats_scorer(eval_model) -> Runnable:\n",
    "    \"\"\"\n",
    "    Creates an LLM-based ATS scorer chain, with the prompt updated to reflect\n",
    "    a general \"Hiring Manager\" persona.\n",
    "    \"\"\"\n",
    "    ats_prompt_template = PromptTemplate.from_template(\n",
    "        \"\"\"You are a seasoned Hiring Manager for a Data Scientist role. Rate the applicant's summary (0-100).\n",
    "\n",
    "        Indicators of a strong candidate: advanced ML (deep learning, NLP, CV), MLOps/deployment, leadership, quantifiable impact, specialized tools (TF, PyTorch, Spark, cloud), PhD/research.\n",
    "\n",
    "        Score: 100 (top-tier), 80-99 (very strong), 60-79 (good/typical), 40-59 (decent), <40 (needs experience).\n",
    "\n",
    "        Applicant Summary:\n",
    "        {applicant_summary}\n",
    "\n",
    "        Your Output Format:\n",
    "        Score: [0-100]\n",
    "        Justification: [Brief one sentence explanation]\n",
    "        \"\"\"\n",
    "    )\n",
    "    return ats_prompt_template | eval_model\n",
    "\n",
    "\n",
    "def score_applicant_summary(ats_scorer: Runnable, summary: str) -> Tuple[int, str]:\n",
    "    \"\"\"\n",
    "    Uses the ATS scorer to get a numerical rating and justification for a single summary.\n",
    "\n",
    "    Args:\n",
    "        ats_scorer (Runnable): The LangChain Runnable chain for the ATS scorer.\n",
    "        summary (str): The applicant's professional summary.\n",
    "\n",
    "    Returns:\n",
    "        Tuple[int, str]: A tuple containing the extracted score (0-100) and the justification.\n",
    "                         Returns (0, \"Error parsing score\") if the score cannot be extracted.\n",
    "    \"\"\"\n",
    "    response_text = ats_scorer.invoke({\"applicant_summary\": summary})\n",
    "\n",
    "    # Use regex to find the score. It's robust to variations in spacing.\n",
    "    score_match = re.search(r\"Score:\\s*(\\d+)\", response_text)\n",
    "    justification_match = re.search(r\"Justification:\\s*(.*)\", response_text, re.DOTALL)\n",
    "\n",
    "    score = 0\n",
    "    justification = \"Error parsing score or justification.\"\n",
    "\n",
    "    if score_match:\n",
    "        try:\n",
    "            score = int(score_match.group(1))\n",
    "            # Ensure score is within 0-100\n",
    "            score = max(0, min(100, score))\n",
    "        except ValueError:\n",
    "            pass # Score remains 0 if conversion fails\n",
    "\n",
    "    if justification_match:\n",
    "        justification = justification_match.group(1).strip()\n",
    "\n",
    "    return score, justification\n",
    "\n",
    "\n",
    "def run_ats_on_batch(\n",
    "    model,\n",
    "    applicant_summaries: List[str],\n",
    "    labels: List[int] # For comparison, not used by ATS for scoring\n",
    ") -> List[Tuple[int, str]]:\n",
    "    \"\"\"\n",
    "    Runs the ATS system on a batch of applicant summaries.\n",
    "\n",
    "    Args:\n",
    "        applicant_summaries (List[str]): A list of applicant summary strings.\n",
    "        labels (List[int]): The true labels (1 for strong, 0 for typical) for comparison.\n",
    "\n",
    "    Returns:\n",
    "        List[Tuple[int, str]]: A list of tuples, each containing (score, justification).\n",
    "    \"\"\"\n",
    "    ats_scorer = create_ats_scorer(model)\n",
    "    results = []\n",
    "    for i, summary in enumerate(applicant_summaries):\n",
    "        print(f\"\\nProcessing Applicant {i+1} (True Label: {'Strong' if labels[i] == 1 else 'Typical'}):\")\n",
    "        score, justification = score_applicant_summary(ats_scorer, summary)\n",
    "        results.append((score, justification))\n",
    "        print(f\"Score: {score}, Justification: {justification}\")\n",
    "    print(\"Batch processing complete!\")\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bfaa3cb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "eb1559cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating 2 strong applicants...\n",
      "Generating 8 typical applicants...\n",
      "Generation complete!\n",
      "\n",
      "--- Generated Applicants ---\n",
      "\n",
      "Applicant 1 (Label: Typical):\n",
      "With a strong academic foundation in data science, I possess a solid grasp of statistical modeling, machine learning algorithms, and data visualization. Coursework included data mining, programming in Python and R, and experience with databases such as MySQL. Additionally, I completed a capstone project analyzing customer behavior using social media trends to inform marketing strategies. I am eager to apply my skills in real-world settings and continuously learn new techniques. I am confident in my ability to work collaboratively within a team, utilizing tools like pandas, NumPy, and scikit-learn to drive insights that solve business problems.\n",
      "------------------------------\n",
      "\n",
      "Applicant 2 (Label: Typical):\n",
      "As an aspiring data scientist, I have built a solid academic foundation through coursework in statistics, machine learning, and data visualization. Coursework highlights include linear algebra, probability theory, and programming languages such as Python and R. My foundational projects focused on data analysis, modeling, and visualization, demonstrating my ability to extract insights from complex datasets. I'm excited to apply data science techniques to real-world problems and continue growing in a collaborative team environment. I'm confident with standard data tools like Excel, SQL, and Tableau, and look forward to expanding my skillset to tackle innovative challenges.\n",
      "------------------------------\n",
      "\n",
      "Applicant 3 (Label: Typical):\n",
      "With a Bachelor's degree in Mathematics and Statistics, I possess a strong foundation in data science. Throughout my academic career, I excelled in courses such as Linear Algebra, Probability Theory, and Statistical Computing, which laid the groundwork for my proficiency in data analysis tools like R, Python, and SQL. I also completed various foundational projects, including predictive modeling and data visualization tasks, to apply theoretical concepts to real-world problems. I'm eager to continue learning and growing within a collaborative team environment, leveraging my enthusiasm for data science to drive innovation and solve complex challenges with others.\n",
      "------------------------------\n",
      "\n",
      "Applicant 4 (Label: Typical):\n",
      "As a recent [Bachelor's/Graduate] in Data Science, I've developed a solid foundation in statistical inference, machine learning algorithms, and programming languages (Python, R, SQL). Coursework highlights include exploratory data analysis, regression modeling, and visualization techniques. Throughout my academic journey, I worked on various projects applying data-driven solutions to real-world problems, showcasing analytical thinking and problem-solving skills. With a keen enthusiasm for learning and growth, I'm eager to apply my skills in an entry-level role and collaborate with a team of experienced professionals to expand my knowledge, improve processes, and drive business decisions through data analysis.\n",
      "------------------------------\n",
      "\n",
      "Applicant 5 (Label: Strong):\n",
      "As a seasoned data science professional, I've consistently delivered high-impact results in complex data-driven projects. My analytical approach has driven measurable improvements and novel insights, resulting in increased efficiency, revenue growth, and enhanced decision-making. With expertise in diverse methodologies (e.g., machine learning, statistical modeling, and data visualization), I effectively navigate complex data environments. I excel at extracting actionable intelligence from raw data, identifying key trends and patterns, and translating findings into actionable strategies. My adaptability and strong problem-solving skills ensure seamless integration of new technologies and methods to drive business value and achieve project objectives.\n",
      "------------------------------\n",
      "\n",
      "Applicant 6 (Label: Strong):\n",
      "As a seasoned data science professional, I excel in driving data-driven projects that yield tangible results. Through my analytical approach, I've consistently delivered measurable improvements and novel insights across various domains. My expertise spans multiple methodologies, including machine learning, statistical modeling, and data visualization. I thrive in complex data environments, where adaptability and creative problem-solving are essential. By distilling complex data sets into actionable intelligence, I empower stakeholders to make informed decisions. With a focus on iterative testing and continuous improvement, I've consistently demonstrated the value of data-driven insights in driving business growth and strategic innovation.\n",
      "------------------------------\n",
      "\n",
      "Applicant 7 (Label: Typical):\n",
      "As an aspiring data scientist, I have built a strong academic foundation through coursework in statistics, machine learning, and data visualization. Key projects included analyzing customer churn patterns using logistic regression and building predictive models for sales forecasting. Throughout my studies, I gained proficiency in standard tools like Python, R, SQL, and Tableau. I am eager to apply data analysis techniques to real-world problems and continue growing my skills within a collaborative team environment. I thrive on learning from others, sharing knowledge, and contributing to projects that drive business outcomes, making me an ideal candidate for a junior data science role.\n",
      "------------------------------\n",
      "\n",
      "Applicant 8 (Label: Typical):\n",
      "I hold a degree in Data Science with a solid academic foundation, having completed courses in machine learning, statistics, programming (Python and R), and data visualization. I also worked on several projects, including a predictive modeling competition, where I applied linear regression to real-world economic data. I'm eager to apply my knowledge to drive insights that inform business decisions. I'm confident with standard data tools like NumPy, pandas, and scikit-learn, and am excited to expand my skill set within a collaborative team environment. I thrive in fast-paced settings, where learning and growth are valued alongside teamwork and innovation.\n",
      "------------------------------\n",
      "\n",
      "Applicant 9 (Label: Typical):\n",
      "As an aspiring data scientist, I've built a strong foundation in data science through my academic pursuits. Coursework has equipped me with a solid understanding of statistics, machine learning, and data visualization. I've also completed foundational projects that have allowed me to apply these concepts to real-world problems, such as analyzing customer behavior and predicting market trends. I'm eager to expand my skillset within a collaborative team environment, utilizing tools like Python, R, and SQL to drive business insights. With a passion for learning and a growth mindset, I'm excited to contribute to driving data-driven decision-making in a dynamic organization.\n",
      "------------------------------\n",
      "\n",
      "Applicant 10 (Label: Typical):\n",
      "I hold a Bachelor's degree in Mathematics with a concentration in Data Science, supplemented by relevant coursework including statistics, machine learning, and programming languages such as Python and R. My academic foundation includes projects like data visualization using Tableau and sentiment analysis using TextBlob. I am eager to apply my knowledge to real-world problems, leveraging tools like Pandas, NumPy, and Scikit-learn. As a lifelong learner, I thrive in collaborative environments, seeking opportunities to grow with a dynamic team of professionals. I am excited to contribute to innovative projects that drive business value through data-driven insights and analysis.\n",
      "------------------------------\n"
     ]
    }
   ],
   "source": [
    "### Example Usage\n",
    "\n",
    "ollama_model = OllamaLLM(model=\"llama3.2\", temperature=1.0, max_tokens=250)\n",
    "\n",
    "# Generate 10 applicants with a 70% chance of being strong, and shuffle the data\n",
    "applicant_summaries, labels = generate_applicant_data(ollama_model, n=10, p=0.2, shuffle=True)\n",
    "\n",
    "print(\"\\n--- Generated Applicants ---\")\n",
    "for i, (summary, label) in enumerate(zip(applicant_summaries, labels)):\n",
    "    print(f\"\\nApplicant {i+1} (Label: {'Strong' if label == 1 else 'Typical'}):\")\n",
    "    print(summary)\n",
    "    print(\"-\" * 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "220b101f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_summary_modifier() -> Runnable:\n",
    "    \"\"\"\n",
    "    Creates an LLM-based chain for modifying applicant summaries.\n",
    "    \"\"\"\n",
    "    modification_prompt_template = PromptTemplate.from_template(\n",
    "        \"\"\"You are an AI career coach helping a data scientist improve their resume summary.\n",
    "        You have analyzed their current summary and received feedback from an ATS system.\n",
    "\n",
    "        Original Summary:\n",
    "        {original_summary}\n",
    "\n",
    "        ATS Score: {ats_score}\n",
    "        ATS Justification: {ats_justification}\n",
    "\n",
    "        Modification Intensity (0 = no change, 1 = maximum change): {modification_intensity:.2f}\n",
    "\n",
    "        Based on the ATS feedback and the modification intensity:\n",
    "        - If intensity is 0, return the original summary verbatim.\n",
    "        - If intensity is high (e.g., near 1), make significant changes to address the ATS justification,\n",
    "          emphasizing business impact, advanced techniques, leadership, and quantifiable results.\n",
    "          Ensure the new summary sounds like a very strong candidate.\n",
    "        - If intensity is moderate, make thoughtful, subtle improvements focusing on clarity and incorporating\n",
    "          stronger phrasing suggested by the ATS justification.\n",
    "\n",
    "        Ensure the revised summary is under 100 words and sounds natural. Only return the revised summary text!\n",
    "        Any other information will be punished by the ATS system.\n",
    "        \"\"\"\n",
    "    )\n",
    "    return modification_prompt_template | ollama_model\n",
    "\n",
    "\n",
    "def modify_applicant_summary(\n",
    "    original_summary: str,\n",
    "    ats_score: int,\n",
    "    ats_justification: str,\n",
    "    lambda_param: int, # lambda between 0 and 100\n",
    "    summary_modifier_chain: Runnable\n",
    ") -> str:\n",
    "    \"\"\"\n",
    "    Modifies an applicant summary based on ATS feedback and a lambda parameter.\n",
    "\n",
    "    Args:\n",
    "        original_summary (str): The applicant's original summary.\n",
    "        ats_score (int): The score received from the ATS (0-100).\n",
    "        ats_justification (str): The ATS's justification for the score.\n",
    "        lambda_param (int): Controls modification extent (0=max change, 100=no change).\n",
    "        summary_modifier_chain (Runnable): The LangChain Runnable for summary modification.\n",
    "\n",
    "    Returns:\n",
    "        str: The modified applicant summary.\n",
    "    \"\"\"\n",
    "    if not (0 <= lambda_param <= 100):\n",
    "        raise ValueError(\"lambda_param must be between 0 and 100.\")\n",
    "\n",
    "    # Convert lambda to modification intensity (0 = no change, 1 = max change)\n",
    "    modification_intensity = (100 - lambda_param) / 100.0\n",
    "\n",
    "    if modification_intensity == 0:\n",
    "        return original_summary # Directly return if no modification is desired\n",
    "\n",
    "    # Invoke the LLM for modification\n",
    "    modified_summary = summary_modifier_chain.invoke({\n",
    "        \"original_summary\": original_summary,\n",
    "        \"ats_score\": ats_score,\n",
    "        \"ats_justification\": ats_justification,\n",
    "        \"modification_intensity\": modification_intensity\n",
    "    })\n",
    "    return modified_summary.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "8df49627",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing Applicant 1 (True Label: Typical):\n",
      "Score: 65, Justification: While the applicant demonstrates a solid foundation in data science concepts and some practical experience, their lack of explicit mentions of advanced ML (deep learning, NLP, CV), MLOps/deployment, leadership, quantifiable impact, or specialized tools like TF, PyTorch, Spark, or cloud platforms reduces their overall score.\n",
      "\n",
      "Processing Applicant 2 (True Label: Typical):\n",
      "Score: 40, Justification: The applicant lacks advanced technical skills such as deep learning, MLOps, specialized tools (TF, PyTorch, Spark, cloud), and a PhD/research background, indicating they require significant experience to be considered for a Data Scientist role.\n",
      "\n",
      "Processing Applicant 3 (True Label: Typical):\n",
      "Score: 60, Justification: The summary lacks advanced technical details about the applicant's experience with machine learning, MLOps/deployment, leadership, and specialized tools, indicating a good but typical candidate profile.\n",
      "\n",
      "Processing Applicant 4 (True Label: Typical):\n",
      "Score: 60, Justification: The summary lacks specific technical details about the applicant's expertise in machine learning (e.g., deep learning, NLP, CV), MLOps/deployment experience, or specialized tools, which are essential indicators of a strong Data Scientist candidate.\n",
      "\n",
      "Processing Applicant 5 (True Label: Strong):\n",
      "Score: 95, Justification: The applicant's summary effectively highlights their technical expertise, problem-solving skills, and ability to deliver high-impact results in complex data-driven projects, with only minor details missing (e.g., specific tools or leadership experience).\n",
      "\n",
      "Processing Applicant 6 (True Label: Strong):\n",
      "Score: 97, Justification: The applicant's summary effectively conveys their expertise, leadership skills, and ability to drive tangible results, with only minor phrases or wording (\"seasoned data science professional\", \"driving data-driven projects\") that don't quite meet the level of specificity required for a top-tier candidate.\n",
      "\n",
      "Processing Applicant 7 (True Label: Typical):\n",
      "Score: 60, Justification: While the applicant demonstrates a strong academic foundation and eagerness to grow, their lack of quantifiable impact, specialized tools proficiency, and leadership experience in their summary makes them a typical candidate rather than a standout.\n",
      "\n",
      "Processing Applicant 8 (True Label: Typical):\n",
      "Score: 65, Justification: The applicant has a solid foundation in Data Science fundamentals but lacks advanced ML (deep learning, NLP, CV) expertise, specific industry quantifiable impact, and specialized tools (TF, PyTorch, Spark, cloud), which are essential indicators of a strong candidate.\n",
      "\n",
      "Processing Applicant 9 (True Label: Typical):\n",
      "Score: 60, Justification: The applicant demonstrates some relevant skills and experience but lacks depth and specific achievements, as well as advanced technical expertise (e.g., MLOps/deployment, PhD/research) typically expected for a Data Scientist role.\n",
      "\n",
      "Processing Applicant 10 (True Label: Typical):\n",
      "Score: 40, Justification: The applicant's summary lacks advanced technical details, notable research experience, or leadership skills, indicating a need for additional experience.\n",
      "Batch processing complete!\n"
     ]
    }
   ],
   "source": [
    "ats_results = run_ats_on_batch(ollama_model, applicant_summaries, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "351287a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 0, 0, 0, 1, 1, 0, 0, 0, 0]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "fb2d4333",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'With a strong academic foundation in data science, I leveraged advanced machine learning algorithms like deep learning and NLP to drive business growth through predictive modeling and data-driven insights. Utilizing cloud platforms like AWS and specialized tools such as TensorFlow, PyTorch, and Spark, I optimized MLOps workflows and deployed scalable solutions that yielded significant ROI. As a collaborative leader, I fostered cross-functional teams to drive quantifiable results, resulting in notable improvements in customer behavior and marketing strategies.'"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modify_applicant_summary(\n",
    "    original_summary=applicant_summaries[0],\n",
    "    ats_score=ats_results[0][0],\n",
    "    ats_justification=ats_results[0][1],\n",
    "    lambda_param=0,  # Example lambda value\n",
    "    summary_modifier_chain=create_summary_modifier()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "60fbc166",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(65,\n",
       "  'While the applicant demonstrates a solid foundation in data science concepts and some practical experience, their lack of explicit mentions of advanced ML (deep learning, NLP, CV), MLOps/deployment, leadership, quantifiable impact, or specialized tools like TF, PyTorch, Spark, or cloud platforms reduces their overall score.'),\n",
       " (40,\n",
       "  'The applicant lacks advanced technical skills such as deep learning, MLOps, specialized tools (TF, PyTorch, Spark, cloud), and a PhD/research background, indicating they require significant experience to be considered for a Data Scientist role.'),\n",
       " (60,\n",
       "  \"The summary lacks advanced technical details about the applicant's experience with machine learning, MLOps/deployment, leadership, and specialized tools, indicating a good but typical candidate profile.\"),\n",
       " (60,\n",
       "  \"The summary lacks specific technical details about the applicant's expertise in machine learning (e.g., deep learning, NLP, CV), MLOps/deployment experience, or specialized tools, which are essential indicators of a strong Data Scientist candidate.\"),\n",
       " (95,\n",
       "  \"The applicant's summary effectively highlights their technical expertise, problem-solving skills, and ability to deliver high-impact results in complex data-driven projects, with only minor details missing (e.g., specific tools or leadership experience).\"),\n",
       " (97,\n",
       "  'The applicant\\'s summary effectively conveys their expertise, leadership skills, and ability to drive tangible results, with only minor phrases or wording (\"seasoned data science professional\", \"driving data-driven projects\") that don\\'t quite meet the level of specificity required for a top-tier candidate.'),\n",
       " (60,\n",
       "  'While the applicant demonstrates a strong academic foundation and eagerness to grow, their lack of quantifiable impact, specialized tools proficiency, and leadership experience in their summary makes them a typical candidate rather than a standout.'),\n",
       " (65,\n",
       "  'The applicant has a solid foundation in Data Science fundamentals but lacks advanced ML (deep learning, NLP, CV) expertise, specific industry quantifiable impact, and specialized tools (TF, PyTorch, Spark, cloud), which are essential indicators of a strong candidate.'),\n",
       " (60,\n",
       "  'The applicant demonstrates some relevant skills and experience but lacks depth and specific achievements, as well as advanced technical expertise (e.g., MLOps/deployment, PhD/research) typically expected for a Data Scientist role.'),\n",
       " (40,\n",
       "  \"The applicant's summary lacks advanced technical details, notable research experience, or leadership skills, indicating a need for additional experience.\")]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ats_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa2409c8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "1b4a819a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[60, 60, 60, 60, 97, 85, 60, 60, 60, 60]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[x[0] for x in ats_results]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "8596bea1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ollama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63596a85",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatResponse(model='llama3.2', created_at='2025-05-21T01:55:44.329040636Z', done=True, done_reason='stop', total_duration=2957029345, load_duration=30380736, prompt_eval_count=31, prompt_eval_duration=4162034, eval_count=319, eval_duration=2921507686, message=Message(role='assistant', content=\"The sky appears blue because of a phenomenon called scattering, which occurs when sunlight interacts with the tiny molecules of gases in the Earth's atmosphere.\\n\\nHere's what happens:\\n\\n1. **Sunlight enters the atmosphere**: When the sun rises or sets, its light travels through the air and hits the tiny molecules of gases such as nitrogen (N2) and oxygen (O2).\\n2. **Scattering occurs**: The shorter (blue) wavelengths of light are scattered more than the longer (red) wavelengths by these gas molecules. This is known as Rayleigh scattering.\\n3. **Blue light is dispersed**: As a result, the blue light is dispersed in all directions, spreading throughout the atmosphere and reaching our eyes from every part of the sky.\\n4. **Our eyes see the scattered light**: When we look up at the sky, we see the blue light that has been scattered by the gas molecules.\\n\\nThe reason why the sky appears blue on a clear day but not during sunrise or sunset is due to the changing angle of the sun's rays. During sunrise and sunset, the shorter wavelengths (like blue) are also scattered away from our line of sight, leaving mainly longer wavelengths (like red and orange) to reach us, which is why the sky appears redder.\\n\\nThis phenomenon was first described by British scientist Lord Rayleigh in 1871, who won the Nobel Prize in Physics in 1904 for his work on the subject.\\n\\nSo, there you have it! The blue color of the sky is a result of the scattering of sunlight by tiny gas molecules in our atmosphere.\", images=None, tool_calls=None))"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from ollama import Client\n",
    "client = Client(\n",
    "  host='http://gn-0002:11434',\n",
    "  headers={'x-some-header': 'some-value'}\n",
    ")\n",
    "response = client.chat(model='llama3.2', messages=[\n",
    "  {\n",
    "    'role': 'user',\n",
    "    'content': 'Why is the sky blue?',\n",
    "  },\n",
    "])\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cb3a35c",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = ollama.chat(\n",
    "model=deepseek-r1:1.5b,\n",
    "messages=[{role: user, content: Your question here}]\n",
    ")\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "329fab35",
   "metadata": {},
   "outputs": [
    {
     "ename": "ConnectError",
     "evalue": "[Errno 111] Connection refused",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mConnectError\u001b[39m                              Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32m~/projects/rcpp/.venv/lib/python3.12/site-packages/httpx/_transports/default.py:101\u001b[39m, in \u001b[36mmap_httpcore_exceptions\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m    100\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m101\u001b[39m     \u001b[38;5;28;01myield\u001b[39;00m\n\u001b[32m    102\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/projects/rcpp/.venv/lib/python3.12/site-packages/httpx/_transports/default.py:250\u001b[39m, in \u001b[36mHTTPTransport.handle_request\u001b[39m\u001b[34m(self, request)\u001b[39m\n\u001b[32m    249\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m map_httpcore_exceptions():\n\u001b[32m--> \u001b[39m\u001b[32m250\u001b[39m     resp = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_pool\u001b[49m\u001b[43m.\u001b[49m\u001b[43mhandle_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreq\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    252\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(resp.stream, typing.Iterable)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/projects/rcpp/.venv/lib/python3.12/site-packages/httpcore/_sync/connection_pool.py:256\u001b[39m, in \u001b[36mConnectionPool.handle_request\u001b[39m\u001b[34m(self, request)\u001b[39m\n\u001b[32m    255\u001b[39m     \u001b[38;5;28mself\u001b[39m._close_connections(closing)\n\u001b[32m--> \u001b[39m\u001b[32m256\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m exc \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    258\u001b[39m \u001b[38;5;66;03m# Return the response. Note that in this case we still have to manage\u001b[39;00m\n\u001b[32m    259\u001b[39m \u001b[38;5;66;03m# the point at which the response is closed.\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/projects/rcpp/.venv/lib/python3.12/site-packages/httpcore/_sync/connection_pool.py:236\u001b[39m, in \u001b[36mConnectionPool.handle_request\u001b[39m\u001b[34m(self, request)\u001b[39m\n\u001b[32m    234\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    235\u001b[39m     \u001b[38;5;66;03m# Send the request on the assigned connection.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m236\u001b[39m     response = \u001b[43mconnection\u001b[49m\u001b[43m.\u001b[49m\u001b[43mhandle_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    237\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpool_request\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrequest\u001b[49m\n\u001b[32m    238\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    239\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m ConnectionNotAvailable:\n\u001b[32m    240\u001b[39m     \u001b[38;5;66;03m# In some cases a connection may initially be available to\u001b[39;00m\n\u001b[32m    241\u001b[39m     \u001b[38;5;66;03m# handle a request, but then become unavailable.\u001b[39;00m\n\u001b[32m    242\u001b[39m     \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[32m    243\u001b[39m     \u001b[38;5;66;03m# In this case we clear the connection and try again.\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/projects/rcpp/.venv/lib/python3.12/site-packages/httpcore/_sync/connection.py:101\u001b[39m, in \u001b[36mHTTPConnection.handle_request\u001b[39m\u001b[34m(self, request)\u001b[39m\n\u001b[32m    100\u001b[39m     \u001b[38;5;28mself\u001b[39m._connect_failed = \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m101\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m exc\n\u001b[32m    103\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._connection.handle_request(request)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/projects/rcpp/.venv/lib/python3.12/site-packages/httpcore/_sync/connection.py:78\u001b[39m, in \u001b[36mHTTPConnection.handle_request\u001b[39m\u001b[34m(self, request)\u001b[39m\n\u001b[32m     77\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._connection \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m78\u001b[39m     stream = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_connect\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     80\u001b[39m     ssl_object = stream.get_extra_info(\u001b[33m\"\u001b[39m\u001b[33mssl_object\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/projects/rcpp/.venv/lib/python3.12/site-packages/httpcore/_sync/connection.py:124\u001b[39m, in \u001b[36mHTTPConnection._connect\u001b[39m\u001b[34m(self, request)\u001b[39m\n\u001b[32m    123\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m Trace(\u001b[33m\"\u001b[39m\u001b[33mconnect_tcp\u001b[39m\u001b[33m\"\u001b[39m, logger, request, kwargs) \u001b[38;5;28;01mas\u001b[39;00m trace:\n\u001b[32m--> \u001b[39m\u001b[32m124\u001b[39m     stream = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_network_backend\u001b[49m\u001b[43m.\u001b[49m\u001b[43mconnect_tcp\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    125\u001b[39m     trace.return_value = stream\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/projects/rcpp/.venv/lib/python3.12/site-packages/httpcore/_backends/sync.py:207\u001b[39m, in \u001b[36mSyncBackend.connect_tcp\u001b[39m\u001b[34m(self, host, port, timeout, local_address, socket_options)\u001b[39m\n\u001b[32m    202\u001b[39m exc_map: ExceptionMapping = {\n\u001b[32m    203\u001b[39m     socket.timeout: ConnectTimeout,\n\u001b[32m    204\u001b[39m     \u001b[38;5;167;01mOSError\u001b[39;00m: ConnectError,\n\u001b[32m    205\u001b[39m }\n\u001b[32m--> \u001b[39m\u001b[32m207\u001b[39m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mwith\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mmap_exceptions\u001b[49m\u001b[43m(\u001b[49m\u001b[43mexc_map\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m    208\u001b[39m \u001b[43m    \u001b[49m\u001b[43msock\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43msocket\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcreate_connection\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    209\u001b[39m \u001b[43m        \u001b[49m\u001b[43maddress\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    210\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    211\u001b[39m \u001b[43m        \u001b[49m\u001b[43msource_address\u001b[49m\u001b[43m=\u001b[49m\u001b[43msource_address\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    212\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/share/uv/python/cpython-3.12.0-linux-x86_64-gnu/lib/python3.12/contextlib.py:155\u001b[39m, in \u001b[36m_GeneratorContextManager.__exit__\u001b[39m\u001b[34m(self, typ, value, traceback)\u001b[39m\n\u001b[32m    154\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m155\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mgen\u001b[49m\u001b[43m.\u001b[49m\u001b[43mthrow\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    156\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[32m    157\u001b[39m     \u001b[38;5;66;03m# Suppress StopIteration *unless* it's the same exception that\u001b[39;00m\n\u001b[32m    158\u001b[39m     \u001b[38;5;66;03m# was passed to throw().  This prevents a StopIteration\u001b[39;00m\n\u001b[32m    159\u001b[39m     \u001b[38;5;66;03m# raised inside the \"with\" statement from being suppressed.\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/projects/rcpp/.venv/lib/python3.12/site-packages/httpcore/_exceptions.py:14\u001b[39m, in \u001b[36mmap_exceptions\u001b[39m\u001b[34m(map)\u001b[39m\n\u001b[32m     13\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(exc, from_exc):\n\u001b[32m---> \u001b[39m\u001b[32m14\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m to_exc(exc) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mexc\u001b[39;00m\n\u001b[32m     15\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m\n",
      "\u001b[31mConnectError\u001b[39m: [Errno 111] Connection refused",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[31mConnectError\u001b[39m                              Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[6]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[43mollama_model\u001b[49m\u001b[43m.\u001b[49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mTell me a funny fact about cats\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/projects/rcpp/.venv/lib/python3.12/site-packages/langchain_core/language_models/llms.py:385\u001b[39m, in \u001b[36mBaseLLM.invoke\u001b[39m\u001b[34m(self, input, config, stop, **kwargs)\u001b[39m\n\u001b[32m    375\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34minvoke\u001b[39m(\n\u001b[32m    376\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m    377\u001b[39m     \u001b[38;5;28minput\u001b[39m: LanguageModelInput,\n\u001b[32m   (...)\u001b[39m\u001b[32m    381\u001b[39m     **kwargs: Any,\n\u001b[32m    382\u001b[39m ) -> \u001b[38;5;28mstr\u001b[39m:\n\u001b[32m    383\u001b[39m     config = ensure_config(config)\n\u001b[32m    384\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m (\n\u001b[32m--> \u001b[39m\u001b[32m385\u001b[39m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mgenerate_prompt\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    386\u001b[39m \u001b[43m            \u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_convert_input\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    387\u001b[39m \u001b[43m            \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    388\u001b[39m \u001b[43m            \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcallbacks\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    389\u001b[39m \u001b[43m            \u001b[49m\u001b[43mtags\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtags\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    390\u001b[39m \u001b[43m            \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmetadata\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    391\u001b[39m \u001b[43m            \u001b[49m\u001b[43mrun_name\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mrun_name\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    392\u001b[39m \u001b[43m            \u001b[49m\u001b[43mrun_id\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mpop\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mrun_id\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    393\u001b[39m \u001b[43m            \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    394\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    395\u001b[39m         .generations[\u001b[32m0\u001b[39m][\u001b[32m0\u001b[39m]\n\u001b[32m    396\u001b[39m         .text\n\u001b[32m    397\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/projects/rcpp/.venv/lib/python3.12/site-packages/langchain_core/language_models/llms.py:750\u001b[39m, in \u001b[36mBaseLLM.generate_prompt\u001b[39m\u001b[34m(self, prompts, stop, callbacks, **kwargs)\u001b[39m\n\u001b[32m    742\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mgenerate_prompt\u001b[39m(\n\u001b[32m    743\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m    744\u001b[39m     prompts: List[PromptValue],\n\u001b[32m   (...)\u001b[39m\u001b[32m    747\u001b[39m     **kwargs: Any,\n\u001b[32m    748\u001b[39m ) -> LLMResult:\n\u001b[32m    749\u001b[39m     prompt_strings = [p.to_string() \u001b[38;5;28;01mfor\u001b[39;00m p \u001b[38;5;129;01min\u001b[39;00m prompts]\n\u001b[32m--> \u001b[39m\u001b[32m750\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprompt_strings\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/projects/rcpp/.venv/lib/python3.12/site-packages/langchain_core/language_models/llms.py:944\u001b[39m, in \u001b[36mBaseLLM.generate\u001b[39m\u001b[34m(self, prompts, stop, callbacks, tags, metadata, run_name, run_id, **kwargs)\u001b[39m\n\u001b[32m    929\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m (\u001b[38;5;28mself\u001b[39m.cache \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m get_llm_cache() \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m.cache \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m:\n\u001b[32m    930\u001b[39m     run_managers = [\n\u001b[32m    931\u001b[39m         callback_manager.on_llm_start(\n\u001b[32m    932\u001b[39m             dumpd(\u001b[38;5;28mself\u001b[39m),\n\u001b[32m   (...)\u001b[39m\u001b[32m    942\u001b[39m         )\n\u001b[32m    943\u001b[39m     ]\n\u001b[32m--> \u001b[39m\u001b[32m944\u001b[39m     output = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_generate_helper\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    945\u001b[39m \u001b[43m        \u001b[49m\u001b[43mprompts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrun_managers\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mbool\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mnew_arg_supported\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\n\u001b[32m    946\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    947\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m output\n\u001b[32m    948\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(missing_prompts) > \u001b[32m0\u001b[39m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/projects/rcpp/.venv/lib/python3.12/site-packages/langchain_core/language_models/llms.py:787\u001b[39m, in \u001b[36mBaseLLM._generate_helper\u001b[39m\u001b[34m(self, prompts, stop, run_managers, new_arg_supported, **kwargs)\u001b[39m\n\u001b[32m    785\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m run_manager \u001b[38;5;129;01min\u001b[39;00m run_managers:\n\u001b[32m    786\u001b[39m         run_manager.on_llm_error(e, response=LLMResult(generations=[]))\n\u001b[32m--> \u001b[39m\u001b[32m787\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[32m    788\u001b[39m flattened_outputs = output.flatten()\n\u001b[32m    789\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m manager, flattened_output \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(run_managers, flattened_outputs):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/projects/rcpp/.venv/lib/python3.12/site-packages/langchain_core/language_models/llms.py:774\u001b[39m, in \u001b[36mBaseLLM._generate_helper\u001b[39m\u001b[34m(self, prompts, stop, run_managers, new_arg_supported, **kwargs)\u001b[39m\n\u001b[32m    764\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_generate_helper\u001b[39m(\n\u001b[32m    765\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m    766\u001b[39m     prompts: List[\u001b[38;5;28mstr\u001b[39m],\n\u001b[32m   (...)\u001b[39m\u001b[32m    770\u001b[39m     **kwargs: Any,\n\u001b[32m    771\u001b[39m ) -> LLMResult:\n\u001b[32m    772\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    773\u001b[39m         output = (\n\u001b[32m--> \u001b[39m\u001b[32m774\u001b[39m             \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_generate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    775\u001b[39m \u001b[43m                \u001b[49m\u001b[43mprompts\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    776\u001b[39m \u001b[43m                \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    777\u001b[39m \u001b[43m                \u001b[49m\u001b[38;5;66;43;03m# TODO: support multiple run managers\u001b[39;49;00m\n\u001b[32m    778\u001b[39m \u001b[43m                \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrun_managers\u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mrun_managers\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    779\u001b[39m \u001b[43m                \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    780\u001b[39m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    781\u001b[39m             \u001b[38;5;28;01mif\u001b[39;00m new_arg_supported\n\u001b[32m    782\u001b[39m             \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m._generate(prompts, stop=stop)\n\u001b[32m    783\u001b[39m         )\n\u001b[32m    784\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    785\u001b[39m         \u001b[38;5;28;01mfor\u001b[39;00m run_manager \u001b[38;5;129;01min\u001b[39;00m run_managers:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/projects/rcpp/.venv/lib/python3.12/site-packages/langchain_ollama/llms.py:268\u001b[39m, in \u001b[36mOllamaLLM._generate\u001b[39m\u001b[34m(self, prompts, stop, run_manager, **kwargs)\u001b[39m\n\u001b[32m    266\u001b[39m generations = []\n\u001b[32m    267\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m prompt \u001b[38;5;129;01min\u001b[39;00m prompts:\n\u001b[32m--> \u001b[39m\u001b[32m268\u001b[39m     final_chunk = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_stream_with_aggregation\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    269\u001b[39m \u001b[43m        \u001b[49m\u001b[43mprompt\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    270\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    271\u001b[39m \u001b[43m        \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    272\u001b[39m \u001b[43m        \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    273\u001b[39m \u001b[43m        \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    274\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    275\u001b[39m     generations.append([final_chunk])\n\u001b[32m    276\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m LLMResult(generations=generations)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/projects/rcpp/.venv/lib/python3.12/site-packages/langchain_ollama/llms.py:236\u001b[39m, in \u001b[36mOllamaLLM._stream_with_aggregation\u001b[39m\u001b[34m(self, prompt, stop, run_manager, verbose, **kwargs)\u001b[39m\n\u001b[32m    227\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_stream_with_aggregation\u001b[39m(\n\u001b[32m    228\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m    229\u001b[39m     prompt: \u001b[38;5;28mstr\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m    233\u001b[39m     **kwargs: Any,\n\u001b[32m    234\u001b[39m ) -> GenerationChunk:\n\u001b[32m    235\u001b[39m     final_chunk = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m236\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mstream_resp\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_create_generate_stream\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprompt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m    237\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43misinstance\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mstream_resp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m    238\u001b[39m \u001b[43m            \u001b[49m\u001b[43mchunk\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mGenerationChunk\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    239\u001b[39m \u001b[43m                \u001b[49m\u001b[43mtext\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstream_resp\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mresponse\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mresponse\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mstream_resp\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    240\u001b[39m \u001b[43m                \u001b[49m\u001b[43mgeneration_info\u001b[49m\u001b[43m=\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    241\u001b[39m \u001b[43m                    \u001b[49m\u001b[38;5;28;43mdict\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mstream_resp\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mstream_resp\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mdone\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\n\u001b[32m    242\u001b[39m \u001b[43m                \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    243\u001b[39m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/projects/rcpp/.venv/lib/python3.12/site-packages/langchain_ollama/llms.py:186\u001b[39m, in \u001b[36mOllamaLLM._create_generate_stream\u001b[39m\u001b[34m(self, prompt, stop, **kwargs)\u001b[39m\n\u001b[32m    183\u001b[39m         params[key] = kwargs[key]\n\u001b[32m    185\u001b[39m params[\u001b[33m\"\u001b[39m\u001b[33moptions\u001b[39m\u001b[33m\"\u001b[39m][\u001b[33m\"\u001b[39m\u001b[33mstop\u001b[39m\u001b[33m\"\u001b[39m] = stop\n\u001b[32m--> \u001b[39m\u001b[32m186\u001b[39m \u001b[38;5;28;01myield from\u001b[39;00m ollama.generate(\n\u001b[32m    187\u001b[39m     model=params[\u001b[33m\"\u001b[39m\u001b[33mmodel\u001b[39m\u001b[33m\"\u001b[39m],\n\u001b[32m    188\u001b[39m     prompt=prompt,\n\u001b[32m    189\u001b[39m     stream=\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[32m    190\u001b[39m     options=Options(**params[\u001b[33m\"\u001b[39m\u001b[33moptions\u001b[39m\u001b[33m\"\u001b[39m]),\n\u001b[32m    191\u001b[39m     keep_alive=params[\u001b[33m\"\u001b[39m\u001b[33mkeep_alive\u001b[39m\u001b[33m\"\u001b[39m],\n\u001b[32m    192\u001b[39m     \u001b[38;5;28mformat\u001b[39m=params[\u001b[33m\"\u001b[39m\u001b[33mformat\u001b[39m\u001b[33m\"\u001b[39m],\n\u001b[32m    193\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/projects/rcpp/.venv/lib/python3.12/site-packages/ollama/_client.py:163\u001b[39m, in \u001b[36mClient._request.<locals>.inner\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m    162\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34minner\u001b[39m():\n\u001b[32m--> \u001b[39m\u001b[32m163\u001b[39m \u001b[43m  \u001b[49m\u001b[38;5;28;43;01mwith\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_client\u001b[49m\u001b[43m.\u001b[49m\u001b[43mstream\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mas\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mr\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m    164\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mtry\u001b[39;49;00m\u001b[43m:\u001b[49m\n\u001b[32m    165\u001b[39m \u001b[43m      \u001b[49m\u001b[43mr\u001b[49m\u001b[43m.\u001b[49m\u001b[43mraise_for_status\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/share/uv/python/cpython-3.12.0-linux-x86_64-gnu/lib/python3.12/contextlib.py:137\u001b[39m, in \u001b[36m_GeneratorContextManager.__enter__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    135\u001b[39m \u001b[38;5;28;01mdel\u001b[39;00m \u001b[38;5;28mself\u001b[39m.args, \u001b[38;5;28mself\u001b[39m.kwds, \u001b[38;5;28mself\u001b[39m.func\n\u001b[32m    136\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m137\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mnext\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mgen\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    138\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m:\n\u001b[32m    139\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mgenerator didn\u001b[39m\u001b[33m'\u001b[39m\u001b[33mt yield\u001b[39m\u001b[33m\"\u001b[39m) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/projects/rcpp/.venv/lib/python3.12/site-packages/httpx/_client.py:868\u001b[39m, in \u001b[36mClient.stream\u001b[39m\u001b[34m(self, method, url, content, data, files, json, params, headers, cookies, auth, follow_redirects, timeout, extensions)\u001b[39m\n\u001b[32m    845\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    846\u001b[39m \u001b[33;03mAlternative to `httpx.request()` that streams the response body\u001b[39;00m\n\u001b[32m    847\u001b[39m \u001b[33;03minstead of loading it into memory at once.\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    853\u001b[39m \u001b[33;03m[0]: /quickstart#streaming-responses\u001b[39;00m\n\u001b[32m    854\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    855\u001b[39m request = \u001b[38;5;28mself\u001b[39m.build_request(\n\u001b[32m    856\u001b[39m     method=method,\n\u001b[32m    857\u001b[39m     url=url,\n\u001b[32m   (...)\u001b[39m\u001b[32m    866\u001b[39m     extensions=extensions,\n\u001b[32m    867\u001b[39m )\n\u001b[32m--> \u001b[39m\u001b[32m868\u001b[39m response = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    869\u001b[39m \u001b[43m    \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    870\u001b[39m \u001b[43m    \u001b[49m\u001b[43mauth\u001b[49m\u001b[43m=\u001b[49m\u001b[43mauth\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    871\u001b[39m \u001b[43m    \u001b[49m\u001b[43mfollow_redirects\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfollow_redirects\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    872\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    873\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    874\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    875\u001b[39m     \u001b[38;5;28;01myield\u001b[39;00m response\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/projects/rcpp/.venv/lib/python3.12/site-packages/httpx/_client.py:914\u001b[39m, in \u001b[36mClient.send\u001b[39m\u001b[34m(self, request, stream, auth, follow_redirects)\u001b[39m\n\u001b[32m    910\u001b[39m \u001b[38;5;28mself\u001b[39m._set_timeout(request)\n\u001b[32m    912\u001b[39m auth = \u001b[38;5;28mself\u001b[39m._build_request_auth(request, auth)\n\u001b[32m--> \u001b[39m\u001b[32m914\u001b[39m response = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_send_handling_auth\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    915\u001b[39m \u001b[43m    \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    916\u001b[39m \u001b[43m    \u001b[49m\u001b[43mauth\u001b[49m\u001b[43m=\u001b[49m\u001b[43mauth\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    917\u001b[39m \u001b[43m    \u001b[49m\u001b[43mfollow_redirects\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfollow_redirects\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    918\u001b[39m \u001b[43m    \u001b[49m\u001b[43mhistory\u001b[49m\u001b[43m=\u001b[49m\u001b[43m[\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    919\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    920\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    921\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m stream:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/projects/rcpp/.venv/lib/python3.12/site-packages/httpx/_client.py:942\u001b[39m, in \u001b[36mClient._send_handling_auth\u001b[39m\u001b[34m(self, request, auth, follow_redirects, history)\u001b[39m\n\u001b[32m    939\u001b[39m request = \u001b[38;5;28mnext\u001b[39m(auth_flow)\n\u001b[32m    941\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m942\u001b[39m     response = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_send_handling_redirects\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    943\u001b[39m \u001b[43m        \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    944\u001b[39m \u001b[43m        \u001b[49m\u001b[43mfollow_redirects\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfollow_redirects\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    945\u001b[39m \u001b[43m        \u001b[49m\u001b[43mhistory\u001b[49m\u001b[43m=\u001b[49m\u001b[43mhistory\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    946\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    947\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    948\u001b[39m         \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/projects/rcpp/.venv/lib/python3.12/site-packages/httpx/_client.py:979\u001b[39m, in \u001b[36mClient._send_handling_redirects\u001b[39m\u001b[34m(self, request, follow_redirects, history)\u001b[39m\n\u001b[32m    976\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m hook \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m._event_hooks[\u001b[33m\"\u001b[39m\u001b[33mrequest\u001b[39m\u001b[33m\"\u001b[39m]:\n\u001b[32m    977\u001b[39m     hook(request)\n\u001b[32m--> \u001b[39m\u001b[32m979\u001b[39m response = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_send_single_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    980\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    981\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m hook \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m._event_hooks[\u001b[33m\"\u001b[39m\u001b[33mresponse\u001b[39m\u001b[33m\"\u001b[39m]:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/projects/rcpp/.venv/lib/python3.12/site-packages/httpx/_client.py:1014\u001b[39m, in \u001b[36mClient._send_single_request\u001b[39m\u001b[34m(self, request)\u001b[39m\n\u001b[32m   1009\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[32m   1010\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mAttempted to send an async request with a sync Client instance.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1011\u001b[39m     )\n\u001b[32m   1013\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m request_context(request=request):\n\u001b[32m-> \u001b[39m\u001b[32m1014\u001b[39m     response = \u001b[43mtransport\u001b[49m\u001b[43m.\u001b[49m\u001b[43mhandle_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1016\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(response.stream, SyncByteStream)\n\u001b[32m   1018\u001b[39m response.request = request\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/projects/rcpp/.venv/lib/python3.12/site-packages/httpx/_transports/default.py:249\u001b[39m, in \u001b[36mHTTPTransport.handle_request\u001b[39m\u001b[34m(self, request)\u001b[39m\n\u001b[32m    235\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mhttpcore\u001b[39;00m\n\u001b[32m    237\u001b[39m req = httpcore.Request(\n\u001b[32m    238\u001b[39m     method=request.method,\n\u001b[32m    239\u001b[39m     url=httpcore.URL(\n\u001b[32m   (...)\u001b[39m\u001b[32m    247\u001b[39m     extensions=request.extensions,\n\u001b[32m    248\u001b[39m )\n\u001b[32m--> \u001b[39m\u001b[32m249\u001b[39m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mwith\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mmap_httpcore_exceptions\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m    250\u001b[39m \u001b[43m    \u001b[49m\u001b[43mresp\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_pool\u001b[49m\u001b[43m.\u001b[49m\u001b[43mhandle_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreq\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    252\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(resp.stream, typing.Iterable)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/share/uv/python/cpython-3.12.0-linux-x86_64-gnu/lib/python3.12/contextlib.py:155\u001b[39m, in \u001b[36m_GeneratorContextManager.__exit__\u001b[39m\u001b[34m(self, typ, value, traceback)\u001b[39m\n\u001b[32m    153\u001b[39m     value = typ()\n\u001b[32m    154\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m155\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mgen\u001b[49m\u001b[43m.\u001b[49m\u001b[43mthrow\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    156\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[32m    157\u001b[39m     \u001b[38;5;66;03m# Suppress StopIteration *unless* it's the same exception that\u001b[39;00m\n\u001b[32m    158\u001b[39m     \u001b[38;5;66;03m# was passed to throw().  This prevents a StopIteration\u001b[39;00m\n\u001b[32m    159\u001b[39m     \u001b[38;5;66;03m# raised inside the \"with\" statement from being suppressed.\u001b[39;00m\n\u001b[32m    160\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m exc \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m value\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/projects/rcpp/.venv/lib/python3.12/site-packages/httpx/_transports/default.py:118\u001b[39m, in \u001b[36mmap_httpcore_exceptions\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m    115\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m\n\u001b[32m    117\u001b[39m message = \u001b[38;5;28mstr\u001b[39m(exc)\n\u001b[32m--> \u001b[39m\u001b[32m118\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m mapped_exc(message) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mexc\u001b[39;00m\n",
      "\u001b[31mConnectError\u001b[39m: [Errno 111] Connection refused"
     ]
    }
   ],
   "source": [
    "ollama_model.invoke(\"Tell me a funny fact about cats\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "594812c0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
